{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Make simpler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import linear_model\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from concepts import concept_instances\n",
    "from utils import load_data, load_q_network_device, prepare_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data = 1000\n",
    "data = load_data()\n",
    "for concept in concept_instances.values():\n",
    "    concept.prepare_data(data, max_size=max_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_network, device = load_q_network_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    preds = preds > 0.5\n",
    "    correct = (preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return max(0, 2*acc-1)\n",
    "\n",
    "def r2(preds, y):\n",
    "    return max(0, r2_score(y.detach().cpu().numpy(), preds.detach().cpu().numpy()))\n",
    "\n",
    "def prepare_data(concept):\n",
    "    obs_train = torch.tensor(concept.obs_train).float().to(device)\n",
    "    obs_test = torch.tensor(concept.obs_test).float().to(device)\n",
    "    _, acts_dict_train = q_network(obs_train, return_acts=True)\n",
    "    _, acts_dict_test = q_network(obs_test, return_acts=True)\n",
    "    acts_dict_train_test = {}\n",
    "    for k in acts_dict_train.keys():\n",
    "        acts_dict_train_test[k] = (acts_dict_train[k], acts_dict_test[k])\n",
    "    acts_dict_train_test['obs'] = (obs_train, obs_test)\n",
    "\n",
    "    return acts_dict_train_test\n",
    "\n",
    "def validate_model(model, val_acts, val_values, binary):\n",
    "    outputs = model(val_acts)\n",
    "    score = binary_accuracy(outputs, val_values) if binary else r2(outputs, val_values)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: random (b)\n",
      "Concept: all lives (b)\n",
      "Concept: last life (b)\n",
      "Concept: reward (b)\n",
      "Concept: ball collision (b)\n",
      "Concept: ball low (b)\n",
      "Concept: ball left paddle (b)\n",
      "Concept: ball right paddle (b)\n",
      "Concept: ball same x paddle (b)\n",
      "Concept: ball distance paddle\n",
      "Best l1_lambda: 0.001 with avg score: 0.007\n",
      "Final Test Score layer 0 with l1_lambda=0.001: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 0 with l1_lambda=0.001: 0.467\n",
      "Best l1_lambda: 0.001 with avg score: 0.114\n",
      "Final Test Score layer 1 with l1_lambda=0.001: 0.145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 1 with l1_lambda=0.001: 0.451\n",
      "Best l1_lambda: 0.001 with avg score: 0.262\n",
      "Final Test Score layer 2 with l1_lambda=0.001: 0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 2 with l1_lambda=0.005: 0.729\n",
      "Best l1_lambda: 0.01 with avg score: 0.110\n",
      "Final Test Score layer 3 with l1_lambda=0.01: 0.081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 3 with l1_lambda=0.001: 0.688\n",
      "Best l1_lambda: 0.001 with avg score: 0.405\n",
      "Final Test Score layer 4 with l1_lambda=0.001: 0.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 4 with l1_lambda=0.005: 0.655\n",
      "Best l1_lambda: 0.05 with avg score: 0.201\n",
      "Final Test Score layer 5 with l1_lambda=0.05: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 5 with l1_lambda=0.001: 0.746\n",
      "Best l1_lambda: 1.0 with avg score: 0.057\n",
      "Final Test Score layer 7 with l1_lambda=1.0: 0.000\n",
      "LassoCV Final Test Score layer 7 with l1_lambda=0.01: 0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best l1_lambda: 0.001 with avg score: 0.000\n",
      "Final Test Score layer obs with l1_lambda=0.001: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer obs with l1_lambda=0.1: 0.070\n",
      "Concept: ball y\n",
      "Best l1_lambda: 0.001 with avg score: 0.026\n",
      "Final Test Score layer 0 with l1_lambda=0.001: 0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 0 with l1_lambda=0.001: 0.630\n",
      "Best l1_lambda: 0.1 with avg score: 0.039\n",
      "Final Test Score layer 1 with l1_lambda=0.1: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 1 with l1_lambda=0.001: 0.501\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m25\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m l1_lambdas \u001b[39m=\u001b[39m [\u001b[39m0.001\u001b[39m, \u001b[39m0.005\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m0.05\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m1.0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m final_training_and_testing(concept_instances, kfold, lr, epochs, l1_lambdas)\n",
      "\u001b[1;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, activations \u001b[39min\u001b[39;00m acts_dict_train_test\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m     best_l1_lambda \u001b[39m=\u001b[39m cross_validate(activations, concept\u001b[39m.\u001b[39;49mvalues_train, l1_lambdas, kfold, lr, epochs, concept\u001b[39m.\u001b[39;49mbinary)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m     train_acts \u001b[39m=\u001b[39m activations[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mreshape(activations[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m     test_acts \u001b[39m=\u001b[39m activations[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mreshape(activations[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mdetach()\n",
      "\u001b[1;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m train_values \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(values_train[train_idx])\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m val_values \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(values_train[val_idx])\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m model \u001b[39m=\u001b[39m train_model(train_acts, train_values, train_acts\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], l1_lambda, lr, epochs, binary)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m score \u001b[39m=\u001b[39m validate_model(model, val_acts, val_values, binary)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m scores\u001b[39m.\u001b[39mappend(score)\n",
      "\u001b[1;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m l1_lambda \u001b[39m*\u001b[39m l1_reg\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     train_loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    436\u001b[0m params_ \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mview_as_real(x) \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(x) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m device_params]\n\u001b[1;32m    438\u001b[0m \u001b[39m# update steps\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m torch\u001b[39m.\u001b[39;49m_foreach_add_(device_state_steps, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m weight_decay \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    442\u001b[0m     device_grads \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_foreach_add(device_grads, device_params, alpha\u001b[39m=\u001b[39mweight_decay)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_model(train_acts, train_values, input_dim, l1_lambda, lr, epochs, binary):\n",
    "    if binary:\n",
    "        model = nn.Sequential(nn.Linear(input_dim, 1), nn.Sigmoid()).to(device)\n",
    "    else:\n",
    "        model = nn.Sequential(nn.Linear(input_dim, 1)).to(device)\n",
    "        \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_acts)\n",
    "        train_loss = loss_fn(outputs, train_values)\n",
    "        l1_reg = torch.tensor(0.0, device=device)\n",
    "        for param in model.parameters():\n",
    "            l1_reg += torch.norm(param, p=1)\n",
    "        train_loss += l1_lambda * l1_reg\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "def cross_validate(activations, values_train, l1_lambdas, kfold, lr, epochs, binary):\n",
    "    best_l1_lambda = 0\n",
    "    best_avg_score = -np.inf\n",
    "    for l1_lambda in l1_lambdas:\n",
    "        scores = []\n",
    "        for train_idx, val_idx in kfold.split(activations[0]):\n",
    "            train_acts = activations[0][train_idx].reshape(len(train_idx), -1).detach()\n",
    "            val_acts = activations[0][val_idx].reshape(len(val_idx), -1).detach()\n",
    "            train_values = torch.tensor(values_train[train_idx]).reshape(-1, 1).float().to(device)\n",
    "            val_values = torch.tensor(values_train[val_idx]).reshape(-1, 1).float().to(device)\n",
    "            model = train_model(train_acts, train_values, train_acts.shape[1], l1_lambda, lr, epochs, binary)\n",
    "            score = validate_model(model, val_acts, val_values, binary)\n",
    "            scores.append(score)\n",
    "        avg_score = np.mean(scores)\n",
    "        if avg_score > best_avg_score:\n",
    "            best_avg_score = avg_score\n",
    "            best_l1_lambda = l1_lambda\n",
    "    print(f\"Best l1_lambda: {best_l1_lambda} with avg score: {best_avg_score:.3f}\")\n",
    "    return best_l1_lambda\n",
    "\n",
    "def final_training_and_testing(concept_instances, kfold, lr, epochs, l1_lambdas):\n",
    "    for concept in concept_instances.values():\n",
    "        acts_dict_train_test = prepare_data(concept)\n",
    "        train_values = torch.tensor(concept.values_train).reshape(-1, 1).float().to(device)\n",
    "        test_values = torch.tensor(concept.values_test).reshape(-1, 1).float().to(device)\n",
    "        print(f\"Concept: {concept.name}\")\n",
    "        if concept.binary:\n",
    "            continue\n",
    "        for k, activations in acts_dict_train_test.items():\n",
    "            best_l1_lambda = cross_validate(activations, concept.values_train, l1_lambdas, kfold, lr, epochs, concept.binary)\n",
    "            train_acts = activations[0].reshape(activations[0].shape[0], -1).detach()\n",
    "            test_acts = activations[1].reshape(activations[1].shape[0], -1).detach()\n",
    "            final_model = train_model(train_acts, train_values, train_acts.shape[1], best_l1_lambda, lr, epochs, concept.binary)\n",
    "            final_score = validate_model(final_model, test_acts, test_values, concept.binary)\n",
    "            print(f\"Final Test Score layer {k} with l1_lambda={best_l1_lambda}: {final_score:.3f}\")\n",
    "            reg = linear_model.LassoCV(max_iter=50, cv=5, alphas=l1_lambdas)\n",
    "            reg.fit(train_acts.cpu().numpy(), train_values.cpu().numpy())\n",
    "            pred = reg.predict(test_acts.cpu().numpy())\n",
    "            score = r2_score(test_values.cpu().numpy(), pred)\n",
    "            print(f\"LassoCV Final Test Score layer {k} with l1_lambda={reg.alpha_}: {score:.3f}\")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "n_splits = 20\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "lr = 0.001\n",
    "epochs = 25\n",
    "l1_lambdas = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "final_training_and_testing(concept_instances, kfold, lr, epochs, l1_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: random (b)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     score \u001b[39m=\u001b[39m binary_accuracy(outputs, val_values) \u001b[39mif\u001b[39;00m concept\u001b[39m.\u001b[39mbinary \u001b[39melse\u001b[39;00m r2(outputs, val_values)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     scores\u001b[39m.\u001b[39mappend(score)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m avg_score \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmean(scores)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mif\u001b[39;00m avg_score \u001b[39m>\u001b[39m best_avg_score:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m     best_avg_score \u001b[39m=\u001b[39m avg_score\n",
      "File \u001b[0;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3501\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3502\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 3504\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39;49m_mean(a, axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   3505\u001b[0m                       out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/numpy/core/_methods.py:102\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mean\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 102\u001b[0m     arr \u001b[39m=\u001b[39m asanyarray(a)\n\u001b[1;32m    104\u001b[0m     is_float16_result \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     rcount \u001b[39m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[39m=\u001b[39mkeepdims, where\u001b[39m=\u001b[39mwhere)\n",
      "File \u001b[0;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/torch/_tensor.py:970\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    969\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 970\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    971\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    972\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for concept in concept_instances.values():\n",
    "    print(f\"Concept: {concept.name}\")\n",
    "    acts_dict_train_test = prepare_data(concept)\n",
    "\n",
    "    for k, activations in acts_dict_train_test.items():\n",
    "        optimal_l1_lambda = 0\n",
    "        best_avg_score = -np.inf\n",
    "        \n",
    "        # Find the best l1_lambda using k-fold CV\n",
    "        for l1_lambda in np.linspace(0.01, 1, num=10):  # Set your range and number of l1_lambda values to test\n",
    "            scores = []\n",
    "\n",
    "            for train_idx, val_idx in kfold.split(activations[0]):\n",
    "                train_acts = activations[0][train_idx].reshape(len(train_idx), -1).detach()\n",
    "                val_acts = activations[0][val_idx].reshape(len(val_idx), -1).detach()\n",
    "\n",
    "                train_values = torch.tensor(concept.values_train[train_idx]).reshape(-1, 1).float().to(device)\n",
    "                val_values = torch.tensor(concept.values_train[val_idx]).reshape(-1, 1).float().to(device)\n",
    "\n",
    "                # Model and optimizer initialization\n",
    "                model = nn.Sequential(nn.Linear(train_acts.shape[1], 1), nn.Sigmoid() if concept.binary else nn.Identity()).to(device)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "                # Training loop\n",
    "                for epoch in range(epochs):\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(train_acts)\n",
    "                    train_loss = loss_fn(outputs, train_values)\n",
    "\n",
    "                    # L1 regularization\n",
    "                    l1_reg = torch.tensor(0.0, device=device)\n",
    "                    for param in model.parameters():\n",
    "                        l1_reg += torch.norm(param, p=1)\n",
    "                    train_loss += l1_lambda * l1_reg\n",
    "                    \n",
    "                    train_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Validation\n",
    "                outputs = model(val_acts)\n",
    "                score = binary_accuracy(outputs, val_values) if concept.binary else r2(outputs, val_values)\n",
    "                scores.append(score)\n",
    "\n",
    "            avg_score = np.mean(scores)\n",
    "            if avg_score > best_avg_score:\n",
    "                best_avg_score = avg_score\n",
    "                optimal_l1_lambda = l1_lambda\n",
    "\n",
    "            # print(f\"Average validation score with l1_lambda={l1_lambda:.2f} for layer {k}: {avg_score:.3f}\")\n",
    "\n",
    "        print(f\"Optimal l1_lambda for layer {k}: {optimal_l1_lambda:.2f} with average validation score: {best_avg_score:.3f}\")\n",
    "        \n",
    "        # Using the best l1_lambda, train on the entire training set and evaluate on the test set\n",
    "        train_acts, test_acts = activations\n",
    "        train_acts = train_acts.reshape(train_acts.shape[0], -1).detach()\n",
    "        test_acts = test_acts.reshape(test_acts.shape[0], -1).detach()\n",
    "\n",
    "        train_values = torch.tensor(concept.values_train).reshape(-1, 1).float().to(device)\n",
    "        test_values = torch.tensor(concept.values_test).reshape(-1, 1).float().to(device)\n",
    "\n",
    "        model = nn.Sequential(nn.Linear(train_acts.shape[1], 1), nn.Sigmoid() if concept.binary else nn.Identity()).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        # Training loop with best l1_lambda\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(train_acts)\n",
    "            train_loss = loss_fn(outputs, train_values)\n",
    "\n",
    "            # L1 regularization\n",
    "            l1_reg = torch.tensor(0.0, device=device)\n",
    "            for param in model.parameters():\n",
    "                l1_reg += torch.norm(param, p=1)\n",
    "            train_loss += optimal_l1_lambda * l1_reg\n",
    "            \n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Test the model on the test dataset\n",
    "        outputs = model(test_acts)\n",
    "        if concept.binary:\n",
    "            print(f\"Test accuracy layer {k} with l1_lambda={optimal_l1_lambda:.2f}: {binary_accuracy(outputs, test_values):.3f}\")\n",
    "        else:\n",
    "            print(f\"Test R2 layer {k} with l1_lambda={optimal_l1_lambda:.2f}: {r2(outputs, test_values):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: random (b)\n",
      "Concept: all lives (b)\n",
      "Concept: last life (b)\n",
      "Concept: reward (b)\n",
      "Concept: ball collision (b)\n",
      "Concept: ball low (b)\n",
      "Concept: ball left paddle (b)\n",
      "Concept: ball right paddle (b)\n",
      "Concept: ball same x paddle (b)\n",
      "Concept: ball distance paddle\n",
      "Test R2 layer 0: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 0 with l1_lambda=0.001: 0.467\n",
      "Test R2 layer 1: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 1 with l1_lambda=0.001: 0.451\n",
      "Test R2 layer 2: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 2 with l1_lambda=0.005: 0.729\n",
      "Test R2 layer 3: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 3 with l1_lambda=0.001: 0.688\n",
      "Test R2 layer 4: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 4 with l1_lambda=0.005: 0.655\n",
      "Test R2 layer 5: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 5 with l1_lambda=0.001: 0.746\n",
      "Test R2 layer 7: 0.000\n",
      "LassoCV Final Test Score layer 7 with l1_lambda=0.01: 0.699\n",
      "Test R2 layer obs: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer obs with l1_lambda=0.1: 0.070\n",
      "Concept: ball y\n",
      "Test R2 layer 0: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 0 with l1_lambda=0.001: 0.630\n",
      "Test R2 layer 1: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 1 with l1_lambda=0.001: 0.501\n",
      "Test R2 layer 2: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 2 with l1_lambda=0.005: 0.759\n",
      "Test R2 layer 3: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 3 with l1_lambda=0.001: 0.780\n",
      "Test R2 layer 4: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 4 with l1_lambda=0.005: 0.761\n",
      "Test R2 layer 5: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 5 with l1_lambda=0.005: 0.735\n",
      "Test R2 layer 7: 0.000\n",
      "LassoCV Final Test Score layer 7 with l1_lambda=0.01: 0.815\n",
      "Test R2 layer obs: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer obs with l1_lambda=0.01: 0.337\n",
      "Concept: ball y next\n",
      "Test R2 layer 0: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 0 with l1_lambda=0.001: 0.548\n",
      "Test R2 layer 1: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 1 with l1_lambda=0.001: 0.487\n",
      "Test R2 layer 2: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 2 with l1_lambda=0.005: 0.691\n",
      "Test R2 layer 3: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 3 with l1_lambda=0.001: 0.643\n",
      "Test R2 layer 4: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 4 with l1_lambda=0.005: 0.678\n",
      "Test R2 layer 5: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 5 with l1_lambda=0.001: 0.686\n",
      "Test R2 layer 7: 0.000\n",
      "LassoCV Final Test Score layer 7 with l1_lambda=0.01: 0.679\n",
      "Test R2 layer obs: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer obs with l1_lambda=0.1: 0.297\n",
      "Concept: ball x\n",
      "Test R2 layer 0: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 0 with l1_lambda=0.001: 0.688\n",
      "Test R2 layer 1: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 1 with l1_lambda=0.001: 0.598\n",
      "Test R2 layer 2: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 2 with l1_lambda=0.001: 0.903\n",
      "Test R2 layer 3: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 3 with l1_lambda=0.001: 0.909\n",
      "Test R2 layer 4: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 4 with l1_lambda=0.001: 0.885\n",
      "Test R2 layer 5: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 5 with l1_lambda=0.001: 0.902\n",
      "Test R2 layer 7: 0.000\n",
      "LassoCV Final Test Score layer 7 with l1_lambda=0.005: 0.861\n",
      "Test R2 layer obs: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer obs with l1_lambda=0.001: 0.450\n",
      "Concept: ball x next\n",
      "Test R2 layer 0: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 0 with l1_lambda=0.001: 0.713\n",
      "Test R2 layer 1: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 1 with l1_lambda=0.001: 0.597\n",
      "Test R2 layer 2: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 2 with l1_lambda=0.005: 0.810\n",
      "Test R2 layer 3: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 3 with l1_lambda=0.001: 0.862\n",
      "Test R2 layer 4: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 4 with l1_lambda=0.001: 0.881\n",
      "Test R2 layer 5: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 5 with l1_lambda=0.001: 0.863\n",
      "Test R2 layer 7: 0.000\n",
      "LassoCV Final Test Score layer 7 with l1_lambda=0.01: 0.828\n",
      "Test R2 layer obs: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer obs with l1_lambda=0.05: 0.402\n",
      "Concept: lives\n",
      "Test R2 layer 0: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 0 with l1_lambda=0.001: 0.996\n",
      "Test R2 layer 1: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 1 with l1_lambda=0.001: 0.999\n",
      "Test R2 layer 2: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 2 with l1_lambda=0.001: 0.996\n",
      "Test R2 layer 3: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 3 with l1_lambda=0.001: 0.999\n",
      "Test R2 layer 4: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 4 with l1_lambda=0.001: 0.990\n",
      "Test R2 layer 5: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 5 with l1_lambda=0.001: 0.988\n",
      "Test R2 layer 7: 0.000\n",
      "LassoCV Final Test Score layer 7 with l1_lambda=0.001: 0.930\n",
      "Test R2 layer obs: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer obs with l1_lambda=0.001: 0.991\n",
      "Concept: x diff\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m train_acts \u001b[39m=\u001b[39m train_acts\u001b[39m.\u001b[39mreshape(train_acts\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m test_acts \u001b[39m=\u001b[39m test_acts\u001b[39m.\u001b[39mreshape(test_acts\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m train_values \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(concept\u001b[39m.\u001b[39;49mvalues_train)\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mfloat()\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m test_values \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(concept\u001b[39m.\u001b[39mvalues_test)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/notebooks/torch_probing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# create 1 layer network as logistic regression\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "l1_lambda = 0.0001\n",
    "for concept in concept_instances.values():\n",
    "    print(f\"Concept: {concept.name}\")\n",
    "    if concept.binary:\n",
    "        continue\n",
    "    acts_dict_train_test = prepare_data(concept)\n",
    "    # train probe for each layer\n",
    "    for k, activations in acts_dict_train_test.items():\n",
    "        train_acts, test_acts = activations\n",
    "        train_acts = train_acts.reshape(train_acts.shape[0], -1).detach()\n",
    "        test_acts = test_acts.reshape(test_acts.shape[0], -1).detach()\n",
    "\n",
    "        train_values = torch.tensor(concept.values_train).reshape(-1, 1).float().to(device)\n",
    "        test_values = torch.tensor(concept.values_test).reshape(-1, 1).float().to(device)\n",
    "\n",
    "        # create 1 layer network as logistic regression\n",
    "        if concept.binary:\n",
    "            model = nn.Sequential(nn.Linear(train_acts.shape[1], 1), nn.Sigmoid()).to(device)\n",
    "        else:\n",
    "            model = nn.Sequential(nn.Linear(train_acts.shape[1], 1)).to(device)\n",
    "\n",
    "        # train the model\n",
    "        for epoch in range(epochs):\n",
    "            optimizer = optim.Adam(model.parameters())\n",
    "            total_train_loss = 0.0\n",
    "\n",
    "            for batch_idx in range(len(train_acts) // batch_size):\n",
    "                start_idx = batch_idx * batch_size\n",
    "                end_idx = start_idx + batch_size\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                batch_train_acts = train_acts[start_idx:end_idx]\n",
    "                batch_train_values = train_values[start_idx:end_idx]\n",
    "                outputs = model(batch_train_acts)\n",
    "                train_loss = loss_fn(outputs, batch_train_values)\n",
    "\n",
    "                # Calculate L1 regularization for weights only\n",
    "                l1_reg = torch.tensor(0.0, device=device)\n",
    "                for name, param in model.named_parameters():\n",
    "                    if 'weight' in name:  # check if 'param' is weight\n",
    "                        l1_reg += torch.norm(param, p=1)\n",
    "\n",
    "                # Add L1 regularization to the loss\n",
    "                train_loss += l1_lambda * l1_reg\n",
    "\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "                total_train_loss += train_loss.item()\n",
    "\n",
    "        # test the model\n",
    "        outputs = model(test_acts)\n",
    "        if concept.binary:\n",
    "            print(f\"Test accuracy layer {k}: {binary_accuracy(outputs, test_values):.3f}\")\n",
    "        else:\n",
    "            print(f\"Test R2 layer {k}: {r2(outputs, test_values):.3f}\")\n",
    "\n",
    "        reg = linear_model.LassoCV(max_iter=50, cv=5, alphas=l1_lambdas)\n",
    "        reg.fit(train_acts.cpu().numpy(), train_values.cpu().numpy())\n",
    "        pred = reg.predict(test_acts.cpu().numpy())\n",
    "        score = r2_score(test_values.cpu().numpy(), pred)\n",
    "        print(f\"LassoCV Final Test Score layer {k} with l1_lambda={reg.alpha_}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: ball x\n",
      "tensor(2.3632, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(51.0095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8475, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(28.3349, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.2473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.0446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.1805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.6045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.9555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7862, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6566, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(54.1320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7688, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.8619, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(30.3491, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.5958, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.9167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.0473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.7266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.9858, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.0488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0779, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(58.5005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7946, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.9783, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(33.1940, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(23.9442, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.3805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4430, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.5100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.0548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.8140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.2506, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(54.2662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.4956, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(34.0751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.4637, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5537, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.4910, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.1973, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.7457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.5929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8498, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(62.7128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.6434, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.7368, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(34.3353, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.1793, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.7563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5471, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.7129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.7299, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.4223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.4484, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(61.6562, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.1526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.9582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(33.7247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.6772, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.8093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0452, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.9870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.9087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.6943, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.1586, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4948, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(71.7201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.9561, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.5040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(40.4254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(32.7958, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.4238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8896, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.0920, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.3346, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.7214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1413, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(48.6875, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.0353, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.2751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.9906, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.1539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9861, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.7738, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.4278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.6615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(51.5254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8604, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.1524, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.2072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.0680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.8454, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.5799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.5481, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.1454, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8686, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(55.2881, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.1430, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(30.0187, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(22.8458, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.6515, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.6142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.9635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.1103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.8876, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(60.6494, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8850, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.5081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(33.7811, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.9840, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.7012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0831, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.8749, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.4588, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.5843, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.8597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5768, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(72.3095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.0087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.6938, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(39.9546, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(32.1501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.2032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.5762, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.6488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.2007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.7889, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(49.1037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7890, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.4181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.9739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.1209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2661, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8704, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.8446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.9922, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.8990, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9806, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(52.1263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.3245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(28.3480, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(21.3111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.2365, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.7999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.2563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5598, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(56.4206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.4254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(31.4662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.5596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.8034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.3434, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.7054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.9056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.2338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3961, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(70.2007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.2063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.3178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(41.2196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(29.5452, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.8289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.5208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(21.3208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.2079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.3451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(52.9490, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7978, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.7858, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(28.8568, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(22.3143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.4887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4876, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.7442, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.9976, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.5833, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.3550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(57.5247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.7744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(32.1278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.8009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.2925, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.1248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.2711, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.7050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.9059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(77.3755, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.2616, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.3081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(42.3854, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(34.7752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.5512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8508, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.7621, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.5921, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.5606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.5025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2000, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(43.0903, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.9053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.5566, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(22.5039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.4012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5480, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.6732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.0584, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.5207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5358, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(44.8816, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6915, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.2976, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.0751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.4695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1852, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.9225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.9454, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.7131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0389, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2608, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(46.6167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.9527, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.6044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.6517, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5395, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.0547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.8379, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.9879, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(48.6394, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4920, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.6379, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.3155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.1283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.2299, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.0758, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.8247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.5010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(51.3834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4798, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.4423, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(29.4521, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(22.2068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.2332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6574, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.8859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.9761, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.5016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.9271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(54.8847, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.6380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(32.1716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.9709, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.5759, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3893, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.5432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.2406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.9664, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.8995, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(81.4637, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.5173, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.3352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(43.5195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(36.3810, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.6151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9594, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.7489, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.8223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.8862, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.9096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(39.6272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7748, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.6159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(21.4676, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.2968, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5846, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5309, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.6934, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.3690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.9713, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8708, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(40.6119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5906, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.1350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(22.4462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.8332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.9385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.9206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.6543, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5840, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(41.2118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4746, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.4815, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(23.1637, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.2374, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.0574, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5389, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.1062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.3441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.1949, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7957, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4793, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(41.5739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3949, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.7204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(23.7058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.5494, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2508, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5479, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.2287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.6814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.6307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9780, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3670, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(41.7553, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.8839, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.1069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.7744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5621, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.3222, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.9438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.9688, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2893, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(41.7661, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2877, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.9837, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.3773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.9153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5852, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.4032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.1306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.2054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(41.6062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2519, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.0190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.5106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.9523, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.4630, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.2326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.3335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2968, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(41.2615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.9820, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.5027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.8791, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6616, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.5075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.2443, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.3484, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2374, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(40.7079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.8674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.3421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.6827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6371, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.5412, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.1539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.2354, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2608, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2860, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(39.9192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.6634, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.3487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.5571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.9426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.9781, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(38.8725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.3562, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(23.4927, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.8790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.9097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.5502, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.6031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.5765, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5146, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(37.5797, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2517, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.9422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(22.8082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.3020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.5126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.1400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.0580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6987, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(36.1089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.4439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(21.9969, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.6563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.1500, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.1533, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.4259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.5823, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.4701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(34.5608, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3876, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.9066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(21.1414, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.0105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.9947, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2689, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.3023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.9861, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.8769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4842, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(33.0773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4791, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.3834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.3304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.4339, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.1540, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.4255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.3510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3849, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(31.7796, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5633, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.9357, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.6397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.9578, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7679, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.9505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.9251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4933, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(30.7127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.5859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.0921, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.5802, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6930, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4820, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.8871, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.5739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.5988, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(29.8505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.3271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.6646, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.2718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.7873, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.2745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.3453, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6789, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(29.1330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6837, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.1330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.3178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5787, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5652, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.7045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.0252, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.1376, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7327, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(28.5097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6886, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.9792, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.0200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.7684, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5293, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.6318, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.8059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.9577, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7724, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.9495, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6853, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.8507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.7535, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.5490, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6390, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.5654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.6068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.7965, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.4344, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6765, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.7397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.5086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.3433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4381, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6731, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.5018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.4208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.6485, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.9547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6647, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.6399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.2815, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.1520, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3965, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.4419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.2477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.5139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3862, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.5050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.5512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.0697, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.9703, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.3845, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.0838, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.3890, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8549, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.0800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.4706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.8697, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.7962, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.3286, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.9270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.2711, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.6763, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.3973, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.6793, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.6291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.2737, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.7763, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.1601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4771, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8677, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.2919, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5930, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.3304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.4975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.4685, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2442, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.2198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.6309, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.0553, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.9251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.2692, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.3236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.3136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8482, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.1669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.4903, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.9561, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.5775, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5479, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.2128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.1601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.1667, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1754, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.1139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.3562, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5862, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(24.2443, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.1608, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.0246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8974, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.0618, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.2259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7787, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8566, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(23.9247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4990, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.1131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.8513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.8871, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.9210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(10.0108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.0995, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6966, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8479, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(23.6177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.0687, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.7063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.7550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0807, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.9441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.9617, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.9772, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8373, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(23.3223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.0280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.5660, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.6262, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.9668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.9132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.8571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5450, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(23.0375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4187, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.9905, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.4304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.5009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.9890, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.8652, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.7398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7936, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(22.7623, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3905, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.9556, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.2992, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.3784, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9934, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.0110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.8182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.6253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7959, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(22.4971, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.9239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.1715, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.2589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9658, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.0326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.7716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.5129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8843, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7793, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(22.2407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3313, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8947, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(15.0463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.1425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.0537, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.7248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.4017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2810, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(21.9926, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8672, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.9252, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.0294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.0743, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.6795, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.2939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9771, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(21.7526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2703, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.8080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.9181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8867, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.0948, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.6340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.1870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.1661, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(21.5205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2389, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.6939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.8098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.1147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.5889, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.0822, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.1124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(21.2970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7989, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.5830, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.7044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.1343, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.5442, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.9799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.0614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6791, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(21.0802, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.1750, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7803, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.4743, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.6008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.1535, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.4986, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.8795, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1686, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6566, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.8692, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.1425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.3661, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.5005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7909, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.1722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.4543, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.7806, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.9662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2173, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.6653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.1088, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7493, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.2607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.3982, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7686, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.1911, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.4081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.6784, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.9206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2671, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.4740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.0728, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.1594, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.2975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.2104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.3632, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.5789, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8770, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5786, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.2877, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.0371, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(14.0602, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.1998, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.2292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.3194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.4823, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(20.1058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.9625, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.1041, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.2476, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.2765, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.3874, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7963, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.9295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.9663, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.8669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.0108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6835, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.2657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.2344, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.2949, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4958, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.7573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.9312, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.7732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.9197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6641, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.2833, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.1931, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.2043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4677, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.5896, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8961, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.6811, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.8303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6452, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.3006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.1522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.1153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6901, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.4263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.5906, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.7426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.3176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.1121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.0278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6583, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.2663, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.5020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.6556, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.3346, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.0716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.9410, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6670, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3816, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(19.1114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7908, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.4153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.5703, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5918, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.3512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.0317, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.8560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5986, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3523, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.9601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.3290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.4857, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.3670, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.9920, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.7717, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5711, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7671, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.8137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.2446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.4028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.3825, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.9528, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.6894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2928, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.6712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6849, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.1615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.3214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.3976, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.9139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.6084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8664, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2628, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.5333, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6498, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.0803, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.2415, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.4121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.8745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.5288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4980, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.9146, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.3980, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(13.0005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.1635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5133, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.4261, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.8360, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.4511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.9627, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.2662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.9221, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.0873, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4992, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.4398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.7980, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.3751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4565, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.0105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1737, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.1375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5467, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.8450, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.0125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4857, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.4533, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.7606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.3007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.0581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1440, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(18.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.7676, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.9378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4726, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.4661, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.7216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.2270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.1047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.8898, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4786, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.6871, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.8654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4599, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.4792, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.6838, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.1538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.1513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0842, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.7720, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.6134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.7930, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.4917, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.6461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.0838, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3868, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.1972, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0549, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.6550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7437, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.5405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.7226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.5036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.6096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.0152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.5402, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3787, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7500, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.4639, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.6541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.5155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.5743, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.9465, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3583, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2886, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9960, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.4301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7585, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.3940, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.5856, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.5267, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.5392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.8809, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9671, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.3202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.3202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.5200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.5380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.5051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.8154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.3783, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9379, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.2148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2821, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7743, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.2529, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.4547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3947, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.5485, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.4714, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.7531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.1087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7812, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.1815, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.3924, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.5589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.4388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.6909, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8813, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(17.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7901, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.1162, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.3300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3767, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.5687, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.4062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.6315, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.9040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1910, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.7970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(12.0469, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.2705, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3684, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.5784, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.3748, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.5722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2969, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.8051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.9790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.2114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3602, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.5878, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.3433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.5140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2891, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.7082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.9169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.1525, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3523, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.5965, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.3117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.4584, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2830, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(16.6107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8218, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(11.8512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(6.0974, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3452, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.6049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(8.2822, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(5.4039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Test R2 layer 0: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/.conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1563: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Final Test Score layer 0 with l1_lambda=0.001: 0.688\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "concept = concept_instances['ball x']\n",
    "batch_size = 64\n",
    "l1_lambda = 0.0\n",
    "print(f\"Concept: {concept.name}\")\n",
    "acts_dict_train_test = prepare_data(concept)\n",
    "# train probe for each layer\n",
    "for k, activations in acts_dict_train_test.items():\n",
    "    train_acts, test_acts = activations\n",
    "    train_acts = train_acts.reshape(train_acts.shape[0], -1).detach()\n",
    "    test_acts = test_acts.reshape(test_acts.shape[0], -1).detach()\n",
    "\n",
    "    train_values = torch.tensor(concept.values_train).reshape(-1, 1).float().to(device)\n",
    "    test_values = torch.tensor(concept.values_test).reshape(-1, 1).float().to(device)\n",
    "\n",
    "    # create 1 layer network as logistic regression\n",
    "    if concept.binary:\n",
    "        model = nn.Sequential(nn.Linear(train_acts.shape[1], 1), nn.Sigmoid()).to(device)\n",
    "    else:\n",
    "        model = nn.Sequential(nn.Linear(train_acts.shape[1], 1)).to(device)\n",
    "\n",
    "    # train the model\n",
    "    for epoch in range(epochs):\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        for batch_idx in range(len(train_acts) // batch_size):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            batch_train_acts = train_acts[start_idx:end_idx]\n",
    "            batch_train_values = train_values[start_idx:end_idx]\n",
    "            outputs = model(batch_train_acts)\n",
    "            train_loss = loss_fn(outputs, batch_train_values)\n",
    "\n",
    "            # Calculate L1 regularization for weights only\n",
    "            l1_reg = torch.tensor(0.0, device=device)\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'weight' in name:  # check if 'param' is weight\n",
    "                    l1_reg += torch.norm(param, p=1)\n",
    "\n",
    "            # Add L1 regularization to the loss\n",
    "            train_loss += l1_lambda * l1_reg\n",
    "            print(train_loss, l1_lambda * l1_reg)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += train_loss.item()\n",
    "\n",
    "    # test the model\n",
    "    outputs = model(test_acts)\n",
    "    if concept.binary:\n",
    "        print(f\"Test accuracy layer {k}: {binary_accuracy(outputs, test_values):.3f}\")\n",
    "    else:\n",
    "        print(f\"Test R2 layer {k}: {r2(outputs, test_values):.3f}\")\n",
    "\n",
    "    reg = linear_model.LassoCV(max_iter=50, cv=5, alphas=l1_lambdas)\n",
    "    reg.fit(train_acts.cpu().numpy(), train_values.cpu().numpy())\n",
    "    pred = reg.predict(test_acts.cpu().numpy())\n",
    "    score = r2_score(test_values.cpu().numpy(), pred)\n",
    "    print(f\"LassoCV Final Test Score layer {k} with l1_lambda={reg.alpha_}: {score:.3f}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.00020997308, 0.0533668)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_.mean(), reg.coef_.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor(-1.3501e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "0.bias Parameter containing:\n",
      "tensor([-0.0025], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# go through parameters in model\n",
    "for name, param in model.named_parameters():\n",
    "    # if bias\n",
    "    if 'bias' in name:\n",
    "        print(name, param)\n",
    "    else:\n",
    "        print(name, param.mean(), param.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
