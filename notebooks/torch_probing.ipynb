{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from concepts import concept_instances\n",
    "from probing import train_probes\n",
    "from utils import load_game_data, load_q_network_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QNetwork(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    (7): Linear(in_features=3136, out_features=512, bias=True)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=512, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_data = load_game_data()\n",
    "q_network, device = load_q_network_device()\n",
    "q_network.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'lr': 0.0001,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 300,\n",
    "    'lambda_l1': 0.00001,\n",
    "    'patience': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random (b)\n",
      "Epoch 1/300 - Train loss: 0.2545 - Test loss: 0.2652 - Test score: -0.0234\n",
      "Epoch 2/300 - Train loss: 0.2532 - Test loss: 0.2628 - Test score: -0.0234\n",
      "Epoch 3/300 - Train loss: 0.2538 - Test loss: 0.2519 - Test score: -0.0165\n",
      "Epoch 4/300 - Train loss: 0.2549 - Test loss: 0.2528 - Test score: 0.0041\n",
      "Epoch 5/300 - Train loss: 0.2508 - Test loss: 0.2525 - Test score: -0.0134\n",
      "Epoch 6/300 - Train loss: 0.2490 - Test loss: 0.2814 - Test score: 0.0195\n",
      "Epoch 7/300 - Train loss: 0.2490 - Test loss: 0.2532 - Test score: -0.0431\n",
      "Epoch 8/300 - Train loss: 0.2493 - Test loss: 0.2523 - Test score: -0.0239\n",
      "Epoch 9/300 - Train loss: 0.2493 - Test loss: 0.2666 - Test score: -0.0156\n",
      "Epoch 10/300 - Train loss: 0.2487 - Test loss: 0.2776 - Test score: -0.0182\n",
      "Epoch 11/300 - Train loss: 0.2471 - Test loss: 0.2708 - Test score: -0.0143\n",
      "Epoch 12/300 - Train loss: 0.2487 - Test loss: 0.2551 - Test score: 0.0096\n",
      "Epoch 13/300 - Train loss: 0.2472 - Test loss: 0.2604 - Test score: 0.0087\n",
      "Epoch 14/300 - Train loss: 0.2481 - Test loss: 0.2541 - Test score: -0.0005\n",
      "Epoch 15/300 - Train loss: 0.2485 - Test loss: 0.2627 - Test score: 0.0093\n",
      "Epoch 16/300 - Train loss: 0.2483 - Test loss: 0.2575 - Test score: 0.0136\n",
      "\n",
      "Layer 0 - Score: 0.0195\n",
      "Epoch 1/300 - Train loss: 0.2508 - Test loss: 0.2502 - Test score: -0.0134\n",
      "Epoch 2/300 - Train loss: 0.2498 - Test loss: 0.2501 - Test score: 0.0180\n",
      "Epoch 3/300 - Train loss: 0.2489 - Test loss: 0.2502 - Test score: 0.0146\n",
      "Epoch 4/300 - Train loss: 0.2481 - Test loss: 0.2505 - Test score: 0.0129\n",
      "Epoch 5/300 - Train loss: 0.2477 - Test loss: 0.2509 - Test score: -0.0153\n",
      "Epoch 6/300 - Train loss: 0.2471 - Test loss: 0.2510 - Test score: -0.0023\n",
      "Epoch 7/300 - Train loss: 0.2464 - Test loss: 0.2509 - Test score: -0.0070\n",
      "Epoch 8/300 - Train loss: 0.2461 - Test loss: 0.2510 - Test score: -0.0032\n",
      "Epoch 9/300 - Train loss: 0.2458 - Test loss: 0.2510 - Test score: -0.0086\n",
      "Epoch 10/300 - Train loss: 0.2453 - Test loss: 0.2513 - Test score: 0.0008\n",
      "Epoch 11/300 - Train loss: 0.2446 - Test loss: 0.2514 - Test score: -0.0346\n",
      "Epoch 12/300 - Train loss: 0.2443 - Test loss: 0.2517 - Test score: -0.0174\n",
      "\n",
      "Layer 1 - Score: 0.0180\n",
      "Epoch 1/300 - Train loss: 0.2539 - Test loss: 0.2547 - Test score: -0.0143\n",
      "Epoch 2/300 - Train loss: 0.2529 - Test loss: 0.2516 - Test score: -0.0044\n",
      "Epoch 3/300 - Train loss: 0.2498 - Test loss: 0.2524 - Test score: -0.0037\n",
      "Epoch 4/300 - Train loss: 0.2490 - Test loss: 0.2530 - Test score: 0.0005\n",
      "Epoch 5/300 - Train loss: 0.2487 - Test loss: 0.2517 - Test score: 0.0104\n",
      "Epoch 6/300 - Train loss: 0.2476 - Test loss: 0.2533 - Test score: -0.0087\n",
      "Epoch 7/300 - Train loss: 0.2466 - Test loss: 0.2536 - Test score: -0.0040\n",
      "Epoch 8/300 - Train loss: 0.2479 - Test loss: 0.2542 - Test score: -0.0141\n",
      "Epoch 9/300 - Train loss: 0.2462 - Test loss: 0.2526 - Test score: -0.0096\n",
      "Epoch 10/300 - Train loss: 0.2445 - Test loss: 0.2544 - Test score: -0.0229\n",
      "Epoch 11/300 - Train loss: 0.2463 - Test loss: 0.2534 - Test score: -0.0184\n",
      "Epoch 12/300 - Train loss: 0.2439 - Test loss: 0.2548 - Test score: -0.0335\n",
      "Epoch 13/300 - Train loss: 0.2433 - Test loss: 0.2536 - Test score: 0.0106\n",
      "Epoch 14/300 - Train loss: 0.2430 - Test loss: 0.2552 - Test score: -0.0440\n",
      "Epoch 15/300 - Train loss: 0.2433 - Test loss: 0.2546 - Test score: -0.0277\n",
      "Epoch 16/300 - Train loss: 0.2432 - Test loss: 0.2552 - Test score: -0.0404\n",
      "Epoch 17/300 - Train loss: 0.2436 - Test loss: 0.2557 - Test score: -0.0178\n",
      "Epoch 18/300 - Train loss: 0.2421 - Test loss: 0.2566 - Test score: -0.0316\n",
      "Epoch 19/300 - Train loss: 0.2426 - Test loss: 0.2552 - Test score: -0.0185\n",
      "Epoch 20/300 - Train loss: 0.2416 - Test loss: 0.2552 - Test score: -0.0031\n",
      "Epoch 21/300 - Train loss: 0.2407 - Test loss: 0.2570 - Test score: -0.0186\n",
      "Epoch 22/300 - Train loss: 0.2408 - Test loss: 0.2559 - Test score: -0.0182\n",
      "Epoch 23/300 - Train loss: 0.2433 - Test loss: 0.2607 - Test score: 0.0081\n",
      "\n",
      "Layer 2 - Score: 0.0106\n",
      "Epoch 1/300 - Train loss: 0.2504 - Test loss: 0.2512 - Test score: -0.0307\n",
      "Epoch 2/300 - Train loss: 0.2496 - Test loss: 0.2510 - Test score: -0.0514\n",
      "Epoch 3/300 - Train loss: 0.2489 - Test loss: 0.2510 - Test score: -0.0674\n",
      "Epoch 4/300 - Train loss: 0.2481 - Test loss: 0.2515 - Test score: -0.0247\n",
      "Epoch 5/300 - Train loss: 0.2477 - Test loss: 0.2515 - Test score: -0.0458\n",
      "Epoch 6/300 - Train loss: 0.2473 - Test loss: 0.2517 - Test score: -0.0383\n",
      "Epoch 7/300 - Train loss: 0.2467 - Test loss: 0.2517 - Test score: -0.0767\n",
      "Epoch 8/300 - Train loss: 0.2465 - Test loss: 0.2521 - Test score: -0.0384\n",
      "Epoch 9/300 - Train loss: 0.2458 - Test loss: 0.2521 - Test score: -0.0451\n",
      "Epoch 10/300 - Train loss: 0.2452 - Test loss: 0.2522 - Test score: -0.0557\n",
      "Epoch 11/300 - Train loss: 0.2451 - Test loss: 0.2524 - Test score: -0.0583\n",
      "Epoch 12/300 - Train loss: 0.2447 - Test loss: 0.2528 - Test score: -0.0371\n",
      "Epoch 13/300 - Train loss: 0.2441 - Test loss: 0.2527 - Test score: -0.0508\n",
      "Epoch 14/300 - Train loss: 0.2438 - Test loss: 0.2531 - Test score: -0.0424\n",
      "\n",
      "Layer 3 - Score: -0.0247\n",
      "Epoch 1/300 - Train loss: 0.2548 - Test loss: 0.2610 - Test score: -0.0314\n",
      "Epoch 2/300 - Train loss: 0.2521 - Test loss: 0.2536 - Test score: -0.0233\n",
      "Epoch 3/300 - Train loss: 0.2505 - Test loss: 0.2549 - Test score: -0.0169\n",
      "Epoch 4/300 - Train loss: 0.2499 - Test loss: 0.2529 - Test score: -0.0165\n",
      "Epoch 5/300 - Train loss: 0.2491 - Test loss: 0.2537 - Test score: -0.0227\n",
      "Epoch 6/300 - Train loss: 0.2480 - Test loss: 0.2543 - Test score: -0.0299\n",
      "Epoch 7/300 - Train loss: 0.2473 - Test loss: 0.2555 - Test score: -0.0092\n",
      "Epoch 8/300 - Train loss: 0.2464 - Test loss: 0.2558 - Test score: 0.0041\n",
      "Epoch 9/300 - Train loss: 0.2472 - Test loss: 0.2535 - Test score: -0.0359\n",
      "Epoch 10/300 - Train loss: 0.2456 - Test loss: 0.2577 - Test score: -0.0033\n",
      "Epoch 11/300 - Train loss: 0.2446 - Test loss: 0.2572 - Test score: -0.0209\n",
      "Epoch 12/300 - Train loss: 0.2448 - Test loss: 0.2548 - Test score: -0.0444\n",
      "Epoch 13/300 - Train loss: 0.2443 - Test loss: 0.2564 - Test score: -0.0111\n",
      "Epoch 14/300 - Train loss: 0.2434 - Test loss: 0.2556 - Test score: -0.0386\n",
      "Epoch 15/300 - Train loss: 0.2433 - Test loss: 0.2561 - Test score: -0.0070\n",
      "Epoch 16/300 - Train loss: 0.2439 - Test loss: 0.2550 - Test score: -0.0394\n",
      "Epoch 17/300 - Train loss: 0.2426 - Test loss: 0.2565 - Test score: -0.0493\n",
      "Epoch 18/300 - Train loss: 0.2430 - Test loss: 0.2560 - Test score: -0.0185\n",
      "\n",
      "Layer 4 - Score: 0.0041\n",
      "Epoch 1/300 - Train loss: 0.2509 - Test loss: 0.2507 - Test score: -0.0017\n",
      "Epoch 2/300 - Train loss: 0.2501 - Test loss: 0.2506 - Test score: -0.0135\n",
      "Epoch 3/300 - Train loss: 0.2493 - Test loss: 0.2509 - Test score: -0.0283\n",
      "Epoch 4/300 - Train loss: 0.2486 - Test loss: 0.2510 - Test score: -0.0378\n",
      "Epoch 5/300 - Train loss: 0.2480 - Test loss: 0.2511 - Test score: -0.0286\n",
      "Epoch 6/300 - Train loss: 0.2474 - Test loss: 0.2514 - Test score: -0.0231\n",
      "Epoch 7/300 - Train loss: 0.2470 - Test loss: 0.2515 - Test score: -0.0283\n",
      "Epoch 8/300 - Train loss: 0.2464 - Test loss: 0.2515 - Test score: -0.0326\n",
      "Epoch 9/300 - Train loss: 0.2459 - Test loss: 0.2516 - Test score: -0.0353\n",
      "Epoch 10/300 - Train loss: 0.2456 - Test loss: 0.2518 - Test score: -0.0353\n",
      "Epoch 11/300 - Train loss: 0.2451 - Test loss: 0.2518 - Test score: -0.0184\n",
      "\n",
      "Layer 5 - Score: -0.0017\n",
      "Epoch 1/300 - Train loss: 0.2508 - Test loss: 0.2510 - Test score: -0.0145\n",
      "Epoch 2/300 - Train loss: 0.2497 - Test loss: 0.2510 - Test score: -0.0230\n",
      "Epoch 3/300 - Train loss: 0.2489 - Test loss: 0.2511 - Test score: -0.0155\n",
      "Epoch 4/300 - Train loss: 0.2484 - Test loss: 0.2513 - Test score: -0.0064\n",
      "Epoch 5/300 - Train loss: 0.2477 - Test loss: 0.2514 - Test score: -0.0244\n",
      "Epoch 6/300 - Train loss: 0.2472 - Test loss: 0.2517 - Test score: -0.0179\n",
      "Epoch 7/300 - Train loss: 0.2468 - Test loss: 0.2518 - Test score: -0.0293\n",
      "Epoch 8/300 - Train loss: 0.2463 - Test loss: 0.2519 - Test score: -0.0179\n",
      "Epoch 9/300 - Train loss: 0.2459 - Test loss: 0.2519 - Test score: -0.0133\n",
      "Epoch 10/300 - Train loss: 0.2456 - Test loss: 0.2520 - Test score: -0.0156\n",
      "Epoch 11/300 - Train loss: 0.2450 - Test loss: 0.2520 - Test score: 0.0036\n",
      "Epoch 12/300 - Train loss: 0.2447 - Test loss: 0.2521 - Test score: -0.0093\n",
      "Epoch 13/300 - Train loss: 0.2442 - Test loss: 0.2522 - Test score: -0.0083\n",
      "Epoch 14/300 - Train loss: 0.2437 - Test loss: 0.2524 - Test score: -0.0198\n",
      "Epoch 15/300 - Train loss: 0.2436 - Test loss: 0.2526 - Test score: -0.0146\n",
      "Epoch 16/300 - Train loss: 0.2432 - Test loss: 0.2526 - Test score: -0.0208\n",
      "Epoch 17/300 - Train loss: 0.2429 - Test loss: 0.2527 - Test score: -0.0096\n",
      "Epoch 18/300 - Train loss: 0.2423 - Test loss: 0.2529 - Test score: -0.0145\n",
      "Epoch 19/300 - Train loss: 0.2424 - Test loss: 0.2529 - Test score: -0.0081\n",
      "Epoch 20/300 - Train loss: 0.2420 - Test loss: 0.2529 - Test score: 0.0023\n",
      "Epoch 21/300 - Train loss: 0.2417 - Test loss: 0.2529 - Test score: 0.0010\n",
      "\n",
      "Layer 6 - Score: 0.0036\n",
      "Epoch 1/300 - Train loss: 0.2780 - Test loss: 0.2771 - Test score: 0.0067\n",
      "Epoch 2/300 - Train loss: 0.2679 - Test loss: 0.2754 - Test score: 0.0008\n",
      "Epoch 3/300 - Train loss: 0.2642 - Test loss: 0.2651 - Test score: -0.0391\n",
      "Epoch 4/300 - Train loss: 0.2616 - Test loss: 0.2637 - Test score: -0.0168\n",
      "Epoch 5/300 - Train loss: 0.2596 - Test loss: 0.2625 - Test score: -0.0220\n",
      "Epoch 6/300 - Train loss: 0.2597 - Test loss: 0.2618 - Test score: -0.0192\n",
      "Epoch 7/300 - Train loss: 0.2586 - Test loss: 0.2614 - Test score: -0.0309\n",
      "Epoch 8/300 - Train loss: 0.2584 - Test loss: 0.2626 - Test score: -0.0238\n",
      "Epoch 9/300 - Train loss: 0.2583 - Test loss: 0.2604 - Test score: -0.0335\n",
      "Epoch 10/300 - Train loss: 0.2576 - Test loss: 0.2595 - Test score: -0.0309\n",
      "Epoch 11/300 - Train loss: 0.2561 - Test loss: 0.2598 - Test score: -0.0218\n",
      "\n",
      "Layer 7 - Score: 0.0067\n",
      "Epoch 1/300 - Train loss: 0.2510 - Test loss: 0.2515 - Test score: -0.0145\n",
      "Epoch 2/300 - Train loss: 0.2505 - Test loss: 0.2518 - Test score: -0.0167\n",
      "Epoch 3/300 - Train loss: 0.2502 - Test loss: 0.2518 - Test score: -0.0259\n",
      "Epoch 4/300 - Train loss: 0.2501 - Test loss: 0.2518 - Test score: -0.0109\n",
      "Epoch 5/300 - Train loss: 0.2501 - Test loss: 0.2518 - Test score: -0.0542\n",
      "Epoch 6/300 - Train loss: 0.2498 - Test loss: 0.2519 - Test score: -0.0354\n",
      "Epoch 7/300 - Train loss: 0.2498 - Test loss: 0.2518 - Test score: -0.0490\n",
      "Epoch 8/300 - Train loss: 0.2498 - Test loss: 0.2519 - Test score: -0.0162\n",
      "Epoch 9/300 - Train loss: 0.2495 - Test loss: 0.2518 - Test score: -0.0324\n",
      "Epoch 10/300 - Train loss: 0.2495 - Test loss: 0.2518 - Test score: -0.0204\n",
      "Epoch 11/300 - Train loss: 0.2495 - Test loss: 0.2518 - Test score: -0.0070\n",
      "Epoch 12/300 - Train loss: 0.2493 - Test loss: 0.2518 - Test score: -0.0145\n",
      "Epoch 13/300 - Train loss: 0.2495 - Test loss: 0.2517 - Test score: -0.0204\n",
      "Epoch 14/300 - Train loss: 0.2492 - Test loss: 0.2517 - Test score: -0.0192\n",
      "Epoch 15/300 - Train loss: 0.2492 - Test loss: 0.2516 - Test score: -0.0106\n",
      "Epoch 16/300 - Train loss: 0.2492 - Test loss: 0.2516 - Test score: -0.0143\n",
      "Epoch 17/300 - Train loss: 0.2491 - Test loss: 0.2517 - Test score: 0.0008\n",
      "Epoch 18/300 - Train loss: 0.2489 - Test loss: 0.2516 - Test score: -0.0145\n",
      "Epoch 19/300 - Train loss: 0.2490 - Test loss: 0.2516 - Test score: -0.0175\n",
      "Epoch 20/300 - Train loss: 0.2489 - Test loss: 0.2516 - Test score: -0.0031\n",
      "Epoch 21/300 - Train loss: 0.2490 - Test loss: 0.2515 - Test score: -0.0015\n",
      "Epoch 22/300 - Train loss: 0.2488 - Test loss: 0.2516 - Test score: -0.0194\n",
      "Epoch 23/300 - Train loss: 0.2489 - Test loss: 0.2516 - Test score: -0.0269\n",
      "Epoch 24/300 - Train loss: 0.2487 - Test loss: 0.2516 - Test score: -0.0065\n",
      "Epoch 25/300 - Train loss: 0.2487 - Test loss: 0.2516 - Test score: -0.0015\n",
      "Epoch 26/300 - Train loss: 0.2488 - Test loss: 0.2515 - Test score: -0.0217\n",
      "Epoch 27/300 - Train loss: 0.2484 - Test loss: 0.2515 - Test score: -0.0026\n",
      "\n",
      "Layer 8 - Score: 0.0008\n",
      "Epoch 1/300 - Train loss: 0.2567 - Test loss: 0.2548 - Test score: -0.0143\n",
      "Epoch 2/300 - Train loss: 0.2516 - Test loss: 0.2508 - Test score: 0.0103\n",
      "Epoch 3/300 - Train loss: 0.2539 - Test loss: 0.2511 - Test score: 0.0013\n",
      "Epoch 4/300 - Train loss: 0.2504 - Test loss: 0.2567 - Test score: -0.0143\n",
      "Epoch 5/300 - Train loss: 0.2515 - Test loss: 0.2553 - Test score: -0.0039\n",
      "Epoch 6/300 - Train loss: 0.2492 - Test loss: 0.2586 - Test score: 0.0195\n",
      "Epoch 7/300 - Train loss: 0.2517 - Test loss: 0.2513 - Test score: -0.0149\n",
      "Epoch 8/300 - Train loss: 0.2501 - Test loss: 0.2519 - Test score: -0.0246\n",
      "Epoch 9/300 - Train loss: 0.2507 - Test loss: 0.2849 - Test score: 0.0195\n",
      "Epoch 10/300 - Train loss: 0.2495 - Test loss: 0.2682 - Test score: -0.0169\n",
      "Epoch 11/300 - Train loss: 0.2499 - Test loss: 0.2550 - Test score: -0.0263\n",
      "Epoch 12/300 - Train loss: 0.2444 - Test loss: 0.2574 - Test score: 0.0025\n",
      "Epoch 13/300 - Train loss: 0.2486 - Test loss: 0.2525 - Test score: -0.0075\n",
      "Epoch 14/300 - Train loss: 0.2456 - Test loss: 0.2614 - Test score: -0.0104\n",
      "Epoch 15/300 - Train loss: 0.2491 - Test loss: 0.2520 - Test score: -0.0229\n",
      "Epoch 16/300 - Train loss: 0.2447 - Test loss: 0.2548 - Test score: -0.0136\n",
      "\n",
      "Layer obs - Score: 0.0195\n",
      "Average score over all layers: 0.0057\n",
      "all lives (b)\n",
      "Layer 0 - Score: 0.9972\n",
      "Layer 1 - Score: 0.9886\n",
      "Layer 2 - Score: 1.0000\n",
      "Layer 3 - Score: 0.9886\n",
      "Layer 4 - Score: 1.0000\n",
      "Layer 5 - Score: 0.9972\n",
      "Layer 6 - Score: 0.9943\n",
      "Layer 7 - Score: 0.9830\n",
      "Layer 8 - Score: 0.4858\n",
      "Layer obs - Score: 0.9972\n",
      "Average score over all layers: 0.9432\n",
      "last life (b)\n",
      "Layer 0 - Score: 0.9965\n",
      "Layer 1 - Score: 0.9931\n",
      "Layer 2 - Score: 0.9931\n",
      "Layer 3 - Score: 0.9931\n",
      "Layer 4 - Score: 0.9931\n",
      "Layer 5 - Score: 0.9896\n",
      "Layer 6 - Score: 0.9861\n",
      "Layer 7 - Score: 0.9931\n",
      "Layer 8 - Score: 0.9028\n",
      "Layer obs - Score: 0.9931\n",
      "Average score over all layers: 0.9833\n",
      "reward (b)\n",
      "Layer 0 - Score: 0.6277\n",
      "Layer 1 - Score: 0.7214\n",
      "Layer 2 - Score: 0.7964\n",
      "Layer 3 - Score: 0.8464\n",
      "Layer 4 - Score: 0.8777\n",
      "Layer 5 - Score: 0.8714\n",
      "Layer 6 - Score: 0.8777\n",
      "Layer 7 - Score: 0.8652\n",
      "Layer 8 - Score: 0.5893\n",
      "Layer obs - Score: 0.4616\n",
      "Average score over all layers: 0.7535\n",
      "ball collision (b)\n",
      "Layer 0 - Score: 0.7462\n",
      "Layer 1 - Score: 0.7648\n",
      "Layer 2 - Score: 0.7553\n",
      "Layer 3 - Score: 0.7320\n",
      "Layer 4 - Score: 0.7733\n",
      "Layer 5 - Score: 0.7811\n",
      "Layer 6 - Score: 0.7778\n",
      "Layer 7 - Score: 0.5907\n",
      "Layer 8 - Score: 0.3675\n",
      "Layer obs - Score: 0.7804\n",
      "Average score over all layers: 0.7069\n",
      "ball low (b)\n",
      "Layer 0 - Score: 0.9680\n",
      "Layer 1 - Score: 0.9598\n",
      "Layer 2 - Score: 0.9696\n",
      "Layer 3 - Score: 0.9647\n",
      "Layer 4 - Score: 0.9680\n",
      "Layer 5 - Score: 0.9581\n",
      "Layer 6 - Score: 0.9598\n",
      "Layer 7 - Score: 0.9104\n",
      "Layer 8 - Score: 0.6516\n",
      "Layer obs - Score: 0.9385\n",
      "Average score over all layers: 0.9248\n",
      "ball left paddle (b)\n",
      "Layer 0 - Score: 0.6766\n",
      "Layer 1 - Score: 0.7151\n",
      "Layer 2 - Score: 0.7193\n",
      "Layer 3 - Score: 0.7469\n",
      "Layer 4 - Score: 0.7484\n",
      "Layer 5 - Score: 0.7453\n",
      "Layer 6 - Score: 0.7406\n",
      "Layer 7 - Score: 0.6922\n",
      "Layer 8 - Score: 0.4693\n",
      "Layer obs - Score: 0.7042\n",
      "Average score over all layers: 0.6958\n",
      "ball right paddle (b)\n",
      "Layer 0 - Score: 0.6528\n",
      "Layer 1 - Score: 0.7246\n",
      "Layer 2 - Score: 0.7636\n",
      "Layer 3 - Score: 0.7740\n",
      "Layer 4 - Score: 0.8014\n",
      "Layer 5 - Score: 0.7690\n",
      "Layer 6 - Score: 0.8167\n",
      "Layer 7 - Score: 0.7335\n",
      "Layer 8 - Score: 0.4613\n",
      "Layer obs - Score: 0.6578\n",
      "Average score over all layers: 0.7155\n",
      "ball same x paddle (b)\n",
      "Layer 0 - Score: 0.3948\n",
      "Layer 1 - Score: 0.4010\n",
      "Layer 2 - Score: 0.4693\n",
      "Layer 3 - Score: 0.4906\n",
      "Layer 4 - Score: 0.5193\n",
      "Layer 5 - Score: 0.4724\n",
      "Layer 6 - Score: 0.4589\n",
      "Layer 7 - Score: 0.4042\n",
      "Epoch 1/300 - Train loss: 0.2583 - Test loss: 0.2565 - Test score: -0.0427\n",
      "Epoch 2/300 - Train loss: 0.2533 - Test loss: 0.2535 - Test score: -0.0432\n",
      "Epoch 3/300 - Train loss: 0.2516 - Test loss: 0.2520 - Test score: -0.0557\n",
      "Epoch 4/300 - Train loss: 0.2504 - Test loss: 0.2507 - Test score: -0.0448\n",
      "Epoch 5/300 - Train loss: 0.2491 - Test loss: 0.2499 - Test score: -0.0328\n",
      "Epoch 6/300 - Train loss: 0.2481 - Test loss: 0.2487 - Test score: -0.0026\n",
      "Epoch 7/300 - Train loss: 0.2469 - Test loss: 0.2478 - Test score: 0.0052\n",
      "Epoch 8/300 - Train loss: 0.2460 - Test loss: 0.2470 - Test score: 0.0625\n",
      "Epoch 9/300 - Train loss: 0.2450 - Test loss: 0.2462 - Test score: 0.1042\n",
      "Epoch 10/300 - Train loss: 0.2440 - Test loss: 0.2454 - Test score: 0.1406\n",
      "Epoch 11/300 - Train loss: 0.2430 - Test loss: 0.2446 - Test score: 0.1854\n",
      "Epoch 12/300 - Train loss: 0.2421 - Test loss: 0.2438 - Test score: 0.2203\n",
      "Epoch 13/300 - Train loss: 0.2412 - Test loss: 0.2434 - Test score: 0.2010\n",
      "Epoch 14/300 - Train loss: 0.2403 - Test loss: 0.2427 - Test score: 0.1984\n",
      "Epoch 15/300 - Train loss: 0.2394 - Test loss: 0.2421 - Test score: 0.2115\n",
      "Epoch 16/300 - Train loss: 0.2389 - Test loss: 0.2414 - Test score: 0.2250\n",
      "Epoch 17/300 - Train loss: 0.2382 - Test loss: 0.2409 - Test score: 0.2432\n",
      "Epoch 18/300 - Train loss: 0.2375 - Test loss: 0.2404 - Test score: 0.2276\n",
      "Epoch 19/300 - Train loss: 0.2364 - Test loss: 0.2397 - Test score: 0.2589\n",
      "Epoch 20/300 - Train loss: 0.2360 - Test loss: 0.2391 - Test score: 0.2641\n",
      "Epoch 21/300 - Train loss: 0.2355 - Test loss: 0.2388 - Test score: 0.2328\n",
      "Epoch 22/300 - Train loss: 0.2350 - Test loss: 0.2381 - Test score: 0.2719\n",
      "Epoch 23/300 - Train loss: 0.2345 - Test loss: 0.2377 - Test score: 0.2615\n",
      "Epoch 24/300 - Train loss: 0.2335 - Test loss: 0.2373 - Test score: 0.2641\n",
      "Epoch 25/300 - Train loss: 0.2330 - Test loss: 0.2369 - Test score: 0.2667\n",
      "Epoch 26/300 - Train loss: 0.2326 - Test loss: 0.2365 - Test score: 0.2693\n",
      "Epoch 27/300 - Train loss: 0.2320 - Test loss: 0.2361 - Test score: 0.2641\n",
      "Epoch 28/300 - Train loss: 0.2311 - Test loss: 0.2358 - Test score: 0.2589\n",
      "Epoch 29/300 - Train loss: 0.2313 - Test loss: 0.2352 - Test score: 0.2875\n",
      "Epoch 30/300 - Train loss: 0.2303 - Test loss: 0.2351 - Test score: 0.2536\n",
      "Epoch 31/300 - Train loss: 0.2301 - Test loss: 0.2347 - Test score: 0.2563\n",
      "Epoch 32/300 - Train loss: 0.2300 - Test loss: 0.2342 - Test score: 0.2849\n",
      "Epoch 33/300 - Train loss: 0.2290 - Test loss: 0.2339 - Test score: 0.2693\n",
      "Epoch 34/300 - Train loss: 0.2285 - Test loss: 0.2336 - Test score: 0.2771\n",
      "Epoch 35/300 - Train loss: 0.2282 - Test loss: 0.2332 - Test score: 0.2823\n",
      "Epoch 36/300 - Train loss: 0.2279 - Test loss: 0.2329 - Test score: 0.2797\n",
      "Epoch 37/300 - Train loss: 0.2275 - Test loss: 0.2326 - Test score: 0.2745\n",
      "Epoch 38/300 - Train loss: 0.2274 - Test loss: 0.2321 - Test score: 0.2823\n",
      "Epoch 39/300 - Train loss: 0.2267 - Test loss: 0.2320 - Test score: 0.2797\n",
      "\n",
      "Layer 8 - Score: 0.2875\n",
      "Layer obs - Score: 0.3760\n",
      "Average score over all layers: 0.4274\n",
      "ball distance paddle\n",
      "Layer 0 - Score: 0.8433\n",
      "Layer 1 - Score: 0.8812\n",
      "Layer 2 - Score: 0.8702\n",
      "Layer 3 - Score: 0.8981\n",
      "Layer 4 - Score: 0.8781\n",
      "Layer 5 - Score: 0.9119\n",
      "Layer 6 - Score: 0.9125\n",
      "Layer 7 - Score: 0.8277\n",
      "Layer 8 - Score: 0.6214\n",
      "Layer obs - Score: 0.8361\n",
      "Average score over all layers: 0.8481\n",
      "ball y\n",
      "Layer 0 - Score: 0.8532\n",
      "Layer 1 - Score: 0.9218\n",
      "Layer 2 - Score: 0.9052\n",
      "Layer 3 - Score: 0.9159\n",
      "Layer 4 - Score: 0.9042\n",
      "Layer 5 - Score: 0.9064\n",
      "Layer 6 - Score: 0.9061\n",
      "Layer 7 - Score: 0.8368\n",
      "Layer 8 - Score: 0.5513\n",
      "Layer obs - Score: 0.8417\n",
      "Average score over all layers: 0.8543\n",
      "ball y next\n",
      "Layer 0 - Score: 0.8058\n",
      "Layer 1 - Score: 0.8963\n",
      "Layer 2 - Score: 0.8868\n",
      "Layer 3 - Score: 0.9008\n",
      "Layer 4 - Score: 0.8921\n",
      "Layer 5 - Score: 0.9001\n",
      "Layer 6 - Score: 0.9007\n",
      "Layer 7 - Score: 0.8155\n",
      "Layer 8 - Score: 0.4831\n",
      "Layer obs - Score: 0.7939\n",
      "Average score over all layers: 0.8275\n",
      "ball x\n",
      "Layer 0 - Score: 0.8931\n",
      "Layer 1 - Score: 0.9412\n",
      "Layer 2 - Score: 0.9351\n",
      "Layer 3 - Score: 0.9415\n",
      "Layer 4 - Score: 0.9308\n",
      "Layer 5 - Score: 0.9278\n",
      "Layer 6 - Score: 0.9279\n",
      "Layer 7 - Score: 0.8477\n",
      "Layer 8 - Score: 0.4343\n",
      "Layer obs - Score: 0.8934\n",
      "Average score over all layers: 0.8673\n",
      "ball x next\n",
      "Layer 0 - Score: 0.8414\n",
      "Layer 1 - Score: 0.9098\n",
      "Layer 2 - Score: 0.9003\n",
      "Layer 3 - Score: 0.9299\n",
      "Layer 4 - Score: 0.9114\n",
      "Layer 5 - Score: 0.9034\n",
      "Layer 6 - Score: 0.9038\n",
      "Layer 7 - Score: 0.8201\n",
      "Layer 8 - Score: 0.4350\n",
      "Layer obs - Score: 0.8300\n",
      "Average score over all layers: 0.8385\n",
      "lives\n",
      "Layer 0 - Score: 0.9996\n",
      "Layer 1 - Score: 1.0000\n",
      "Layer 2 - Score: 0.9994\n",
      "Layer 3 - Score: 0.9996\n",
      "Layer 4 - Score: 0.9970\n",
      "Layer 5 - Score: 0.9962\n",
      "Layer 6 - Score: 0.9963\n",
      "Layer 7 - Score: 0.9671\n",
      "Layer 8 - Score: 0.6333\n",
      "Layer obs - Score: 0.9995\n",
      "Average score over all layers: 0.9588\n",
      "x diff\n",
      "Layer 0 - Score: 0.4590\n",
      "Layer 1 - Score: 0.5192\n",
      "Layer 2 - Score: 0.5043\n",
      "Layer 3 - Score: 0.6102\n",
      "Layer 4 - Score: 0.5554\n",
      "Layer 5 - Score: 0.7092\n",
      "Layer 6 - Score: 0.7103\n",
      "Layer 7 - Score: 0.5008\n",
      "Epoch 1/300 - Train loss: 1.9324 - Test loss: 1.2924 - Test score: -0.4149\n",
      "Epoch 2/300 - Train loss: 1.2599 - Test loss: 1.0427 - Test score: -0.1429\n",
      "Epoch 3/300 - Train loss: 1.0962 - Test loss: 0.9658 - Test score: -0.0617\n",
      "Epoch 4/300 - Train loss: 1.0317 - Test loss: 0.9278 - Test score: -0.0211\n",
      "Epoch 5/300 - Train loss: 0.9965 - Test loss: 0.9070 - Test score: 0.0010\n",
      "Epoch 6/300 - Train loss: 0.9753 - Test loss: 0.8926 - Test score: 0.0171\n",
      "Epoch 7/300 - Train loss: 0.9588 - Test loss: 0.8830 - Test score: 0.0269\n",
      "Epoch 8/300 - Train loss: 0.9475 - Test loss: 0.8729 - Test score: 0.0388\n",
      "Epoch 9/300 - Train loss: 0.9341 - Test loss: 0.8651 - Test score: 0.0471\n",
      "Epoch 10/300 - Train loss: 0.9257 - Test loss: 0.8557 - Test score: 0.0588\n",
      "Epoch 11/300 - Train loss: 0.9142 - Test loss: 0.8481 - Test score: 0.0674\n",
      "Epoch 12/300 - Train loss: 0.9082 - Test loss: 0.8415 - Test score: 0.0747\n",
      "Epoch 13/300 - Train loss: 0.8972 - Test loss: 0.8354 - Test score: 0.0813\n",
      "Epoch 14/300 - Train loss: 0.8902 - Test loss: 0.8284 - Test score: 0.0896\n",
      "Epoch 15/300 - Train loss: 0.8818 - Test loss: 0.8222 - Test score: 0.0969\n",
      "Epoch 16/300 - Train loss: 0.8749 - Test loss: 0.8176 - Test score: 0.1016\n",
      "Epoch 17/300 - Train loss: 0.8672 - Test loss: 0.8120 - Test score: 0.1082\n",
      "Epoch 18/300 - Train loss: 0.8606 - Test loss: 0.8078 - Test score: 0.1127\n",
      "Epoch 19/300 - Train loss: 0.8533 - Test loss: 0.8031 - Test score: 0.1181\n",
      "Epoch 20/300 - Train loss: 0.8487 - Test loss: 0.7983 - Test score: 0.1237\n",
      "Epoch 21/300 - Train loss: 0.8417 - Test loss: 0.7928 - Test score: 0.1309\n",
      "Epoch 22/300 - Train loss: 0.8364 - Test loss: 0.7900 - Test score: 0.1333\n",
      "Epoch 23/300 - Train loss: 0.8319 - Test loss: 0.7868 - Test score: 0.1367\n",
      "Epoch 24/300 - Train loss: 0.8276 - Test loss: 0.7811 - Test score: 0.1448\n",
      "Epoch 25/300 - Train loss: 0.8234 - Test loss: 0.7779 - Test score: 0.1483\n",
      "Epoch 26/300 - Train loss: 0.8169 - Test loss: 0.7752 - Test score: 0.1509\n",
      "Epoch 27/300 - Train loss: 0.8139 - Test loss: 0.7744 - Test score: 0.1507\n",
      "Epoch 28/300 - Train loss: 0.8094 - Test loss: 0.7693 - Test score: 0.1576\n",
      "Epoch 29/300 - Train loss: 0.8049 - Test loss: 0.7680 - Test score: 0.1583\n",
      "Epoch 30/300 - Train loss: 0.8022 - Test loss: 0.7637 - Test score: 0.1647\n",
      "Epoch 31/300 - Train loss: 0.7980 - Test loss: 0.7626 - Test score: 0.1648\n",
      "Epoch 32/300 - Train loss: 0.7966 - Test loss: 0.7588 - Test score: 0.1704\n",
      "Epoch 33/300 - Train loss: 0.7921 - Test loss: 0.7575 - Test score: 0.1710\n",
      "Epoch 34/300 - Train loss: 0.7889 - Test loss: 0.7547 - Test score: 0.1749\n",
      "Epoch 35/300 - Train loss: 0.7856 - Test loss: 0.7528 - Test score: 0.1770\n",
      "Epoch 36/300 - Train loss: 0.7834 - Test loss: 0.7511 - Test score: 0.1787\n",
      "Epoch 37/300 - Train loss: 0.7795 - Test loss: 0.7500 - Test score: 0.1794\n",
      "Epoch 38/300 - Train loss: 0.7779 - Test loss: 0.7481 - Test score: 0.1818\n",
      "Epoch 39/300 - Train loss: 0.7762 - Test loss: 0.7463 - Test score: 0.1841\n",
      "Epoch 40/300 - Train loss: 0.7738 - Test loss: 0.7450 - Test score: 0.1853\n",
      "Epoch 41/300 - Train loss: 0.7718 - Test loss: 0.7447 - Test score: 0.1850\n",
      "Epoch 42/300 - Train loss: 0.7686 - Test loss: 0.7420 - Test score: 0.1890\n",
      "Epoch 43/300 - Train loss: 0.7667 - Test loss: 0.7408 - Test score: 0.1902\n",
      "Epoch 44/300 - Train loss: 0.7647 - Test loss: 0.7394 - Test score: 0.1929\n",
      "Epoch 45/300 - Train loss: 0.7624 - Test loss: 0.7400 - Test score: 0.1901\n",
      "Epoch 46/300 - Train loss: 0.7631 - Test loss: 0.7370 - Test score: 0.1946\n",
      "Epoch 47/300 - Train loss: 0.7596 - Test loss: 0.7362 - Test score: 0.1953\n",
      "Epoch 48/300 - Train loss: 0.7571 - Test loss: 0.7365 - Test score: 0.1942\n",
      "Epoch 49/300 - Train loss: 0.7562 - Test loss: 0.7344 - Test score: 0.1972\n",
      "Epoch 50/300 - Train loss: 0.7528 - Test loss: 0.7330 - Test score: 0.1991\n",
      "Epoch 51/300 - Train loss: 0.7536 - Test loss: 0.7320 - Test score: 0.2005\n",
      "Epoch 52/300 - Train loss: 0.7509 - Test loss: 0.7313 - Test score: 0.2020\n",
      "Epoch 53/300 - Train loss: 0.7534 - Test loss: 0.7304 - Test score: 0.2022\n",
      "Epoch 54/300 - Train loss: 0.7475 - Test loss: 0.7316 - Test score: 0.1995\n",
      "Epoch 55/300 - Train loss: 0.7485 - Test loss: 0.7292 - Test score: 0.2045\n",
      "Epoch 56/300 - Train loss: 0.7469 - Test loss: 0.7286 - Test score: 0.2035\n",
      "Epoch 57/300 - Train loss: 0.7440 - Test loss: 0.7296 - Test score: 0.2016\n",
      "Epoch 58/300 - Train loss: 0.7438 - Test loss: 0.7286 - Test score: 0.2028\n",
      "Epoch 59/300 - Train loss: 0.7436 - Test loss: 0.7269 - Test score: 0.2053\n",
      "Epoch 60/300 - Train loss: 0.7413 - Test loss: 0.7255 - Test score: 0.2084\n",
      "Epoch 61/300 - Train loss: 0.7402 - Test loss: 0.7264 - Test score: 0.2055\n",
      "Epoch 62/300 - Train loss: 0.7395 - Test loss: 0.7245 - Test score: 0.2085\n",
      "Epoch 63/300 - Train loss: 0.7379 - Test loss: 0.7265 - Test score: 0.2048\n",
      "Epoch 64/300 - Train loss: 0.7403 - Test loss: 0.7230 - Test score: 0.2106\n",
      "Epoch 65/300 - Train loss: 0.7369 - Test loss: 0.7228 - Test score: 0.2105\n",
      "Epoch 66/300 - Train loss: 0.7370 - Test loss: 0.7223 - Test score: 0.2110\n",
      "Epoch 67/300 - Train loss: 0.7349 - Test loss: 0.7223 - Test score: 0.2104\n",
      "Epoch 68/300 - Train loss: 0.7345 - Test loss: 0.7217 - Test score: 0.2112\n",
      "Epoch 69/300 - Train loss: 0.7338 - Test loss: 0.7207 - Test score: 0.2129\n",
      "Epoch 70/300 - Train loss: 0.7325 - Test loss: 0.7214 - Test score: 0.2111\n",
      "Epoch 71/300 - Train loss: 0.7311 - Test loss: 0.7199 - Test score: 0.2135\n",
      "Epoch 72/300 - Train loss: 0.7305 - Test loss: 0.7197 - Test score: 0.2135\n",
      "Epoch 73/300 - Train loss: 0.7304 - Test loss: 0.7189 - Test score: 0.2148\n",
      "Epoch 74/300 - Train loss: 0.7296 - Test loss: 0.7195 - Test score: 0.2132\n",
      "Epoch 75/300 - Train loss: 0.7293 - Test loss: 0.7187 - Test score: 0.2143\n",
      "Epoch 76/300 - Train loss: 0.7290 - Test loss: 0.7181 - Test score: 0.2152\n",
      "Epoch 77/300 - Train loss: 0.7302 - Test loss: 0.7176 - Test score: 0.2157\n",
      "Epoch 78/300 - Train loss: 0.7284 - Test loss: 0.7174 - Test score: 0.2171\n",
      "Epoch 79/300 - Train loss: 0.7257 - Test loss: 0.7176 - Test score: 0.2152\n",
      "Epoch 80/300 - Train loss: 0.7260 - Test loss: 0.7163 - Test score: 0.2174\n",
      "Epoch 81/300 - Train loss: 0.7264 - Test loss: 0.7167 - Test score: 0.2165\n",
      "Epoch 82/300 - Train loss: 0.7253 - Test loss: 0.7157 - Test score: 0.2185\n",
      "Epoch 83/300 - Train loss: 0.7260 - Test loss: 0.7155 - Test score: 0.2182\n",
      "Epoch 84/300 - Train loss: 0.7234 - Test loss: 0.7156 - Test score: 0.2177\n",
      "Epoch 85/300 - Train loss: 0.7238 - Test loss: 0.7153 - Test score: 0.2180\n",
      "Epoch 86/300 - Train loss: 0.7231 - Test loss: 0.7145 - Test score: 0.2201\n",
      "Epoch 87/300 - Train loss: 0.7219 - Test loss: 0.7143 - Test score: 0.2195\n",
      "Epoch 88/300 - Train loss: 0.7220 - Test loss: 0.7139 - Test score: 0.2202\n",
      "Epoch 89/300 - Train loss: 0.7208 - Test loss: 0.7141 - Test score: 0.2209\n",
      "Epoch 90/300 - Train loss: 0.7200 - Test loss: 0.7133 - Test score: 0.2206\n",
      "Epoch 91/300 - Train loss: 0.7208 - Test loss: 0.7134 - Test score: 0.2201\n",
      "Epoch 92/300 - Train loss: 0.7195 - Test loss: 0.7131 - Test score: 0.2206\n",
      "Epoch 93/300 - Train loss: 0.7197 - Test loss: 0.7127 - Test score: 0.2219\n",
      "Epoch 94/300 - Train loss: 0.7198 - Test loss: 0.7129 - Test score: 0.2205\n",
      "Epoch 95/300 - Train loss: 0.7182 - Test loss: 0.7136 - Test score: 0.2192\n",
      "Epoch 96/300 - Train loss: 0.7181 - Test loss: 0.7124 - Test score: 0.2209\n",
      "Epoch 97/300 - Train loss: 0.7182 - Test loss: 0.7115 - Test score: 0.2225\n",
      "Epoch 98/300 - Train loss: 0.7180 - Test loss: 0.7113 - Test score: 0.2231\n",
      "Epoch 99/300 - Train loss: 0.7164 - Test loss: 0.7116 - Test score: 0.2220\n",
      "Epoch 100/300 - Train loss: 0.7177 - Test loss: 0.7127 - Test score: 0.2200\n",
      "Epoch 101/300 - Train loss: 0.7167 - Test loss: 0.7107 - Test score: 0.2234\n",
      "Epoch 102/300 - Train loss: 0.7156 - Test loss: 0.7104 - Test score: 0.2239\n",
      "Epoch 103/300 - Train loss: 0.7171 - Test loss: 0.7109 - Test score: 0.2244\n",
      "Epoch 104/300 - Train loss: 0.7180 - Test loss: 0.7108 - Test score: 0.2225\n",
      "Epoch 105/300 - Train loss: 0.7149 - Test loss: 0.7099 - Test score: 0.2247\n",
      "Epoch 106/300 - Train loss: 0.7143 - Test loss: 0.7107 - Test score: 0.2224\n",
      "Epoch 107/300 - Train loss: 0.7144 - Test loss: 0.7117 - Test score: 0.2206\n",
      "Epoch 108/300 - Train loss: 0.7124 - Test loss: 0.7103 - Test score: 0.2251\n",
      "Epoch 109/300 - Train loss: 0.7160 - Test loss: 0.7090 - Test score: 0.2253\n",
      "Epoch 110/300 - Train loss: 0.7124 - Test loss: 0.7098 - Test score: 0.2235\n",
      "Epoch 111/300 - Train loss: 0.7155 - Test loss: 0.7123 - Test score: 0.2195\n",
      "Epoch 112/300 - Train loss: 0.7145 - Test loss: 0.7088 - Test score: 0.2260\n",
      "Epoch 113/300 - Train loss: 0.7133 - Test loss: 0.7085 - Test score: 0.2255\n",
      "Epoch 114/300 - Train loss: 0.7125 - Test loss: 0.7081 - Test score: 0.2263\n",
      "Epoch 115/300 - Train loss: 0.7118 - Test loss: 0.7081 - Test score: 0.2261\n",
      "Epoch 116/300 - Train loss: 0.7109 - Test loss: 0.7084 - Test score: 0.2252\n",
      "Epoch 117/300 - Train loss: 0.7108 - Test loss: 0.7085 - Test score: 0.2268\n",
      "Epoch 118/300 - Train loss: 0.7112 - Test loss: 0.7108 - Test score: 0.2212\n",
      "Epoch 119/300 - Train loss: 0.7108 - Test loss: 0.7073 - Test score: 0.2268\n",
      "Epoch 120/300 - Train loss: 0.7112 - Test loss: 0.7072 - Test score: 0.2272\n",
      "Epoch 121/300 - Train loss: 0.7098 - Test loss: 0.7071 - Test score: 0.2271\n",
      "Epoch 122/300 - Train loss: 0.7099 - Test loss: 0.7070 - Test score: 0.2270\n",
      "Epoch 123/300 - Train loss: 0.7092 - Test loss: 0.7083 - Test score: 0.2245\n",
      "Epoch 124/300 - Train loss: 0.7104 - Test loss: 0.7072 - Test score: 0.2264\n",
      "Epoch 125/300 - Train loss: 0.7090 - Test loss: 0.7066 - Test score: 0.2273\n",
      "Epoch 126/300 - Train loss: 0.7081 - Test loss: 0.7062 - Test score: 0.2287\n",
      "Epoch 127/300 - Train loss: 0.7086 - Test loss: 0.7064 - Test score: 0.2288\n",
      "Epoch 128/300 - Train loss: 0.7086 - Test loss: 0.7059 - Test score: 0.2286\n",
      "Epoch 129/300 - Train loss: 0.7084 - Test loss: 0.7058 - Test score: 0.2287\n",
      "Epoch 130/300 - Train loss: 0.7082 - Test loss: 0.7058 - Test score: 0.2286\n",
      "Epoch 131/300 - Train loss: 0.7088 - Test loss: 0.7056 - Test score: 0.2289\n",
      "Epoch 132/300 - Train loss: 0.7094 - Test loss: 0.7063 - Test score: 0.2271\n",
      "Epoch 133/300 - Train loss: 0.7071 - Test loss: 0.7053 - Test score: 0.2291\n",
      "Epoch 134/300 - Train loss: 0.7082 - Test loss: 0.7066 - Test score: 0.2289\n",
      "Epoch 135/300 - Train loss: 0.7088 - Test loss: 0.7054 - Test score: 0.2285\n",
      "Epoch 136/300 - Train loss: 0.7081 - Test loss: 0.7049 - Test score: 0.2300\n",
      "Epoch 137/300 - Train loss: 0.7064 - Test loss: 0.7049 - Test score: 0.2294\n",
      "Epoch 138/300 - Train loss: 0.7063 - Test loss: 0.7054 - Test score: 0.2283\n",
      "Epoch 139/300 - Train loss: 0.7049 - Test loss: 0.7046 - Test score: 0.2298\n",
      "Epoch 140/300 - Train loss: 0.7059 - Test loss: 0.7043 - Test score: 0.2305\n",
      "Epoch 141/300 - Train loss: 0.7063 - Test loss: 0.7044 - Test score: 0.2295\n",
      "Epoch 142/300 - Train loss: 0.7062 - Test loss: 0.7043 - Test score: 0.2304\n",
      "Epoch 143/300 - Train loss: 0.7070 - Test loss: 0.7040 - Test score: 0.2308\n",
      "Epoch 144/300 - Train loss: 0.7059 - Test loss: 0.7041 - Test score: 0.2299\n",
      "Epoch 145/300 - Train loss: 0.7046 - Test loss: 0.7042 - Test score: 0.2297\n",
      "Epoch 146/300 - Train loss: 0.7060 - Test loss: 0.7040 - Test score: 0.2302\n",
      "Epoch 147/300 - Train loss: 0.7044 - Test loss: 0.7038 - Test score: 0.2302\n",
      "Epoch 148/300 - Train loss: 0.7050 - Test loss: 0.7038 - Test score: 0.2300\n",
      "Epoch 149/300 - Train loss: 0.7041 - Test loss: 0.7048 - Test score: 0.2283\n",
      "Epoch 150/300 - Train loss: 0.7032 - Test loss: 0.7053 - Test score: 0.2274\n",
      "Epoch 151/300 - Train loss: 0.7047 - Test loss: 0.7033 - Test score: 0.2308\n",
      "Epoch 152/300 - Train loss: 0.7039 - Test loss: 0.7039 - Test score: 0.2296\n",
      "Epoch 153/300 - Train loss: 0.7036 - Test loss: 0.7031 - Test score: 0.2317\n",
      "Epoch 154/300 - Train loss: 0.7042 - Test loss: 0.7032 - Test score: 0.2308\n",
      "Epoch 155/300 - Train loss: 0.7031 - Test loss: 0.7034 - Test score: 0.2319\n",
      "Epoch 156/300 - Train loss: 0.7022 - Test loss: 0.7028 - Test score: 0.2316\n",
      "Epoch 157/300 - Train loss: 0.7047 - Test loss: 0.7037 - Test score: 0.2296\n",
      "Epoch 158/300 - Train loss: 0.7036 - Test loss: 0.7027 - Test score: 0.2315\n",
      "Epoch 159/300 - Train loss: 0.7025 - Test loss: 0.7024 - Test score: 0.2323\n",
      "Epoch 160/300 - Train loss: 0.7024 - Test loss: 0.7025 - Test score: 0.2316\n",
      "Epoch 161/300 - Train loss: 0.7026 - Test loss: 0.7026 - Test score: 0.2313\n",
      "Epoch 162/300 - Train loss: 0.7021 - Test loss: 0.7024 - Test score: 0.2324\n",
      "Epoch 163/300 - Train loss: 0.7048 - Test loss: 0.7022 - Test score: 0.2324\n",
      "Epoch 164/300 - Train loss: 0.7021 - Test loss: 0.7021 - Test score: 0.2320\n",
      "Epoch 165/300 - Train loss: 0.7021 - Test loss: 0.7019 - Test score: 0.2323\n",
      "Epoch 166/300 - Train loss: 0.7015 - Test loss: 0.7017 - Test score: 0.2327\n",
      "Epoch 167/300 - Train loss: 0.7016 - Test loss: 0.7017 - Test score: 0.2330\n",
      "Epoch 168/300 - Train loss: 0.7009 - Test loss: 0.7029 - Test score: 0.2326\n",
      "Epoch 169/300 - Train loss: 0.7014 - Test loss: 0.7016 - Test score: 0.2325\n",
      "Epoch 170/300 - Train loss: 0.7037 - Test loss: 0.7014 - Test score: 0.2331\n",
      "Epoch 171/300 - Train loss: 0.7015 - Test loss: 0.7012 - Test score: 0.2335\n",
      "Epoch 172/300 - Train loss: 0.7005 - Test loss: 0.7014 - Test score: 0.2334\n",
      "Epoch 173/300 - Train loss: 0.7008 - Test loss: 0.7014 - Test score: 0.2336\n",
      "Epoch 174/300 - Train loss: 0.7002 - Test loss: 0.7012 - Test score: 0.2339\n",
      "Epoch 175/300 - Train loss: 0.6998 - Test loss: 0.7019 - Test score: 0.2335\n",
      "Epoch 176/300 - Train loss: 0.7026 - Test loss: 0.7010 - Test score: 0.2335\n",
      "Epoch 177/300 - Train loss: 0.7011 - Test loss: 0.7010 - Test score: 0.2338\n",
      "Epoch 178/300 - Train loss: 0.7002 - Test loss: 0.7007 - Test score: 0.2336\n",
      "Epoch 179/300 - Train loss: 0.7004 - Test loss: 0.7007 - Test score: 0.2340\n",
      "Epoch 180/300 - Train loss: 0.7001 - Test loss: 0.7007 - Test score: 0.2339\n",
      "Epoch 181/300 - Train loss: 0.6999 - Test loss: 0.7005 - Test score: 0.2343\n",
      "Epoch 182/300 - Train loss: 0.6989 - Test loss: 0.7003 - Test score: 0.2341\n",
      "Epoch 183/300 - Train loss: 0.7000 - Test loss: 0.7004 - Test score: 0.2340\n",
      "Epoch 184/300 - Train loss: 0.6990 - Test loss: 0.7006 - Test score: 0.2341\n",
      "Epoch 185/300 - Train loss: 0.7000 - Test loss: 0.7001 - Test score: 0.2345\n",
      "Epoch 186/300 - Train loss: 0.7002 - Test loss: 0.7005 - Test score: 0.2346\n",
      "Epoch 187/300 - Train loss: 0.6994 - Test loss: 0.7003 - Test score: 0.2338\n",
      "Epoch 188/300 - Train loss: 0.6981 - Test loss: 0.7001 - Test score: 0.2341\n",
      "Epoch 189/300 - Train loss: 0.6994 - Test loss: 0.7003 - Test score: 0.2337\n",
      "Epoch 190/300 - Train loss: 0.6979 - Test loss: 0.7002 - Test score: 0.2340\n",
      "Epoch 191/300 - Train loss: 0.6997 - Test loss: 0.7003 - Test score: 0.2346\n",
      "Epoch 192/300 - Train loss: 0.6971 - Test loss: 0.6999 - Test score: 0.2348\n",
      "Epoch 193/300 - Train loss: 0.6995 - Test loss: 0.6999 - Test score: 0.2342\n",
      "Epoch 194/300 - Train loss: 0.6977 - Test loss: 0.7001 - Test score: 0.2339\n",
      "Epoch 195/300 - Train loss: 0.6979 - Test loss: 0.6996 - Test score: 0.2346\n",
      "Epoch 196/300 - Train loss: 0.6979 - Test loss: 0.6996 - Test score: 0.2349\n",
      "Epoch 197/300 - Train loss: 0.6984 - Test loss: 0.6994 - Test score: 0.2353\n",
      "Epoch 198/300 - Train loss: 0.6998 - Test loss: 0.6992 - Test score: 0.2356\n",
      "Epoch 199/300 - Train loss: 0.6971 - Test loss: 0.6999 - Test score: 0.2337\n",
      "Epoch 200/300 - Train loss: 0.6990 - Test loss: 0.6992 - Test score: 0.2352\n",
      "Epoch 201/300 - Train loss: 0.6978 - Test loss: 0.6994 - Test score: 0.2346\n",
      "Epoch 202/300 - Train loss: 0.6967 - Test loss: 0.7001 - Test score: 0.2353\n",
      "Epoch 203/300 - Train loss: 0.6977 - Test loss: 0.6996 - Test score: 0.2341\n",
      "Epoch 204/300 - Train loss: 0.6973 - Test loss: 0.6993 - Test score: 0.2360\n",
      "Epoch 205/300 - Train loss: 0.6977 - Test loss: 0.6994 - Test score: 0.2357\n",
      "Epoch 206/300 - Train loss: 0.6972 - Test loss: 0.6991 - Test score: 0.2357\n",
      "Epoch 207/300 - Train loss: 0.6963 - Test loss: 0.6993 - Test score: 0.2360\n",
      "Epoch 208/300 - Train loss: 0.6980 - Test loss: 0.6991 - Test score: 0.2348\n",
      "Epoch 209/300 - Train loss: 0.6958 - Test loss: 0.6993 - Test score: 0.2345\n",
      "Epoch 210/300 - Train loss: 0.6965 - Test loss: 0.6998 - Test score: 0.2335\n",
      "Epoch 211/300 - Train loss: 0.6967 - Test loss: 0.6987 - Test score: 0.2358\n",
      "Epoch 212/300 - Train loss: 0.6967 - Test loss: 0.6985 - Test score: 0.2358\n",
      "Epoch 213/300 - Train loss: 0.6968 - Test loss: 0.7000 - Test score: 0.2330\n",
      "Epoch 214/300 - Train loss: 0.6967 - Test loss: 0.7001 - Test score: 0.2328\n",
      "Epoch 215/300 - Train loss: 0.6952 - Test loss: 0.6989 - Test score: 0.2351\n",
      "Epoch 216/300 - Train loss: 0.6966 - Test loss: 0.6987 - Test score: 0.2355\n",
      "Epoch 217/300 - Train loss: 0.6963 - Test loss: 0.6988 - Test score: 0.2350\n",
      "\n",
      "Layer 8 - Score: 0.2360\n",
      "Layer obs - Score: 0.4677\n",
      "Average score over all layers: 0.5272\n",
      "frames until collision horizontal\n",
      "Epoch 1/300 - Train loss: 1.0046 - Test loss: 1.1084 - Test score: 0.0173\n",
      "Epoch 2/300 - Train loss: 0.9493 - Test loss: 1.0943 - Test score: 0.0307\n",
      "Epoch 3/300 - Train loss: 0.9295 - Test loss: 1.0582 - Test score: 0.0579\n",
      "Epoch 4/300 - Train loss: 0.9166 - Test loss: 1.0644 - Test score: 0.0571\n",
      "Epoch 5/300 - Train loss: 0.9134 - Test loss: 1.0507 - Test score: 0.0504\n",
      "Epoch 6/300 - Train loss: 0.9020 - Test loss: 1.0649 - Test score: 0.0256\n",
      "Epoch 7/300 - Train loss: 0.8730 - Test loss: 1.0263 - Test score: 0.0889\n",
      "Epoch 8/300 - Train loss: 0.8700 - Test loss: 1.0160 - Test score: 0.0955\n",
      "Epoch 9/300 - Train loss: 0.8634 - Test loss: 1.1182 - Test score: -0.0481\n",
      "Epoch 10/300 - Train loss: 0.8672 - Test loss: 1.0626 - Test score: 0.0225\n",
      "Epoch 11/300 - Train loss: 0.8572 - Test loss: 1.0026 - Test score: 0.1042\n",
      "Epoch 12/300 - Train loss: 0.8542 - Test loss: 1.1595 - Test score: -0.1058\n",
      "Epoch 13/300 - Train loss: 0.8427 - Test loss: 1.1210 - Test score: 0.0013\n",
      "Epoch 14/300 - Train loss: 0.8368 - Test loss: 0.9951 - Test score: 0.1220\n",
      "Epoch 15/300 - Train loss: 0.8170 - Test loss: 0.9846 - Test score: 0.1301\n",
      "Epoch 16/300 - Train loss: 0.8095 - Test loss: 1.1091 - Test score: -0.0449\n",
      "Epoch 17/300 - Train loss: 0.8172 - Test loss: 0.9883 - Test score: 0.1296\n",
      "Epoch 18/300 - Train loss: 0.7931 - Test loss: 0.9707 - Test score: 0.1415\n",
      "Epoch 19/300 - Train loss: 0.7955 - Test loss: 0.9717 - Test score: 0.1420\n",
      "Epoch 20/300 - Train loss: 0.8031 - Test loss: 1.1240 - Test score: -0.0673\n",
      "Epoch 21/300 - Train loss: 0.7940 - Test loss: 0.9600 - Test score: 0.1506\n",
      "Epoch 22/300 - Train loss: 0.7887 - Test loss: 0.9597 - Test score: 0.1501\n",
      "Epoch 23/300 - Train loss: 0.7836 - Test loss: 0.9746 - Test score: 0.1203\n",
      "Epoch 24/300 - Train loss: 0.7728 - Test loss: 0.9646 - Test score: 0.1521\n",
      "Epoch 25/300 - Train loss: 0.7649 - Test loss: 0.9505 - Test score: 0.1580\n",
      "Epoch 26/300 - Train loss: 0.7698 - Test loss: 0.9502 - Test score: 0.1633\n",
      "Epoch 27/300 - Train loss: 0.7878 - Test loss: 0.9468 - Test score: 0.1648\n",
      "Epoch 28/300 - Train loss: 0.7444 - Test loss: 0.9559 - Test score: 0.1595\n",
      "Epoch 29/300 - Train loss: 0.7575 - Test loss: 0.9976 - Test score: 0.0839\n",
      "Epoch 30/300 - Train loss: 0.7798 - Test loss: 0.9560 - Test score: 0.1609\n",
      "Epoch 31/300 - Train loss: 0.7449 - Test loss: 0.9624 - Test score: 0.1548\n",
      "Epoch 32/300 - Train loss: 0.7691 - Test loss: 1.0264 - Test score: 0.0452\n",
      "Epoch 33/300 - Train loss: 0.7328 - Test loss: 0.9297 - Test score: 0.1800\n",
      "Epoch 34/300 - Train loss: 0.7427 - Test loss: 0.9300 - Test score: 0.1731\n",
      "Epoch 35/300 - Train loss: 0.7205 - Test loss: 0.9275 - Test score: 0.1758\n",
      "Epoch 36/300 - Train loss: 0.7297 - Test loss: 0.9370 - Test score: 0.1779\n",
      "Epoch 37/300 - Train loss: 0.7328 - Test loss: 0.9221 - Test score: 0.1872\n",
      "Epoch 38/300 - Train loss: 0.7298 - Test loss: 0.9470 - Test score: 0.1438\n",
      "Epoch 39/300 - Train loss: 0.7243 - Test loss: 0.9156 - Test score: 0.1915\n",
      "Epoch 40/300 - Train loss: 0.7114 - Test loss: 0.9232 - Test score: 0.1901\n",
      "Epoch 41/300 - Train loss: 0.7044 - Test loss: 0.9380 - Test score: 0.1542\n",
      "Epoch 42/300 - Train loss: 0.6968 - Test loss: 0.9218 - Test score: 0.1917\n",
      "Epoch 43/300 - Train loss: 0.6960 - Test loss: 0.9638 - Test score: 0.1166\n",
      "Epoch 44/300 - Train loss: 0.7042 - Test loss: 0.9205 - Test score: 0.1746\n",
      "Epoch 45/300 - Train loss: 0.6891 - Test loss: 0.9054 - Test score: 0.1987\n",
      "Epoch 46/300 - Train loss: 0.7086 - Test loss: 0.9106 - Test score: 0.1891\n",
      "Epoch 47/300 - Train loss: 0.6874 - Test loss: 0.9014 - Test score: 0.1998\n",
      "Epoch 48/300 - Train loss: 0.6862 - Test loss: 0.9031 - Test score: 0.2064\n",
      "Epoch 49/300 - Train loss: 0.7074 - Test loss: 1.1255 - Test score: -0.0862\n",
      "Epoch 50/300 - Train loss: 0.7178 - Test loss: 0.9079 - Test score: 0.1884\n",
      "Epoch 51/300 - Train loss: 0.6947 - Test loss: 0.9065 - Test score: 0.2060\n",
      "Epoch 52/300 - Train loss: 0.6772 - Test loss: 0.8953 - Test score: 0.2035\n",
      "Epoch 53/300 - Train loss: 0.6802 - Test loss: 0.9356 - Test score: 0.1483\n",
      "Epoch 54/300 - Train loss: 0.6707 - Test loss: 0.9357 - Test score: 0.1476\n",
      "Epoch 55/300 - Train loss: 0.6737 - Test loss: 0.9080 - Test score: 0.1822\n",
      "Epoch 56/300 - Train loss: 0.6593 - Test loss: 0.8870 - Test score: 0.2144\n",
      "Epoch 57/300 - Train loss: 0.6708 - Test loss: 0.9384 - Test score: 0.1746\n",
      "Epoch 58/300 - Train loss: 0.6671 - Test loss: 0.8887 - Test score: 0.2208\n",
      "Epoch 59/300 - Train loss: 0.6694 - Test loss: 0.8859 - Test score: 0.2220\n",
      "Epoch 60/300 - Train loss: 0.6570 - Test loss: 0.9962 - Test score: 0.0667\n",
      "Epoch 61/300 - Train loss: 0.6680 - Test loss: 0.9092 - Test score: 0.1758\n",
      "Epoch 62/300 - Train loss: 0.6757 - Test loss: 0.8802 - Test score: 0.2182\n",
      "Epoch 63/300 - Train loss: 0.6527 - Test loss: 0.8778 - Test score: 0.2261\n",
      "Epoch 64/300 - Train loss: 0.6495 - Test loss: 0.8849 - Test score: 0.2240\n",
      "Epoch 65/300 - Train loss: 0.6584 - Test loss: 0.8765 - Test score: 0.2198\n",
      "Epoch 66/300 - Train loss: 0.6552 - Test loss: 0.9005 - Test score: 0.2091\n",
      "Epoch 67/300 - Train loss: 0.6468 - Test loss: 0.8750 - Test score: 0.2226\n",
      "Epoch 68/300 - Train loss: 0.6711 - Test loss: 0.8726 - Test score: 0.2325\n",
      "Epoch 69/300 - Train loss: 0.6493 - Test loss: 0.8917 - Test score: 0.1975\n",
      "Epoch 70/300 - Train loss: 0.6478 - Test loss: 0.9363 - Test score: 0.1739\n",
      "Epoch 71/300 - Train loss: 0.6553 - Test loss: 0.8795 - Test score: 0.2122\n",
      "Epoch 72/300 - Train loss: 0.6511 - Test loss: 0.8696 - Test score: 0.2252\n",
      "Epoch 73/300 - Train loss: 0.6672 - Test loss: 0.8969 - Test score: 0.1870\n",
      "Epoch 74/300 - Train loss: 0.6562 - Test loss: 0.9568 - Test score: 0.1543\n",
      "Epoch 75/300 - Train loss: 0.6327 - Test loss: 0.8626 - Test score: 0.2384\n",
      "Epoch 76/300 - Train loss: 0.6394 - Test loss: 0.8740 - Test score: 0.2328\n",
      "Epoch 77/300 - Train loss: 0.6358 - Test loss: 0.8640 - Test score: 0.2341\n",
      "Epoch 78/300 - Train loss: 0.6184 - Test loss: 0.8893 - Test score: 0.1942\n",
      "Epoch 79/300 - Train loss: 0.6263 - Test loss: 0.8598 - Test score: 0.2421\n",
      "Epoch 80/300 - Train loss: 0.6280 - Test loss: 0.9275 - Test score: 0.1820\n",
      "Epoch 81/300 - Train loss: 0.6294 - Test loss: 0.8682 - Test score: 0.2226\n",
      "Epoch 82/300 - Train loss: 0.6245 - Test loss: 0.9848 - Test score: 0.0706\n",
      "Epoch 83/300 - Train loss: 0.6296 - Test loss: 0.8623 - Test score: 0.2318\n",
      "Epoch 84/300 - Train loss: 0.6123 - Test loss: 0.8539 - Test score: 0.2450\n",
      "Epoch 85/300 - Train loss: 0.6136 - Test loss: 0.8685 - Test score: 0.2201\n",
      "Epoch 86/300 - Train loss: 0.6043 - Test loss: 0.8550 - Test score: 0.2433\n",
      "Epoch 87/300 - Train loss: 0.6254 - Test loss: 0.8549 - Test score: 0.2511\n",
      "Epoch 88/300 - Train loss: 0.6093 - Test loss: 0.8561 - Test score: 0.2377\n",
      "Epoch 89/300 - Train loss: 0.6084 - Test loss: 0.8862 - Test score: 0.2223\n",
      "Epoch 90/300 - Train loss: 0.6200 - Test loss: 1.0303 - Test score: 0.0128\n",
      "Epoch 91/300 - Train loss: 0.6159 - Test loss: 0.8503 - Test score: 0.2441\n",
      "Epoch 92/300 - Train loss: 0.6032 - Test loss: 0.8880 - Test score: 0.1893\n",
      "Epoch 93/300 - Train loss: 0.6156 - Test loss: 0.8923 - Test score: 0.1844\n",
      "Epoch 94/300 - Train loss: 0.6130 - Test loss: 0.8495 - Test score: 0.2524\n",
      "Epoch 95/300 - Train loss: 0.6077 - Test loss: 0.8635 - Test score: 0.2225\n",
      "Epoch 96/300 - Train loss: 0.5937 - Test loss: 0.8594 - Test score: 0.2268\n",
      "Epoch 97/300 - Train loss: 0.5942 - Test loss: 0.8736 - Test score: 0.2072\n",
      "Epoch 98/300 - Train loss: 0.5985 - Test loss: 0.8754 - Test score: 0.2037\n",
      "Epoch 99/300 - Train loss: 0.5973 - Test loss: 0.8457 - Test score: 0.2478\n",
      "Epoch 100/300 - Train loss: 0.5998 - Test loss: 0.8555 - Test score: 0.2488\n",
      "Epoch 101/300 - Train loss: 0.5876 - Test loss: 0.8441 - Test score: 0.2462\n",
      "Epoch 102/300 - Train loss: 0.5984 - Test loss: 0.8538 - Test score: 0.2308\n",
      "Epoch 103/300 - Train loss: 0.5959 - Test loss: 0.8523 - Test score: 0.2506\n",
      "Epoch 104/300 - Train loss: 0.6068 - Test loss: 0.8775 - Test score: 0.1974\n",
      "\n",
      "Layer 0 - Score: 0.2524\n",
      "Epoch 1/300 - Train loss: 1.2025 - Test loss: 1.1425 - Test score: -0.0174\n",
      "Epoch 2/300 - Train loss: 0.9457 - Test loss: 1.1232 - Test score: -0.0021\n",
      "Epoch 3/300 - Train loss: 0.9291 - Test loss: 1.1013 - Test score: 0.0206\n",
      "Epoch 4/300 - Train loss: 0.9104 - Test loss: 1.0880 - Test score: 0.0298\n",
      "Epoch 5/300 - Train loss: 0.9007 - Test loss: 1.0719 - Test score: 0.0471\n",
      "Epoch 6/300 - Train loss: 0.8852 - Test loss: 1.0593 - Test score: 0.0609\n",
      "Epoch 7/300 - Train loss: 0.8686 - Test loss: 1.0532 - Test score: 0.0597\n",
      "Epoch 8/300 - Train loss: 0.8600 - Test loss: 1.0461 - Test score: 0.0642\n",
      "Epoch 9/300 - Train loss: 0.8496 - Test loss: 1.0320 - Test score: 0.0842\n",
      "Epoch 10/300 - Train loss: 0.8422 - Test loss: 1.0256 - Test score: 0.0873\n",
      "Epoch 11/300 - Train loss: 0.8339 - Test loss: 1.0182 - Test score: 0.0946\n",
      "Epoch 12/300 - Train loss: 0.8249 - Test loss: 1.0110 - Test score: 0.1025\n",
      "Epoch 13/300 - Train loss: 0.8154 - Test loss: 1.0059 - Test score: 0.1092\n",
      "Epoch 14/300 - Train loss: 0.8104 - Test loss: 1.0028 - Test score: 0.1055\n",
      "Epoch 15/300 - Train loss: 0.8030 - Test loss: 0.9951 - Test score: 0.1163\n",
      "Epoch 16/300 - Train loss: 0.7943 - Test loss: 0.9894 - Test score: 0.1233\n",
      "Epoch 17/300 - Train loss: 0.7918 - Test loss: 0.9867 - Test score: 0.1208\n",
      "Epoch 18/300 - Train loss: 0.7838 - Test loss: 0.9839 - Test score: 0.1221\n",
      "Epoch 19/300 - Train loss: 0.7770 - Test loss: 0.9759 - Test score: 0.1350\n",
      "Epoch 20/300 - Train loss: 0.7743 - Test loss: 0.9731 - Test score: 0.1400\n",
      "Epoch 21/300 - Train loss: 0.7676 - Test loss: 0.9687 - Test score: 0.1403\n",
      "Epoch 22/300 - Train loss: 0.7624 - Test loss: 0.9673 - Test score: 0.1375\n",
      "Epoch 23/300 - Train loss: 0.7549 - Test loss: 0.9608 - Test score: 0.1486\n",
      "Epoch 24/300 - Train loss: 0.7542 - Test loss: 0.9594 - Test score: 0.1461\n",
      "Epoch 25/300 - Train loss: 0.7469 - Test loss: 0.9571 - Test score: 0.1469\n",
      "Epoch 26/300 - Train loss: 0.7426 - Test loss: 0.9510 - Test score: 0.1575\n",
      "Epoch 27/300 - Train loss: 0.7399 - Test loss: 0.9501 - Test score: 0.1533\n",
      "Epoch 28/300 - Train loss: 0.7332 - Test loss: 0.9480 - Test score: 0.1544\n",
      "Epoch 29/300 - Train loss: 0.7287 - Test loss: 0.9419 - Test score: 0.1651\n",
      "Epoch 30/300 - Train loss: 0.7250 - Test loss: 0.9397 - Test score: 0.1644\n",
      "Epoch 31/300 - Train loss: 0.7196 - Test loss: 0.9372 - Test score: 0.1682\n",
      "Epoch 32/300 - Train loss: 0.7160 - Test loss: 0.9371 - Test score: 0.1646\n",
      "Epoch 33/300 - Train loss: 0.7122 - Test loss: 0.9359 - Test score: 0.1642\n",
      "Epoch 34/300 - Train loss: 0.7148 - Test loss: 0.9293 - Test score: 0.1757\n",
      "Epoch 35/300 - Train loss: 0.7051 - Test loss: 0.9370 - Test score: 0.1587\n",
      "Epoch 36/300 - Train loss: 0.7100 - Test loss: 0.9241 - Test score: 0.1806\n",
      "Epoch 37/300 - Train loss: 0.6999 - Test loss: 0.9235 - Test score: 0.1776\n",
      "Epoch 38/300 - Train loss: 0.6946 - Test loss: 0.9206 - Test score: 0.1812\n",
      "Epoch 39/300 - Train loss: 0.6913 - Test loss: 0.9194 - Test score: 0.1811\n",
      "Epoch 40/300 - Train loss: 0.6878 - Test loss: 0.9162 - Test score: 0.1869\n",
      "Epoch 41/300 - Train loss: 0.6848 - Test loss: 0.9148 - Test score: 0.1905\n",
      "Epoch 42/300 - Train loss: 0.6811 - Test loss: 0.9130 - Test score: 0.1875\n",
      "Epoch 43/300 - Train loss: 0.6763 - Test loss: 0.9122 - Test score: 0.1866\n",
      "Epoch 44/300 - Train loss: 0.6820 - Test loss: 0.9079 - Test score: 0.1946\n",
      "Epoch 45/300 - Train loss: 0.6711 - Test loss: 0.9065 - Test score: 0.1969\n",
      "Epoch 46/300 - Train loss: 0.6682 - Test loss: 0.9051 - Test score: 0.1949\n",
      "Epoch 47/300 - Train loss: 0.6682 - Test loss: 0.9056 - Test score: 0.1915\n",
      "Epoch 48/300 - Train loss: 0.6619 - Test loss: 0.9000 - Test score: 0.2008\n",
      "Epoch 49/300 - Train loss: 0.6609 - Test loss: 0.9001 - Test score: 0.1982\n",
      "Epoch 50/300 - Train loss: 0.6555 - Test loss: 0.8969 - Test score: 0.2049\n",
      "Epoch 51/300 - Train loss: 0.6549 - Test loss: 0.8995 - Test score: 0.1961\n",
      "Epoch 52/300 - Train loss: 0.6536 - Test loss: 0.8932 - Test score: 0.2068\n",
      "Epoch 53/300 - Train loss: 0.6491 - Test loss: 0.8939 - Test score: 0.2035\n",
      "Epoch 54/300 - Train loss: 0.6461 - Test loss: 0.8924 - Test score: 0.2043\n",
      "Epoch 55/300 - Train loss: 0.6429 - Test loss: 0.8889 - Test score: 0.2111\n",
      "Epoch 56/300 - Train loss: 0.6394 - Test loss: 0.8888 - Test score: 0.2135\n",
      "Epoch 57/300 - Train loss: 0.6374 - Test loss: 0.8861 - Test score: 0.2131\n",
      "Epoch 58/300 - Train loss: 0.6381 - Test loss: 0.8847 - Test score: 0.2158\n",
      "Epoch 59/300 - Train loss: 0.6350 - Test loss: 0.8863 - Test score: 0.2078\n",
      "Epoch 60/300 - Train loss: 0.6323 - Test loss: 0.8815 - Test score: 0.2165\n",
      "Epoch 61/300 - Train loss: 0.6288 - Test loss: 0.8800 - Test score: 0.2194\n",
      "Epoch 62/300 - Train loss: 0.6272 - Test loss: 0.8799 - Test score: 0.2160\n",
      "Epoch 63/300 - Train loss: 0.6249 - Test loss: 0.8809 - Test score: 0.2122\n",
      "Epoch 64/300 - Train loss: 0.6223 - Test loss: 0.8766 - Test score: 0.2231\n",
      "Epoch 65/300 - Train loss: 0.6190 - Test loss: 0.8754 - Test score: 0.2211\n",
      "Epoch 66/300 - Train loss: 0.6191 - Test loss: 0.8734 - Test score: 0.2236\n",
      "Epoch 67/300 - Train loss: 0.6149 - Test loss: 0.8732 - Test score: 0.2216\n",
      "Epoch 68/300 - Train loss: 0.6136 - Test loss: 0.8707 - Test score: 0.2264\n",
      "Epoch 69/300 - Train loss: 0.6114 - Test loss: 0.8698 - Test score: 0.2257\n",
      "Epoch 70/300 - Train loss: 0.6093 - Test loss: 0.8680 - Test score: 0.2293\n",
      "Epoch 71/300 - Train loss: 0.6066 - Test loss: 0.8681 - Test score: 0.2268\n",
      "Epoch 72/300 - Train loss: 0.6057 - Test loss: 0.8685 - Test score: 0.2242\n",
      "Epoch 73/300 - Train loss: 0.6022 - Test loss: 0.8681 - Test score: 0.2241\n",
      "Epoch 74/300 - Train loss: 0.6028 - Test loss: 0.8715 - Test score: 0.2170\n",
      "Epoch 75/300 - Train loss: 0.6062 - Test loss: 0.8676 - Test score: 0.2227\n",
      "Epoch 76/300 - Train loss: 0.5981 - Test loss: 0.8610 - Test score: 0.2356\n",
      "Epoch 77/300 - Train loss: 0.5974 - Test loss: 0.8613 - Test score: 0.2316\n",
      "Epoch 78/300 - Train loss: 0.5929 - Test loss: 0.8604 - Test score: 0.2316\n",
      "Epoch 79/300 - Train loss: 0.5903 - Test loss: 0.8597 - Test score: 0.2322\n",
      "Epoch 80/300 - Train loss: 0.5891 - Test loss: 0.8572 - Test score: 0.2396\n",
      "Epoch 81/300 - Train loss: 0.5874 - Test loss: 0.8561 - Test score: 0.2377\n",
      "Epoch 82/300 - Train loss: 0.5846 - Test loss: 0.8547 - Test score: 0.2420\n",
      "Epoch 83/300 - Train loss: 0.5826 - Test loss: 0.8538 - Test score: 0.2403\n",
      "Epoch 84/300 - Train loss: 0.5821 - Test loss: 0.8529 - Test score: 0.2412\n",
      "Epoch 85/300 - Train loss: 0.5801 - Test loss: 0.8548 - Test score: 0.2354\n",
      "Epoch 86/300 - Train loss: 0.5768 - Test loss: 0.8536 - Test score: 0.2364\n",
      "Epoch 87/300 - Train loss: 0.5769 - Test loss: 0.8508 - Test score: 0.2417\n",
      "Epoch 88/300 - Train loss: 0.5750 - Test loss: 0.8502 - Test score: 0.2401\n",
      "Epoch 89/300 - Train loss: 0.5736 - Test loss: 0.8476 - Test score: 0.2471\n",
      "Epoch 90/300 - Train loss: 0.5720 - Test loss: 0.8566 - Test score: 0.2284\n",
      "Epoch 91/300 - Train loss: 0.5722 - Test loss: 0.8468 - Test score: 0.2442\n",
      "Epoch 92/300 - Train loss: 0.5672 - Test loss: 0.8445 - Test score: 0.2489\n",
      "Epoch 93/300 - Train loss: 0.5667 - Test loss: 0.8445 - Test score: 0.2471\n",
      "Epoch 94/300 - Train loss: 0.5631 - Test loss: 0.8429 - Test score: 0.2516\n",
      "Epoch 95/300 - Train loss: 0.5684 - Test loss: 0.8494 - Test score: 0.2361\n",
      "Epoch 96/300 - Train loss: 0.5619 - Test loss: 0.8410 - Test score: 0.2518\n",
      "Epoch 97/300 - Train loss: 0.5585 - Test loss: 0.8418 - Test score: 0.2532\n",
      "Epoch 98/300 - Train loss: 0.5585 - Test loss: 0.8398 - Test score: 0.2527\n",
      "Epoch 99/300 - Train loss: 0.5568 - Test loss: 0.8387 - Test score: 0.2535\n",
      "Epoch 100/300 - Train loss: 0.5540 - Test loss: 0.8382 - Test score: 0.2548\n",
      "Epoch 101/300 - Train loss: 0.5559 - Test loss: 0.8396 - Test score: 0.2484\n",
      "Epoch 102/300 - Train loss: 0.5517 - Test loss: 0.8382 - Test score: 0.2501\n",
      "Epoch 103/300 - Train loss: 0.5495 - Test loss: 0.8366 - Test score: 0.2528\n",
      "Epoch 104/300 - Train loss: 0.5510 - Test loss: 0.8382 - Test score: 0.2485\n",
      "Epoch 105/300 - Train loss: 0.5523 - Test loss: 0.8345 - Test score: 0.2549\n",
      "Epoch 106/300 - Train loss: 0.5454 - Test loss: 0.8338 - Test score: 0.2570\n",
      "Epoch 107/300 - Train loss: 0.5435 - Test loss: 0.8327 - Test score: 0.2604\n",
      "Epoch 108/300 - Train loss: 0.5431 - Test loss: 0.8319 - Test score: 0.2577\n",
      "Epoch 109/300 - Train loss: 0.5419 - Test loss: 0.8313 - Test score: 0.2580\n",
      "Epoch 110/300 - Train loss: 0.5450 - Test loss: 0.8301 - Test score: 0.2615\n",
      "Epoch 111/300 - Train loss: 0.5401 - Test loss: 0.8305 - Test score: 0.2574\n",
      "Epoch 112/300 - Train loss: 0.5365 - Test loss: 0.8288 - Test score: 0.2617\n",
      "Epoch 113/300 - Train loss: 0.5359 - Test loss: 0.8300 - Test score: 0.2568\n",
      "Epoch 114/300 - Train loss: 0.5347 - Test loss: 0.8272 - Test score: 0.2645\n",
      "Epoch 115/300 - Train loss: 0.5323 - Test loss: 0.8263 - Test score: 0.2646\n",
      "Epoch 116/300 - Train loss: 0.5321 - Test loss: 0.8258 - Test score: 0.2629\n",
      "Epoch 117/300 - Train loss: 0.5313 - Test loss: 0.8252 - Test score: 0.2639\n",
      "Epoch 118/300 - Train loss: 0.5298 - Test loss: 0.8267 - Test score: 0.2589\n",
      "Epoch 119/300 - Train loss: 0.5278 - Test loss: 0.8235 - Test score: 0.2656\n",
      "Epoch 120/300 - Train loss: 0.5276 - Test loss: 0.8231 - Test score: 0.2656\n",
      "Epoch 121/300 - Train loss: 0.5263 - Test loss: 0.8225 - Test score: 0.2651\n",
      "Epoch 122/300 - Train loss: 0.5233 - Test loss: 0.8253 - Test score: 0.2586\n",
      "Epoch 123/300 - Train loss: 0.5243 - Test loss: 0.8223 - Test score: 0.2640\n",
      "Epoch 124/300 - Train loss: 0.5218 - Test loss: 0.8228 - Test score: 0.2621\n",
      "Epoch 125/300 - Train loss: 0.5209 - Test loss: 0.8204 - Test score: 0.2670\n",
      "Epoch 126/300 - Train loss: 0.5199 - Test loss: 0.8252 - Test score: 0.2568\n",
      "Epoch 127/300 - Train loss: 0.5202 - Test loss: 0.8228 - Test score: 0.2699\n",
      "Epoch 128/300 - Train loss: 0.5173 - Test loss: 0.8226 - Test score: 0.2600\n",
      "Epoch 129/300 - Train loss: 0.5167 - Test loss: 0.8177 - Test score: 0.2700\n",
      "Epoch 130/300 - Train loss: 0.5157 - Test loss: 0.8171 - Test score: 0.2690\n",
      "Epoch 131/300 - Train loss: 0.5116 - Test loss: 0.8223 - Test score: 0.2586\n",
      "Epoch 132/300 - Train loss: 0.5170 - Test loss: 0.8159 - Test score: 0.2714\n",
      "Epoch 133/300 - Train loss: 0.5108 - Test loss: 0.8160 - Test score: 0.2703\n",
      "Epoch 134/300 - Train loss: 0.5092 - Test loss: 0.8166 - Test score: 0.2683\n",
      "Epoch 135/300 - Train loss: 0.5079 - Test loss: 0.8144 - Test score: 0.2713\n",
      "Epoch 136/300 - Train loss: 0.5092 - Test loss: 0.8156 - Test score: 0.2678\n",
      "Epoch 137/300 - Train loss: 0.5051 - Test loss: 0.8128 - Test score: 0.2755\n",
      "Epoch 138/300 - Train loss: 0.5047 - Test loss: 0.8122 - Test score: 0.2738\n",
      "Epoch 139/300 - Train loss: 0.5035 - Test loss: 0.8118 - Test score: 0.2745\n",
      "Epoch 140/300 - Train loss: 0.5021 - Test loss: 0.8133 - Test score: 0.2773\n",
      "Epoch 141/300 - Train loss: 0.5008 - Test loss: 0.8109 - Test score: 0.2751\n",
      "Epoch 142/300 - Train loss: 0.5013 - Test loss: 0.8108 - Test score: 0.2741\n",
      "Epoch 143/300 - Train loss: 0.4998 - Test loss: 0.8110 - Test score: 0.2724\n",
      "Epoch 144/300 - Train loss: 0.4971 - Test loss: 0.8090 - Test score: 0.2767\n",
      "Epoch 145/300 - Train loss: 0.4986 - Test loss: 0.8095 - Test score: 0.2747\n",
      "Epoch 146/300 - Train loss: 0.4953 - Test loss: 0.8083 - Test score: 0.2784\n",
      "Epoch 147/300 - Train loss: 0.4970 - Test loss: 0.8082 - Test score: 0.2794\n",
      "Epoch 148/300 - Train loss: 0.4936 - Test loss: 0.8067 - Test score: 0.2786\n",
      "Epoch 149/300 - Train loss: 0.4935 - Test loss: 0.8061 - Test score: 0.2795\n",
      "Epoch 150/300 - Train loss: 0.4923 - Test loss: 0.8064 - Test score: 0.2788\n",
      "Epoch 151/300 - Train loss: 0.4916 - Test loss: 0.8057 - Test score: 0.2784\n",
      "Epoch 152/300 - Train loss: 0.4917 - Test loss: 0.8087 - Test score: 0.2714\n",
      "Epoch 153/300 - Train loss: 0.4914 - Test loss: 0.8063 - Test score: 0.2754\n",
      "Epoch 154/300 - Train loss: 0.4897 - Test loss: 0.8046 - Test score: 0.2812\n",
      "Epoch 155/300 - Train loss: 0.4869 - Test loss: 0.8041 - Test score: 0.2805\n",
      "Epoch 156/300 - Train loss: 0.4859 - Test loss: 0.8035 - Test score: 0.2808\n",
      "Epoch 157/300 - Train loss: 0.4850 - Test loss: 0.8035 - Test score: 0.2821\n",
      "Epoch 158/300 - Train loss: 0.4828 - Test loss: 0.8021 - Test score: 0.2826\n",
      "Epoch 159/300 - Train loss: 0.4829 - Test loss: 0.8018 - Test score: 0.2825\n",
      "Epoch 160/300 - Train loss: 0.4871 - Test loss: 0.8018 - Test score: 0.2841\n",
      "Epoch 161/300 - Train loss: 0.4812 - Test loss: 0.8018 - Test score: 0.2796\n",
      "Epoch 162/300 - Train loss: 0.4809 - Test loss: 0.8009 - Test score: 0.2825\n",
      "Epoch 163/300 - Train loss: 0.4783 - Test loss: 0.8008 - Test score: 0.2855\n",
      "Epoch 164/300 - Train loss: 0.4793 - Test loss: 0.7999 - Test score: 0.2828\n",
      "Epoch 165/300 - Train loss: 0.4768 - Test loss: 0.8007 - Test score: 0.2809\n",
      "Epoch 166/300 - Train loss: 0.4762 - Test loss: 0.7998 - Test score: 0.2813\n",
      "Epoch 167/300 - Train loss: 0.4773 - Test loss: 0.7982 - Test score: 0.2849\n",
      "Epoch 168/300 - Train loss: 0.4735 - Test loss: 0.7990 - Test score: 0.2821\n",
      "Epoch 169/300 - Train loss: 0.4772 - Test loss: 0.8009 - Test score: 0.2782\n",
      "Epoch 170/300 - Train loss: 0.4729 - Test loss: 0.7995 - Test score: 0.2798\n",
      "Epoch 171/300 - Train loss: 0.4715 - Test loss: 0.7975 - Test score: 0.2873\n",
      "Epoch 172/300 - Train loss: 0.4702 - Test loss: 0.7968 - Test score: 0.2852\n",
      "Epoch 173/300 - Train loss: 0.4693 - Test loss: 0.7967 - Test score: 0.2840\n",
      "Epoch 174/300 - Train loss: 0.4693 - Test loss: 0.7961 - Test score: 0.2880\n",
      "Epoch 175/300 - Train loss: 0.4684 - Test loss: 0.7962 - Test score: 0.2884\n",
      "Epoch 176/300 - Train loss: 0.4670 - Test loss: 0.7957 - Test score: 0.2881\n",
      "Epoch 177/300 - Train loss: 0.4677 - Test loss: 0.7968 - Test score: 0.2819\n",
      "Epoch 178/300 - Train loss: 0.4659 - Test loss: 0.7950 - Test score: 0.2878\n",
      "Epoch 179/300 - Train loss: 0.4655 - Test loss: 0.7948 - Test score: 0.2852\n",
      "Epoch 180/300 - Train loss: 0.4645 - Test loss: 0.7976 - Test score: 0.2790\n",
      "Epoch 181/300 - Train loss: 0.4633 - Test loss: 0.7941 - Test score: 0.2861\n",
      "Epoch 182/300 - Train loss: 0.4622 - Test loss: 0.7934 - Test score: 0.2870\n",
      "Epoch 183/300 - Train loss: 0.4607 - Test loss: 0.7925 - Test score: 0.2913\n",
      "Epoch 184/300 - Train loss: 0.4618 - Test loss: 0.7928 - Test score: 0.2871\n",
      "Epoch 185/300 - Train loss: 0.4595 - Test loss: 0.7933 - Test score: 0.2919\n",
      "Epoch 186/300 - Train loss: 0.4604 - Test loss: 0.7925 - Test score: 0.2864\n",
      "Epoch 187/300 - Train loss: 0.4595 - Test loss: 0.7911 - Test score: 0.2906\n",
      "Epoch 188/300 - Train loss: 0.4572 - Test loss: 0.7913 - Test score: 0.2922\n",
      "Epoch 189/300 - Train loss: 0.4560 - Test loss: 0.7919 - Test score: 0.2918\n",
      "Epoch 190/300 - Train loss: 0.4564 - Test loss: 0.7918 - Test score: 0.2862\n",
      "Epoch 191/300 - Train loss: 0.4545 - Test loss: 0.7898 - Test score: 0.2921\n",
      "Epoch 192/300 - Train loss: 0.4540 - Test loss: 0.7901 - Test score: 0.2903\n",
      "Epoch 193/300 - Train loss: 0.4538 - Test loss: 0.7893 - Test score: 0.2931\n",
      "Epoch 194/300 - Train loss: 0.4520 - Test loss: 0.7891 - Test score: 0.2907\n",
      "Epoch 195/300 - Train loss: 0.4544 - Test loss: 0.7886 - Test score: 0.2918\n",
      "Epoch 196/300 - Train loss: 0.4518 - Test loss: 0.7888 - Test score: 0.2941\n",
      "Epoch 197/300 - Train loss: 0.4501 - Test loss: 0.7888 - Test score: 0.2893\n",
      "Epoch 198/300 - Train loss: 0.4498 - Test loss: 0.7891 - Test score: 0.2943\n",
      "Epoch 199/300 - Train loss: 0.4490 - Test loss: 0.7871 - Test score: 0.2940\n",
      "Epoch 200/300 - Train loss: 0.4484 - Test loss: 0.7869 - Test score: 0.2930\n",
      "Epoch 201/300 - Train loss: 0.4476 - Test loss: 0.7869 - Test score: 0.2926\n",
      "Epoch 202/300 - Train loss: 0.4473 - Test loss: 0.7861 - Test score: 0.2928\n",
      "Epoch 203/300 - Train loss: 0.4450 - Test loss: 0.7855 - Test score: 0.2944\n",
      "Epoch 204/300 - Train loss: 0.4443 - Test loss: 0.7898 - Test score: 0.2848\n",
      "Epoch 205/300 - Train loss: 0.4497 - Test loss: 0.7863 - Test score: 0.2948\n",
      "Epoch 206/300 - Train loss: 0.4437 - Test loss: 0.7857 - Test score: 0.2950\n",
      "Epoch 207/300 - Train loss: 0.4429 - Test loss: 0.7853 - Test score: 0.2939\n",
      "Epoch 208/300 - Train loss: 0.4428 - Test loss: 0.7884 - Test score: 0.2960\n",
      "Epoch 209/300 - Train loss: 0.4414 - Test loss: 0.7861 - Test score: 0.2893\n",
      "Epoch 210/300 - Train loss: 0.4428 - Test loss: 0.7838 - Test score: 0.2945\n",
      "Epoch 211/300 - Train loss: 0.4395 - Test loss: 0.7843 - Test score: 0.2923\n",
      "Epoch 212/300 - Train loss: 0.4401 - Test loss: 0.7845 - Test score: 0.2966\n",
      "Epoch 213/300 - Train loss: 0.4383 - Test loss: 0.7863 - Test score: 0.2964\n",
      "Epoch 214/300 - Train loss: 0.4389 - Test loss: 0.7860 - Test score: 0.2885\n",
      "Epoch 215/300 - Train loss: 0.4374 - Test loss: 0.7844 - Test score: 0.2974\n",
      "Epoch 216/300 - Train loss: 0.4375 - Test loss: 0.7825 - Test score: 0.2963\n",
      "Epoch 217/300 - Train loss: 0.4381 - Test loss: 0.7825 - Test score: 0.2940\n",
      "Epoch 218/300 - Train loss: 0.4347 - Test loss: 0.7831 - Test score: 0.2935\n",
      "Epoch 219/300 - Train loss: 0.4354 - Test loss: 0.7819 - Test score: 0.2979\n",
      "Epoch 220/300 - Train loss: 0.4332 - Test loss: 0.7823 - Test score: 0.2945\n",
      "Epoch 221/300 - Train loss: 0.4334 - Test loss: 0.7817 - Test score: 0.2982\n",
      "Epoch 222/300 - Train loss: 0.4328 - Test loss: 0.7821 - Test score: 0.2944\n",
      "Epoch 223/300 - Train loss: 0.4378 - Test loss: 0.7812 - Test score: 0.2983\n",
      "Epoch 224/300 - Train loss: 0.4305 - Test loss: 0.7816 - Test score: 0.2971\n",
      "Epoch 225/300 - Train loss: 0.4310 - Test loss: 0.7825 - Test score: 0.2991\n",
      "Epoch 226/300 - Train loss: 0.4351 - Test loss: 0.7801 - Test score: 0.2982\n",
      "Epoch 227/300 - Train loss: 0.4306 - Test loss: 0.7824 - Test score: 0.2915\n",
      "Epoch 228/300 - Train loss: 0.4313 - Test loss: 0.7809 - Test score: 0.2950\n",
      "Epoch 229/300 - Train loss: 0.4307 - Test loss: 0.7821 - Test score: 0.2915\n",
      "Epoch 230/300 - Train loss: 0.4281 - Test loss: 0.7827 - Test score: 0.2895\n",
      "Epoch 231/300 - Train loss: 0.4263 - Test loss: 0.7804 - Test score: 0.2946\n",
      "Epoch 232/300 - Train loss: 0.4259 - Test loss: 0.7797 - Test score: 0.2961\n",
      "Epoch 233/300 - Train loss: 0.4278 - Test loss: 0.7812 - Test score: 0.2917\n",
      "Epoch 234/300 - Train loss: 0.4255 - Test loss: 0.7843 - Test score: 0.2857\n",
      "Epoch 235/300 - Train loss: 0.4234 - Test loss: 0.7787 - Test score: 0.2974\n",
      "\n",
      "Layer 1 - Score: 0.2991\n",
      "Epoch 1/300 - Train loss: 0.9616 - Test loss: 1.1027 - Test score: 0.0074\n",
      "Epoch 2/300 - Train loss: 0.9159 - Test loss: 1.0565 - Test score: 0.0667\n",
      "Epoch 3/300 - Train loss: 0.8841 - Test loss: 1.0421 - Test score: 0.0641\n",
      "Epoch 4/300 - Train loss: 0.8527 - Test loss: 1.0220 - Test score: 0.0822\n",
      "Epoch 5/300 - Train loss: 0.8399 - Test loss: 1.0083 - Test score: 0.0972\n",
      "Epoch 6/300 - Train loss: 0.8329 - Test loss: 0.9937 - Test score: 0.1158\n",
      "Epoch 7/300 - Train loss: 0.8306 - Test loss: 0.9851 - Test score: 0.1234\n",
      "Epoch 8/300 - Train loss: 0.8027 - Test loss: 0.9776 - Test score: 0.1284\n",
      "Epoch 9/300 - Train loss: 0.8013 - Test loss: 0.9831 - Test score: 0.1147\n",
      "Epoch 10/300 - Train loss: 0.7909 - Test loss: 0.9650 - Test score: 0.1417\n",
      "Epoch 11/300 - Train loss: 0.7829 - Test loss: 0.9911 - Test score: 0.0962\n",
      "Epoch 12/300 - Train loss: 0.7768 - Test loss: 0.9768 - Test score: 0.1386\n",
      "Epoch 13/300 - Train loss: 0.7682 - Test loss: 0.9787 - Test score: 0.1109\n",
      "Epoch 14/300 - Train loss: 0.7605 - Test loss: 0.9595 - Test score: 0.1364\n",
      "Epoch 15/300 - Train loss: 0.7558 - Test loss: 0.9476 - Test score: 0.1508\n",
      "Epoch 16/300 - Train loss: 0.7497 - Test loss: 0.9399 - Test score: 0.1662\n",
      "Epoch 17/300 - Train loss: 0.7395 - Test loss: 0.9744 - Test score: 0.1407\n",
      "Epoch 18/300 - Train loss: 0.7418 - Test loss: 0.9433 - Test score: 0.1670\n",
      "Epoch 19/300 - Train loss: 0.7395 - Test loss: 0.9554 - Test score: 0.1326\n",
      "Epoch 20/300 - Train loss: 0.7274 - Test loss: 0.9430 - Test score: 0.1673\n",
      "Epoch 21/300 - Train loss: 0.7296 - Test loss: 0.9306 - Test score: 0.1641\n",
      "Epoch 22/300 - Train loss: 0.7208 - Test loss: 0.9224 - Test score: 0.1792\n",
      "Epoch 23/300 - Train loss: 0.7269 - Test loss: 0.9197 - Test score: 0.1787\n",
      "Epoch 24/300 - Train loss: 0.7191 - Test loss: 0.9184 - Test score: 0.1862\n",
      "Epoch 25/300 - Train loss: 0.7164 - Test loss: 0.9220 - Test score: 0.1704\n",
      "Epoch 26/300 - Train loss: 0.7142 - Test loss: 0.9110 - Test score: 0.1916\n",
      "Epoch 27/300 - Train loss: 0.7025 - Test loss: 0.9155 - Test score: 0.1902\n",
      "Epoch 28/300 - Train loss: 0.7015 - Test loss: 0.9123 - Test score: 0.1806\n",
      "Epoch 29/300 - Train loss: 0.7022 - Test loss: 0.9300 - Test score: 0.1543\n",
      "Epoch 30/300 - Train loss: 0.6971 - Test loss: 0.9065 - Test score: 0.1987\n",
      "Epoch 31/300 - Train loss: 0.6976 - Test loss: 0.9074 - Test score: 0.1964\n",
      "Epoch 32/300 - Train loss: 0.6881 - Test loss: 0.9343 - Test score: 0.1475\n",
      "Epoch 33/300 - Train loss: 0.6966 - Test loss: 0.9027 - Test score: 0.1941\n",
      "Epoch 34/300 - Train loss: 0.6838 - Test loss: 0.9010 - Test score: 0.1925\n",
      "Epoch 35/300 - Train loss: 0.6802 - Test loss: 0.9080 - Test score: 0.1979\n",
      "Epoch 36/300 - Train loss: 0.6802 - Test loss: 0.9587 - Test score: 0.1095\n",
      "Epoch 37/300 - Train loss: 0.6827 - Test loss: 0.8945 - Test score: 0.2019\n",
      "Epoch 38/300 - Train loss: 0.6768 - Test loss: 0.8925 - Test score: 0.2024\n",
      "Epoch 39/300 - Train loss: 0.6766 - Test loss: 0.8881 - Test score: 0.2074\n",
      "Epoch 40/300 - Train loss: 0.6686 - Test loss: 0.8886 - Test score: 0.2115\n",
      "Epoch 41/300 - Train loss: 0.6702 - Test loss: 0.8868 - Test score: 0.2110\n",
      "Epoch 42/300 - Train loss: 0.6620 - Test loss: 0.8870 - Test score: 0.2109\n",
      "Epoch 43/300 - Train loss: 0.6701 - Test loss: 0.8883 - Test score: 0.2044\n",
      "Epoch 44/300 - Train loss: 0.6683 - Test loss: 0.9089 - Test score: 0.1716\n",
      "Epoch 45/300 - Train loss: 0.6584 - Test loss: 0.8977 - Test score: 0.2067\n",
      "Epoch 46/300 - Train loss: 0.6568 - Test loss: 0.8810 - Test score: 0.2112\n",
      "Epoch 47/300 - Train loss: 0.6643 - Test loss: 0.8805 - Test score: 0.2188\n",
      "Epoch 48/300 - Train loss: 0.6496 - Test loss: 0.8804 - Test score: 0.2173\n",
      "Epoch 49/300 - Train loss: 0.6546 - Test loss: 0.8987 - Test score: 0.1828\n",
      "Epoch 50/300 - Train loss: 0.6580 - Test loss: 0.8862 - Test score: 0.2131\n",
      "Epoch 51/300 - Train loss: 0.6561 - Test loss: 0.9007 - Test score: 0.2032\n",
      "Epoch 52/300 - Train loss: 0.6488 - Test loss: 0.8811 - Test score: 0.2054\n",
      "Epoch 53/300 - Train loss: 0.6526 - Test loss: 0.8773 - Test score: 0.2130\n",
      "Epoch 54/300 - Train loss: 0.6459 - Test loss: 0.8847 - Test score: 0.2177\n",
      "Epoch 55/300 - Train loss: 0.6388 - Test loss: 0.8769 - Test score: 0.2229\n",
      "Epoch 56/300 - Train loss: 0.6340 - Test loss: 0.9060 - Test score: 0.1690\n",
      "Epoch 57/300 - Train loss: 0.6380 - Test loss: 0.8908 - Test score: 0.1883\n",
      "Epoch 58/300 - Train loss: 0.6385 - Test loss: 0.8683 - Test score: 0.2221\n",
      "Epoch 59/300 - Train loss: 0.6310 - Test loss: 0.8679 - Test score: 0.2225\n",
      "Epoch 60/300 - Train loss: 0.6354 - Test loss: 0.9205 - Test score: 0.1470\n",
      "Epoch 61/300 - Train loss: 0.6327 - Test loss: 0.8667 - Test score: 0.2249\n",
      "Epoch 62/300 - Train loss: 0.6320 - Test loss: 0.8767 - Test score: 0.2053\n",
      "Epoch 63/300 - Train loss: 0.6264 - Test loss: 0.8687 - Test score: 0.2319\n",
      "Epoch 64/300 - Train loss: 0.6284 - Test loss: 0.8720 - Test score: 0.2285\n",
      "Epoch 65/300 - Train loss: 0.6317 - Test loss: 0.8814 - Test score: 0.1982\n",
      "Epoch 66/300 - Train loss: 0.6233 - Test loss: 0.8662 - Test score: 0.2218\n",
      "Epoch 67/300 - Train loss: 0.6219 - Test loss: 0.8611 - Test score: 0.2286\n",
      "Epoch 68/300 - Train loss: 0.6218 - Test loss: 0.9136 - Test score: 0.1527\n",
      "Epoch 69/300 - Train loss: 0.6239 - Test loss: 0.9383 - Test score: 0.1196\n",
      "Epoch 70/300 - Train loss: 0.6207 - Test loss: 0.8595 - Test score: 0.2360\n",
      "Epoch 71/300 - Train loss: 0.6183 - Test loss: 0.8613 - Test score: 0.2270\n",
      "Epoch 72/300 - Train loss: 0.6170 - Test loss: 0.8901 - Test score: 0.1843\n",
      "Epoch 73/300 - Train loss: 0.6246 - Test loss: 0.8622 - Test score: 0.2231\n",
      "Epoch 74/300 - Train loss: 0.6136 - Test loss: 0.8634 - Test score: 0.2337\n",
      "Epoch 75/300 - Train loss: 0.6157 - Test loss: 0.8629 - Test score: 0.2371\n",
      "Epoch 76/300 - Train loss: 0.6204 - Test loss: 0.8565 - Test score: 0.2404\n",
      "Epoch 77/300 - Train loss: 0.6155 - Test loss: 0.8667 - Test score: 0.2325\n",
      "Epoch 78/300 - Train loss: 0.6101 - Test loss: 0.8691 - Test score: 0.2310\n",
      "Epoch 79/300 - Train loss: 0.6072 - Test loss: 0.8583 - Test score: 0.2268\n",
      "Epoch 80/300 - Train loss: 0.6045 - Test loss: 0.8718 - Test score: 0.2057\n",
      "Epoch 81/300 - Train loss: 0.6045 - Test loss: 0.8491 - Test score: 0.2439\n",
      "Epoch 82/300 - Train loss: 0.6037 - Test loss: 0.8586 - Test score: 0.2393\n",
      "Epoch 83/300 - Train loss: 0.6010 - Test loss: 0.8506 - Test score: 0.2408\n",
      "Epoch 84/300 - Train loss: 0.6029 - Test loss: 0.8476 - Test score: 0.2412\n",
      "Epoch 85/300 - Train loss: 0.6003 - Test loss: 0.8526 - Test score: 0.2317\n",
      "Epoch 86/300 - Train loss: 0.6040 - Test loss: 0.8564 - Test score: 0.2412\n",
      "Epoch 87/300 - Train loss: 0.6022 - Test loss: 0.8585 - Test score: 0.2380\n",
      "Epoch 88/300 - Train loss: 0.6003 - Test loss: 0.8583 - Test score: 0.2377\n",
      "Epoch 89/300 - Train loss: 0.5939 - Test loss: 0.8562 - Test score: 0.2233\n",
      "Epoch 90/300 - Train loss: 0.5939 - Test loss: 0.8479 - Test score: 0.2409\n",
      "Epoch 91/300 - Train loss: 0.6025 - Test loss: 0.8570 - Test score: 0.2402\n",
      "\n",
      "Layer 2 - Score: 0.2439\n",
      "Layer 3 - Score: 0.3254\n",
      "Epoch 1/300 - Train loss: 1.0543 - Test loss: 1.1488 - Test score: -0.0272\n",
      "Epoch 2/300 - Train loss: 0.9335 - Test loss: 1.0808 - Test score: 0.0372\n",
      "Epoch 3/300 - Train loss: 0.8834 - Test loss: 1.0534 - Test score: 0.0479\n",
      "Epoch 4/300 - Train loss: 0.8575 - Test loss: 1.0149 - Test score: 0.0944\n",
      "Epoch 5/300 - Train loss: 0.8333 - Test loss: 0.9987 - Test score: 0.1166\n",
      "Epoch 6/300 - Train loss: 0.8189 - Test loss: 0.9818 - Test score: 0.1356\n",
      "Epoch 7/300 - Train loss: 0.7904 - Test loss: 0.9682 - Test score: 0.1411\n",
      "Epoch 8/300 - Train loss: 0.7772 - Test loss: 0.9653 - Test score: 0.1365\n",
      "Epoch 9/300 - Train loss: 0.7690 - Test loss: 0.9461 - Test score: 0.1666\n",
      "Epoch 10/300 - Train loss: 0.7534 - Test loss: 0.9367 - Test score: 0.1773\n",
      "Epoch 11/300 - Train loss: 0.7450 - Test loss: 0.9308 - Test score: 0.1810\n",
      "Epoch 12/300 - Train loss: 0.7322 - Test loss: 0.9234 - Test score: 0.1850\n",
      "Epoch 13/300 - Train loss: 0.7267 - Test loss: 0.9175 - Test score: 0.1902\n",
      "Epoch 14/300 - Train loss: 0.7239 - Test loss: 0.9162 - Test score: 0.1924\n",
      "Epoch 15/300 - Train loss: 0.7109 - Test loss: 0.9117 - Test score: 0.1966\n",
      "Epoch 16/300 - Train loss: 0.7050 - Test loss: 0.9059 - Test score: 0.2103\n",
      "Epoch 17/300 - Train loss: 0.7017 - Test loss: 0.8991 - Test score: 0.2166\n",
      "Epoch 18/300 - Train loss: 0.6916 - Test loss: 0.9033 - Test score: 0.1997\n",
      "Epoch 19/300 - Train loss: 0.6869 - Test loss: 0.8898 - Test score: 0.2182\n",
      "Epoch 20/300 - Train loss: 0.6833 - Test loss: 0.8979 - Test score: 0.2200\n",
      "Epoch 21/300 - Train loss: 0.6766 - Test loss: 0.8955 - Test score: 0.2085\n",
      "Epoch 22/300 - Train loss: 0.6776 - Test loss: 0.8838 - Test score: 0.2301\n",
      "Epoch 23/300 - Train loss: 0.6716 - Test loss: 0.8773 - Test score: 0.2382\n",
      "Epoch 24/300 - Train loss: 0.6663 - Test loss: 0.8767 - Test score: 0.2378\n",
      "Epoch 25/300 - Train loss: 0.6734 - Test loss: 0.8776 - Test score: 0.2354\n",
      "Epoch 26/300 - Train loss: 0.6570 - Test loss: 0.8859 - Test score: 0.2318\n",
      "Epoch 27/300 - Train loss: 0.6532 - Test loss: 0.8701 - Test score: 0.2394\n",
      "Epoch 28/300 - Train loss: 0.6521 - Test loss: 0.8761 - Test score: 0.2277\n",
      "Epoch 29/300 - Train loss: 0.6524 - Test loss: 0.8674 - Test score: 0.2402\n",
      "Epoch 30/300 - Train loss: 0.6492 - Test loss: 0.8657 - Test score: 0.2399\n",
      "Epoch 31/300 - Train loss: 0.6463 - Test loss: 0.8693 - Test score: 0.2332\n",
      "Epoch 32/300 - Train loss: 0.6442 - Test loss: 0.8955 - Test score: 0.2242\n",
      "Epoch 33/300 - Train loss: 0.6431 - Test loss: 0.8612 - Test score: 0.2534\n",
      "Epoch 34/300 - Train loss: 0.6373 - Test loss: 0.8762 - Test score: 0.2246\n",
      "Epoch 35/300 - Train loss: 0.6376 - Test loss: 0.8581 - Test score: 0.2547\n",
      "Epoch 36/300 - Train loss: 0.6291 - Test loss: 0.8578 - Test score: 0.2541\n",
      "Epoch 37/300 - Train loss: 0.6301 - Test loss: 0.8714 - Test score: 0.2253\n",
      "Epoch 38/300 - Train loss: 0.6278 - Test loss: 0.8556 - Test score: 0.2539\n",
      "Epoch 39/300 - Train loss: 0.6272 - Test loss: 0.8525 - Test score: 0.2583\n",
      "Epoch 40/300 - Train loss: 0.6250 - Test loss: 0.8574 - Test score: 0.2465\n",
      "Epoch 41/300 - Train loss: 0.6248 - Test loss: 0.8531 - Test score: 0.2603\n",
      "Epoch 42/300 - Train loss: 0.6187 - Test loss: 0.8605 - Test score: 0.2387\n",
      "Epoch 43/300 - Train loss: 0.6239 - Test loss: 0.8499 - Test score: 0.2533\n",
      "Epoch 44/300 - Train loss: 0.6152 - Test loss: 0.8554 - Test score: 0.2583\n",
      "Epoch 45/300 - Train loss: 0.6130 - Test loss: 0.8479 - Test score: 0.2564\n",
      "Epoch 46/300 - Train loss: 0.6284 - Test loss: 0.8666 - Test score: 0.2504\n",
      "Epoch 47/300 - Train loss: 0.6126 - Test loss: 0.8424 - Test score: 0.2609\n",
      "Epoch 48/300 - Train loss: 0.6073 - Test loss: 0.8472 - Test score: 0.2576\n",
      "Epoch 49/300 - Train loss: 0.6176 - Test loss: 0.8419 - Test score: 0.2678\n",
      "Epoch 50/300 - Train loss: 0.6098 - Test loss: 0.8480 - Test score: 0.2522\n",
      "Epoch 51/300 - Train loss: 0.6048 - Test loss: 0.8426 - Test score: 0.2680\n",
      "Epoch 52/300 - Train loss: 0.6041 - Test loss: 0.8424 - Test score: 0.2583\n",
      "Epoch 53/300 - Train loss: 0.6011 - Test loss: 0.8395 - Test score: 0.2712\n",
      "Epoch 54/300 - Train loss: 0.6027 - Test loss: 0.8482 - Test score: 0.2670\n",
      "Epoch 55/300 - Train loss: 0.5989 - Test loss: 0.8379 - Test score: 0.2715\n",
      "Epoch 56/300 - Train loss: 0.5974 - Test loss: 0.8353 - Test score: 0.2738\n",
      "Epoch 57/300 - Train loss: 0.5971 - Test loss: 0.8502 - Test score: 0.2625\n",
      "Epoch 58/300 - Train loss: 0.5959 - Test loss: 0.8302 - Test score: 0.2759\n",
      "Epoch 59/300 - Train loss: 0.5944 - Test loss: 0.8411 - Test score: 0.2708\n",
      "Epoch 60/300 - Train loss: 0.5923 - Test loss: 0.8390 - Test score: 0.2733\n",
      "Epoch 61/300 - Train loss: 0.5900 - Test loss: 0.8334 - Test score: 0.2760\n",
      "Epoch 62/300 - Train loss: 0.5922 - Test loss: 0.8476 - Test score: 0.2445\n",
      "Epoch 63/300 - Train loss: 0.5929 - Test loss: 0.8396 - Test score: 0.2727\n",
      "Epoch 64/300 - Train loss: 0.5896 - Test loss: 0.8295 - Test score: 0.2758\n",
      "Epoch 65/300 - Train loss: 0.5955 - Test loss: 0.8454 - Test score: 0.2476\n",
      "Epoch 66/300 - Train loss: 0.5895 - Test loss: 0.8359 - Test score: 0.2730\n",
      "Epoch 67/300 - Train loss: 0.5861 - Test loss: 0.8303 - Test score: 0.2736\n",
      "Epoch 68/300 - Train loss: 0.5833 - Test loss: 0.8287 - Test score: 0.2762\n",
      "Epoch 69/300 - Train loss: 0.5835 - Test loss: 0.8343 - Test score: 0.2629\n",
      "Epoch 70/300 - Train loss: 0.5903 - Test loss: 0.8276 - Test score: 0.2785\n",
      "Epoch 71/300 - Train loss: 0.5796 - Test loss: 0.8272 - Test score: 0.2732\n",
      "Epoch 72/300 - Train loss: 0.5816 - Test loss: 0.8267 - Test score: 0.2795\n",
      "Epoch 73/300 - Train loss: 0.5776 - Test loss: 0.8255 - Test score: 0.2771\n",
      "Epoch 74/300 - Train loss: 0.5775 - Test loss: 0.8262 - Test score: 0.2776\n",
      "Epoch 75/300 - Train loss: 0.5768 - Test loss: 0.8289 - Test score: 0.2773\n",
      "Epoch 76/300 - Train loss: 0.5773 - Test loss: 0.8385 - Test score: 0.2732\n",
      "Epoch 77/300 - Train loss: 0.5810 - Test loss: 0.8230 - Test score: 0.2810\n",
      "Epoch 78/300 - Train loss: 0.5745 - Test loss: 0.8226 - Test score: 0.2765\n",
      "Epoch 79/300 - Train loss: 0.5725 - Test loss: 0.8242 - Test score: 0.2746\n",
      "Epoch 80/300 - Train loss: 0.5766 - Test loss: 0.8232 - Test score: 0.2785\n",
      "Epoch 81/300 - Train loss: 0.5727 - Test loss: 0.8317 - Test score: 0.2625\n",
      "Epoch 82/300 - Train loss: 0.5681 - Test loss: 0.8217 - Test score: 0.2852\n",
      "Epoch 83/300 - Train loss: 0.5793 - Test loss: 0.8222 - Test score: 0.2757\n",
      "Epoch 84/300 - Train loss: 0.5685 - Test loss: 0.8238 - Test score: 0.2741\n",
      "Epoch 85/300 - Train loss: 0.5732 - Test loss: 0.8230 - Test score: 0.2845\n",
      "Epoch 86/300 - Train loss: 0.5684 - Test loss: 0.8324 - Test score: 0.2589\n",
      "Epoch 87/300 - Train loss: 0.5705 - Test loss: 0.8247 - Test score: 0.2808\n",
      "Epoch 88/300 - Train loss: 0.5634 - Test loss: 0.8200 - Test score: 0.2810\n",
      "Epoch 89/300 - Train loss: 0.5647 - Test loss: 0.8366 - Test score: 0.2508\n",
      "Epoch 90/300 - Train loss: 0.5658 - Test loss: 0.8197 - Test score: 0.2819\n",
      "Epoch 91/300 - Train loss: 0.5615 - Test loss: 0.8193 - Test score: 0.2852\n",
      "Epoch 92/300 - Train loss: 0.5651 - Test loss: 0.8209 - Test score: 0.2832\n",
      "\n",
      "Layer 4 - Score: 0.2852\n",
      "Layer 5 - Score: 0.3168\n",
      "Layer 6 - Score: 0.3170\n",
      "Epoch 1/300 - Train loss: 1.3888 - Test loss: 1.3028 - Test score: -0.2168\n",
      "Epoch 2/300 - Train loss: 1.1229 - Test loss: 1.2408 - Test score: -0.1606\n",
      "Epoch 3/300 - Train loss: 1.0635 - Test loss: 1.1755 - Test score: -0.0829\n",
      "Epoch 4/300 - Train loss: 1.0278 - Test loss: 1.1399 - Test score: -0.0345\n",
      "Epoch 5/300 - Train loss: 0.9964 - Test loss: 1.1205 - Test score: -0.0223\n",
      "Epoch 6/300 - Train loss: 0.9803 - Test loss: 1.1035 - Test score: 0.0015\n",
      "Epoch 7/300 - Train loss: 0.9669 - Test loss: 1.0930 - Test score: 0.0052\n",
      "Epoch 8/300 - Train loss: 0.9525 - Test loss: 1.1017 - Test score: -0.0139\n",
      "Epoch 9/300 - Train loss: 0.9448 - Test loss: 1.0757 - Test score: 0.0363\n",
      "Epoch 10/300 - Train loss: 0.9329 - Test loss: 1.0605 - Test score: 0.0451\n",
      "Epoch 11/300 - Train loss: 0.9220 - Test loss: 1.0527 - Test score: 0.0534\n",
      "Epoch 12/300 - Train loss: 0.9133 - Test loss: 1.0506 - Test score: 0.0499\n",
      "Epoch 13/300 - Train loss: 0.9077 - Test loss: 1.0410 - Test score: 0.0639\n",
      "Epoch 14/300 - Train loss: 0.8996 - Test loss: 1.0414 - Test score: 0.0723\n",
      "Epoch 15/300 - Train loss: 0.8988 - Test loss: 1.0317 - Test score: 0.0725\n",
      "Epoch 16/300 - Train loss: 0.8869 - Test loss: 1.0306 - Test score: 0.0703\n",
      "Epoch 17/300 - Train loss: 0.8839 - Test loss: 1.0357 - Test score: 0.0815\n",
      "Epoch 18/300 - Train loss: 0.8819 - Test loss: 1.0233 - Test score: 0.0910\n",
      "Epoch 19/300 - Train loss: 0.8753 - Test loss: 1.0178 - Test score: 0.0938\n",
      "Epoch 20/300 - Train loss: 0.8680 - Test loss: 1.0124 - Test score: 0.0968\n",
      "Epoch 21/300 - Train loss: 0.8680 - Test loss: 1.0093 - Test score: 0.0961\n",
      "Epoch 22/300 - Train loss: 0.8648 - Test loss: 1.0097 - Test score: 0.0924\n",
      "Epoch 23/300 - Train loss: 0.8620 - Test loss: 1.0167 - Test score: 0.1011\n",
      "Epoch 24/300 - Train loss: 0.8574 - Test loss: 1.0127 - Test score: 0.0842\n",
      "Epoch 25/300 - Train loss: 0.8538 - Test loss: 0.9997 - Test score: 0.1135\n",
      "Epoch 26/300 - Train loss: 0.8536 - Test loss: 0.9991 - Test score: 0.1039\n",
      "Epoch 27/300 - Train loss: 0.8488 - Test loss: 1.0030 - Test score: 0.1136\n",
      "Epoch 28/300 - Train loss: 0.8552 - Test loss: 1.0024 - Test score: 0.1148\n",
      "Epoch 29/300 - Train loss: 0.8511 - Test loss: 0.9901 - Test score: 0.1215\n",
      "Epoch 30/300 - Train loss: 0.8423 - Test loss: 1.0177 - Test score: 0.0715\n",
      "Epoch 31/300 - Train loss: 0.8421 - Test loss: 1.0116 - Test score: 0.0793\n",
      "Epoch 32/300 - Train loss: 0.8360 - Test loss: 0.9862 - Test score: 0.1207\n",
      "Epoch 33/300 - Train loss: 0.8369 - Test loss: 1.0100 - Test score: 0.0797\n",
      "Epoch 34/300 - Train loss: 0.8455 - Test loss: 0.9838 - Test score: 0.1213\n",
      "Epoch 35/300 - Train loss: 0.8315 - Test loss: 0.9854 - Test score: 0.1292\n",
      "Epoch 36/300 - Train loss: 0.8307 - Test loss: 0.9786 - Test score: 0.1305\n",
      "Epoch 37/300 - Train loss: 0.8269 - Test loss: 0.9837 - Test score: 0.1166\n",
      "Epoch 38/300 - Train loss: 0.8267 - Test loss: 0.9782 - Test score: 0.1357\n",
      "Epoch 39/300 - Train loss: 0.8311 - Test loss: 0.9802 - Test score: 0.1208\n",
      "Epoch 40/300 - Train loss: 0.8266 - Test loss: 0.9781 - Test score: 0.1242\n",
      "Epoch 41/300 - Train loss: 0.8187 - Test loss: 0.9721 - Test score: 0.1401\n",
      "Epoch 42/300 - Train loss: 0.8183 - Test loss: 0.9698 - Test score: 0.1400\n",
      "Epoch 43/300 - Train loss: 0.8215 - Test loss: 0.9837 - Test score: 0.1121\n",
      "Epoch 44/300 - Train loss: 0.8230 - Test loss: 0.9706 - Test score: 0.1337\n",
      "Epoch 45/300 - Train loss: 0.8146 - Test loss: 0.9875 - Test score: 0.1064\n",
      "Epoch 46/300 - Train loss: 0.8175 - Test loss: 0.9732 - Test score: 0.1434\n",
      "Epoch 47/300 - Train loss: 0.8145 - Test loss: 0.9687 - Test score: 0.1346\n",
      "Epoch 48/300 - Train loss: 0.8130 - Test loss: 0.9688 - Test score: 0.1469\n",
      "Epoch 49/300 - Train loss: 0.8098 - Test loss: 0.9631 - Test score: 0.1439\n",
      "Epoch 50/300 - Train loss: 0.8171 - Test loss: 0.9631 - Test score: 0.1427\n",
      "Epoch 51/300 - Train loss: 0.8153 - Test loss: 0.9862 - Test score: 0.1048\n",
      "Epoch 52/300 - Train loss: 0.8078 - Test loss: 0.9628 - Test score: 0.1411\n",
      "Epoch 53/300 - Train loss: 0.8160 - Test loss: 0.9628 - Test score: 0.1402\n",
      "Epoch 54/300 - Train loss: 0.8035 - Test loss: 0.9713 - Test score: 0.1261\n",
      "Epoch 55/300 - Train loss: 0.8038 - Test loss: 0.9591 - Test score: 0.1546\n",
      "Epoch 56/300 - Train loss: 0.8013 - Test loss: 0.9822 - Test score: 0.1096\n",
      "Epoch 57/300 - Train loss: 0.8023 - Test loss: 0.9934 - Test score: 0.1282\n",
      "Epoch 58/300 - Train loss: 0.8016 - Test loss: 0.9767 - Test score: 0.1163\n",
      "Epoch 59/300 - Train loss: 0.8043 - Test loss: 0.9560 - Test score: 0.1578\n",
      "Epoch 60/300 - Train loss: 0.8030 - Test loss: 0.9527 - Test score: 0.1566\n",
      "Epoch 61/300 - Train loss: 0.8017 - Test loss: 0.9540 - Test score: 0.1591\n",
      "Epoch 62/300 - Train loss: 0.7981 - Test loss: 0.9531 - Test score: 0.1533\n",
      "Epoch 63/300 - Train loss: 0.8064 - Test loss: 0.9509 - Test score: 0.1589\n",
      "Epoch 64/300 - Train loss: 0.7922 - Test loss: 0.9510 - Test score: 0.1605\n",
      "Epoch 65/300 - Train loss: 0.7967 - Test loss: 0.9517 - Test score: 0.1623\n",
      "Epoch 66/300 - Train loss: 0.7981 - Test loss: 0.9621 - Test score: 0.1354\n",
      "Epoch 67/300 - Train loss: 0.7926 - Test loss: 0.9530 - Test score: 0.1501\n",
      "Epoch 68/300 - Train loss: 0.7911 - Test loss: 0.9489 - Test score: 0.1581\n",
      "Epoch 69/300 - Train loss: 0.7918 - Test loss: 0.9666 - Test score: 0.1276\n",
      "Epoch 70/300 - Train loss: 0.7902 - Test loss: 0.9472 - Test score: 0.1618\n",
      "Epoch 71/300 - Train loss: 0.7878 - Test loss: 0.9536 - Test score: 0.1630\n",
      "Epoch 72/300 - Train loss: 0.7901 - Test loss: 0.9650 - Test score: 0.1537\n",
      "Epoch 73/300 - Train loss: 0.7870 - Test loss: 0.9454 - Test score: 0.1645\n",
      "Epoch 74/300 - Train loss: 0.7882 - Test loss: 0.9496 - Test score: 0.1532\n",
      "Epoch 75/300 - Train loss: 0.7869 - Test loss: 0.9914 - Test score: 0.0922\n",
      "Epoch 76/300 - Train loss: 0.7860 - Test loss: 0.9444 - Test score: 0.1687\n",
      "Epoch 77/300 - Train loss: 0.7842 - Test loss: 0.9417 - Test score: 0.1683\n",
      "Epoch 78/300 - Train loss: 0.7856 - Test loss: 0.9413 - Test score: 0.1690\n",
      "Epoch 79/300 - Train loss: 0.7850 - Test loss: 0.9422 - Test score: 0.1654\n",
      "Epoch 80/300 - Train loss: 0.7908 - Test loss: 0.9414 - Test score: 0.1683\n",
      "Epoch 81/300 - Train loss: 0.7841 - Test loss: 0.9642 - Test score: 0.1290\n",
      "Epoch 82/300 - Train loss: 0.7843 - Test loss: 0.9525 - Test score: 0.1656\n",
      "Epoch 83/300 - Train loss: 0.7842 - Test loss: 0.9421 - Test score: 0.1710\n",
      "Epoch 84/300 - Train loss: 0.7886 - Test loss: 0.9468 - Test score: 0.1536\n",
      "Epoch 85/300 - Train loss: 0.7778 - Test loss: 0.9401 - Test score: 0.1719\n",
      "Epoch 86/300 - Train loss: 0.7796 - Test loss: 0.9386 - Test score: 0.1743\n",
      "Epoch 87/300 - Train loss: 0.7795 - Test loss: 0.9388 - Test score: 0.1676\n",
      "Epoch 88/300 - Train loss: 0.7810 - Test loss: 0.9466 - Test score: 0.1531\n",
      "Epoch 89/300 - Train loss: 0.7775 - Test loss: 0.9447 - Test score: 0.1718\n",
      "Epoch 90/300 - Train loss: 0.7789 - Test loss: 0.9373 - Test score: 0.1731\n",
      "Epoch 91/300 - Train loss: 0.7773 - Test loss: 0.9358 - Test score: 0.1743\n",
      "Epoch 92/300 - Train loss: 0.7791 - Test loss: 0.9393 - Test score: 0.1753\n",
      "Epoch 93/300 - Train loss: 0.7761 - Test loss: 0.9357 - Test score: 0.1747\n",
      "Epoch 94/300 - Train loss: 0.7739 - Test loss: 0.9351 - Test score: 0.1736\n",
      "Epoch 95/300 - Train loss: 0.7779 - Test loss: 0.9361 - Test score: 0.1722\n",
      "Epoch 96/300 - Train loss: 0.7757 - Test loss: 0.9472 - Test score: 0.1515\n",
      "Epoch 97/300 - Train loss: 0.7743 - Test loss: 0.9351 - Test score: 0.1764\n",
      "Epoch 98/300 - Train loss: 0.7705 - Test loss: 0.9387 - Test score: 0.1766\n",
      "Epoch 99/300 - Train loss: 0.7733 - Test loss: 0.9709 - Test score: 0.1163\n",
      "Epoch 100/300 - Train loss: 0.7787 - Test loss: 0.9337 - Test score: 0.1773\n",
      "Epoch 101/300 - Train loss: 0.7717 - Test loss: 0.9339 - Test score: 0.1721\n",
      "Epoch 102/300 - Train loss: 0.7719 - Test loss: 0.9442 - Test score: 0.1535\n",
      "Epoch 103/300 - Train loss: 0.7724 - Test loss: 0.9329 - Test score: 0.1789\n",
      "Epoch 104/300 - Train loss: 0.7713 - Test loss: 0.9356 - Test score: 0.1683\n",
      "Epoch 105/300 - Train loss: 0.7721 - Test loss: 0.9312 - Test score: 0.1791\n",
      "Epoch 106/300 - Train loss: 0.7791 - Test loss: 0.9329 - Test score: 0.1722\n",
      "Epoch 107/300 - Train loss: 0.7742 - Test loss: 0.9341 - Test score: 0.1797\n",
      "Epoch 108/300 - Train loss: 0.7730 - Test loss: 0.9409 - Test score: 0.1585\n",
      "Epoch 109/300 - Train loss: 0.7684 - Test loss: 0.9338 - Test score: 0.1816\n",
      "Epoch 110/300 - Train loss: 0.7685 - Test loss: 0.9313 - Test score: 0.1754\n",
      "Epoch 111/300 - Train loss: 0.7669 - Test loss: 0.9307 - Test score: 0.1810\n",
      "Epoch 112/300 - Train loss: 0.7657 - Test loss: 0.9318 - Test score: 0.1813\n",
      "Epoch 113/300 - Train loss: 0.7641 - Test loss: 0.9450 - Test score: 0.1737\n",
      "Epoch 114/300 - Train loss: 0.7688 - Test loss: 0.9385 - Test score: 0.1606\n",
      "Epoch 115/300 - Train loss: 0.7643 - Test loss: 0.9291 - Test score: 0.1794\n",
      "Epoch 116/300 - Train loss: 0.7656 - Test loss: 0.9295 - Test score: 0.1756\n",
      "Epoch 117/300 - Train loss: 0.7665 - Test loss: 0.9316 - Test score: 0.1729\n",
      "Epoch 118/300 - Train loss: 0.7662 - Test loss: 0.9343 - Test score: 0.1669\n",
      "Epoch 119/300 - Train loss: 0.7644 - Test loss: 0.9371 - Test score: 0.1626\n",
      "\n",
      "Layer 7 - Score: 0.1816\n",
      "Epoch 1/300 - Train loss: 1.2387 - Test loss: 1.2649 - Test score: -0.1409\n",
      "Epoch 2/300 - Train loss: 1.0590 - Test loss: 1.1882 - Test score: -0.0643\n",
      "Epoch 3/300 - Train loss: 1.0120 - Test loss: 1.1638 - Test score: -0.0432\n",
      "Epoch 4/300 - Train loss: 0.9930 - Test loss: 1.1555 - Test score: -0.0368\n",
      "Epoch 5/300 - Train loss: 0.9832 - Test loss: 1.1498 - Test score: -0.0292\n",
      "Epoch 6/300 - Train loss: 0.9788 - Test loss: 1.1480 - Test score: -0.0295\n",
      "Epoch 7/300 - Train loss: 0.9740 - Test loss: 1.1452 - Test score: -0.0263\n",
      "Epoch 8/300 - Train loss: 0.9700 - Test loss: 1.1412 - Test score: -0.0191\n",
      "Epoch 9/300 - Train loss: 0.9663 - Test loss: 1.1388 - Test score: -0.0159\n",
      "Epoch 10/300 - Train loss: 0.9638 - Test loss: 1.1382 - Test score: -0.0178\n",
      "Epoch 11/300 - Train loss: 0.9617 - Test loss: 1.1351 - Test score: -0.0130\n",
      "Epoch 12/300 - Train loss: 0.9581 - Test loss: 1.1327 - Test score: -0.0078\n",
      "Epoch 13/300 - Train loss: 0.9571 - Test loss: 1.1321 - Test score: -0.0101\n",
      "Epoch 14/300 - Train loss: 0.9521 - Test loss: 1.1297 - Test score: -0.0062\n",
      "Epoch 15/300 - Train loss: 0.9513 - Test loss: 1.1281 - Test score: -0.0037\n",
      "Epoch 16/300 - Train loss: 0.9491 - Test loss: 1.1275 - Test score: -0.0045\n",
      "Epoch 17/300 - Train loss: 0.9468 - Test loss: 1.1252 - Test score: 0.0025\n",
      "Epoch 18/300 - Train loss: 0.9471 - Test loss: 1.1237 - Test score: 0.0031\n",
      "Epoch 19/300 - Train loss: 0.9427 - Test loss: 1.1227 - Test score: 0.0026\n",
      "Epoch 20/300 - Train loss: 0.9428 - Test loss: 1.1217 - Test score: 0.0038\n",
      "Epoch 21/300 - Train loss: 0.9395 - Test loss: 1.1204 - Test score: 0.0057\n",
      "Epoch 22/300 - Train loss: 0.9399 - Test loss: 1.1193 - Test score: 0.0074\n",
      "Epoch 23/300 - Train loss: 0.9347 - Test loss: 1.1191 - Test score: 0.0057\n",
      "Epoch 24/300 - Train loss: 0.9343 - Test loss: 1.1191 - Test score: 0.0045\n",
      "Epoch 25/300 - Train loss: 0.9326 - Test loss: 1.1185 - Test score: 0.0048\n",
      "Epoch 26/300 - Train loss: 0.9340 - Test loss: 1.1174 - Test score: 0.0063\n",
      "Epoch 27/300 - Train loss: 0.9311 - Test loss: 1.1153 - Test score: 0.0112\n",
      "Epoch 28/300 - Train loss: 0.9416 - Test loss: 1.1154 - Test score: 0.0095\n",
      "Epoch 29/300 - Train loss: 0.9293 - Test loss: 1.1139 - Test score: 0.0124\n",
      "Epoch 30/300 - Train loss: 0.9269 - Test loss: 1.1138 - Test score: 0.0112\n",
      "Epoch 31/300 - Train loss: 0.9263 - Test loss: 1.1122 - Test score: 0.0177\n",
      "Epoch 32/300 - Train loss: 0.9254 - Test loss: 1.1146 - Test score: 0.0084\n",
      "Epoch 33/300 - Train loss: 0.9243 - Test loss: 1.1109 - Test score: 0.0165\n",
      "Epoch 34/300 - Train loss: 0.9218 - Test loss: 1.1102 - Test score: 0.0184\n",
      "Epoch 35/300 - Train loss: 0.9224 - Test loss: 1.1096 - Test score: 0.0194\n",
      "Epoch 36/300 - Train loss: 0.9197 - Test loss: 1.1092 - Test score: 0.0203\n",
      "Epoch 37/300 - Train loss: 0.9217 - Test loss: 1.1087 - Test score: 0.0199\n",
      "Epoch 38/300 - Train loss: 0.9184 - Test loss: 1.1084 - Test score: 0.0191\n",
      "Epoch 39/300 - Train loss: 0.9183 - Test loss: 1.1079 - Test score: 0.0215\n",
      "Epoch 40/300 - Train loss: 0.9183 - Test loss: 1.1078 - Test score: 0.0192\n",
      "Epoch 41/300 - Train loss: 0.9157 - Test loss: 1.1085 - Test score: 0.0166\n",
      "Epoch 42/300 - Train loss: 0.9146 - Test loss: 1.1065 - Test score: 0.0236\n",
      "Epoch 43/300 - Train loss: 0.9148 - Test loss: 1.1074 - Test score: 0.0186\n",
      "Epoch 44/300 - Train loss: 0.9154 - Test loss: 1.1059 - Test score: 0.0222\n",
      "Epoch 45/300 - Train loss: 0.9140 - Test loss: 1.1055 - Test score: 0.0231\n",
      "Epoch 46/300 - Train loss: 0.9193 - Test loss: 1.1052 - Test score: 0.0224\n",
      "Epoch 47/300 - Train loss: 0.9145 - Test loss: 1.1047 - Test score: 0.0256\n",
      "Epoch 48/300 - Train loss: 0.9109 - Test loss: 1.1085 - Test score: 0.0147\n",
      "Epoch 49/300 - Train loss: 0.9130 - Test loss: 1.1039 - Test score: 0.0256\n",
      "Epoch 50/300 - Train loss: 0.9189 - Test loss: 1.1037 - Test score: 0.0252\n",
      "Epoch 51/300 - Train loss: 0.9095 - Test loss: 1.1034 - Test score: 0.0262\n",
      "Epoch 52/300 - Train loss: 0.9103 - Test loss: 1.1033 - Test score: 0.0254\n",
      "Epoch 53/300 - Train loss: 0.9091 - Test loss: 1.1030 - Test score: 0.0254\n",
      "Epoch 54/300 - Train loss: 0.9090 - Test loss: 1.1029 - Test score: 0.0252\n",
      "Epoch 55/300 - Train loss: 0.9076 - Test loss: 1.1027 - Test score: 0.0254\n",
      "Epoch 56/300 - Train loss: 0.9065 - Test loss: 1.1021 - Test score: 0.0270\n",
      "Epoch 57/300 - Train loss: 0.9070 - Test loss: 1.1018 - Test score: 0.0289\n",
      "Epoch 58/300 - Train loss: 0.9071 - Test loss: 1.1021 - Test score: 0.0255\n",
      "Epoch 59/300 - Train loss: 0.9064 - Test loss: 1.1024 - Test score: 0.0248\n",
      "Epoch 60/300 - Train loss: 0.9074 - Test loss: 1.1013 - Test score: 0.0277\n",
      "Epoch 61/300 - Train loss: 0.9053 - Test loss: 1.1011 - Test score: 0.0279\n",
      "Epoch 62/300 - Train loss: 0.9060 - Test loss: 1.1009 - Test score: 0.0301\n",
      "Epoch 63/300 - Train loss: 0.9032 - Test loss: 1.1029 - Test score: 0.0228\n",
      "Epoch 64/300 - Train loss: 0.9046 - Test loss: 1.1003 - Test score: 0.0292\n",
      "Epoch 65/300 - Train loss: 0.9054 - Test loss: 1.1003 - Test score: 0.0284\n",
      "Epoch 66/300 - Train loss: 0.9017 - Test loss: 1.0998 - Test score: 0.0298\n",
      "Epoch 67/300 - Train loss: 0.9006 - Test loss: 1.0998 - Test score: 0.0304\n",
      "Epoch 68/300 - Train loss: 0.9028 - Test loss: 1.0998 - Test score: 0.0297\n",
      "Epoch 69/300 - Train loss: 0.9029 - Test loss: 1.0996 - Test score: 0.0309\n",
      "Epoch 70/300 - Train loss: 0.9026 - Test loss: 1.0994 - Test score: 0.0302\n",
      "Epoch 71/300 - Train loss: 0.9027 - Test loss: 1.1002 - Test score: 0.0271\n",
      "Epoch 72/300 - Train loss: 0.9022 - Test loss: 1.0992 - Test score: 0.0314\n",
      "Epoch 73/300 - Train loss: 0.8999 - Test loss: 1.0995 - Test score: 0.0285\n",
      "Epoch 74/300 - Train loss: 0.9040 - Test loss: 1.1003 - Test score: 0.0264\n",
      "Epoch 75/300 - Train loss: 0.9057 - Test loss: 1.0988 - Test score: 0.0316\n",
      "Epoch 76/300 - Train loss: 0.8986 - Test loss: 1.1011 - Test score: 0.0247\n",
      "Epoch 77/300 - Train loss: 0.8981 - Test loss: 1.0986 - Test score: 0.0307\n",
      "Epoch 78/300 - Train loss: 0.8971 - Test loss: 1.0985 - Test score: 0.0304\n",
      "Epoch 79/300 - Train loss: 0.9000 - Test loss: 1.0997 - Test score: 0.0271\n",
      "Epoch 80/300 - Train loss: 0.9009 - Test loss: 1.0982 - Test score: 0.0338\n",
      "Epoch 81/300 - Train loss: 0.8999 - Test loss: 1.0980 - Test score: 0.0327\n",
      "Epoch 82/300 - Train loss: 0.8977 - Test loss: 1.0979 - Test score: 0.0319\n",
      "Epoch 83/300 - Train loss: 0.8978 - Test loss: 1.0977 - Test score: 0.0324\n",
      "Epoch 84/300 - Train loss: 0.9043 - Test loss: 1.0981 - Test score: 0.0305\n",
      "Epoch 85/300 - Train loss: 0.8980 - Test loss: 1.0982 - Test score: 0.0298\n",
      "Epoch 86/300 - Train loss: 0.8981 - Test loss: 1.0974 - Test score: 0.0335\n",
      "Epoch 87/300 - Train loss: 0.8956 - Test loss: 1.0993 - Test score: 0.0271\n",
      "Epoch 88/300 - Train loss: 0.8985 - Test loss: 1.0971 - Test score: 0.0336\n",
      "Epoch 89/300 - Train loss: 0.8964 - Test loss: 1.0975 - Test score: 0.0312\n",
      "Epoch 90/300 - Train loss: 0.9033 - Test loss: 1.0975 - Test score: 0.0343\n",
      "Epoch 91/300 - Train loss: 0.8967 - Test loss: 1.0977 - Test score: 0.0304\n",
      "Epoch 92/300 - Train loss: 0.8942 - Test loss: 1.0970 - Test score: 0.0343\n",
      "Epoch 93/300 - Train loss: 0.8933 - Test loss: 1.0968 - Test score: 0.0340\n",
      "Epoch 94/300 - Train loss: 0.8953 - Test loss: 1.0966 - Test score: 0.0340\n",
      "Epoch 95/300 - Train loss: 0.8926 - Test loss: 1.0979 - Test score: 0.0294\n",
      "Epoch 96/300 - Train loss: 0.8950 - Test loss: 1.0988 - Test score: 0.0272\n",
      "Epoch 97/300 - Train loss: 0.8945 - Test loss: 1.0971 - Test score: 0.0313\n",
      "Epoch 98/300 - Train loss: 0.8940 - Test loss: 1.0965 - Test score: 0.0334\n",
      "Epoch 99/300 - Train loss: 0.8921 - Test loss: 1.0968 - Test score: 0.0314\n",
      "Epoch 100/300 - Train loss: 0.8932 - Test loss: 1.0962 - Test score: 0.0336\n",
      "\n",
      "Layer 8 - Score: 0.0343\n",
      "Epoch 1/300 - Train loss: 0.9931 - Test loss: 1.1144 - Test score: 0.0055\n",
      "Epoch 2/300 - Train loss: 0.9398 - Test loss: 1.1311 - Test score: -0.0354\n",
      "Epoch 3/300 - Train loss: 0.9198 - Test loss: 1.1442 - Test score: -0.0606\n",
      "Epoch 4/300 - Train loss: 0.9239 - Test loss: 1.1663 - Test score: -0.0941\n",
      "Epoch 5/300 - Train loss: 0.8932 - Test loss: 1.0876 - Test score: 0.0401\n",
      "Epoch 6/300 - Train loss: 0.8865 - Test loss: 1.0648 - Test score: 0.0612\n",
      "Epoch 7/300 - Train loss: 0.8755 - Test loss: 1.0450 - Test score: 0.0523\n",
      "Epoch 8/300 - Train loss: 0.8684 - Test loss: 1.0355 - Test score: 0.0872\n",
      "Epoch 9/300 - Train loss: 0.8595 - Test loss: 1.0156 - Test score: 0.1025\n",
      "Epoch 10/300 - Train loss: 0.8394 - Test loss: 1.0137 - Test score: 0.0854\n",
      "Epoch 11/300 - Train loss: 0.8520 - Test loss: 1.0130 - Test score: 0.0828\n",
      "Epoch 12/300 - Train loss: 0.8199 - Test loss: 0.9972 - Test score: 0.1046\n",
      "Epoch 13/300 - Train loss: 0.8076 - Test loss: 1.0019 - Test score: 0.1161\n",
      "Epoch 14/300 - Train loss: 0.8062 - Test loss: 0.9823 - Test score: 0.1197\n",
      "Epoch 15/300 - Train loss: 0.8093 - Test loss: 0.9716 - Test score: 0.1360\n",
      "Epoch 16/300 - Train loss: 0.7870 - Test loss: 0.9698 - Test score: 0.1325\n",
      "Epoch 17/300 - Train loss: 0.7810 - Test loss: 0.9768 - Test score: 0.1185\n",
      "Epoch 18/300 - Train loss: 0.7689 - Test loss: 1.0199 - Test score: 0.0990\n",
      "Epoch 19/300 - Train loss: 0.7759 - Test loss: 0.9962 - Test score: 0.0881\n",
      "Epoch 20/300 - Train loss: 0.7605 - Test loss: 0.9488 - Test score: 0.1608\n",
      "Epoch 21/300 - Train loss: 0.7661 - Test loss: 1.0373 - Test score: 0.0804\n",
      "Epoch 22/300 - Train loss: 0.7661 - Test loss: 0.9410 - Test score: 0.1678\n",
      "Epoch 23/300 - Train loss: 0.7381 - Test loss: 1.0324 - Test score: 0.0848\n",
      "Epoch 24/300 - Train loss: 0.7345 - Test loss: 0.9323 - Test score: 0.1719\n",
      "Epoch 25/300 - Train loss: 0.7226 - Test loss: 0.9282 - Test score: 0.1731\n",
      "Epoch 26/300 - Train loss: 0.7149 - Test loss: 0.9261 - Test score: 0.1819\n",
      "Epoch 27/300 - Train loss: 0.7315 - Test loss: 0.9494 - Test score: 0.1642\n",
      "Epoch 28/300 - Train loss: 0.7152 - Test loss: 0.9186 - Test score: 0.1823\n",
      "Epoch 29/300 - Train loss: 0.7008 - Test loss: 0.9635 - Test score: 0.1144\n",
      "Epoch 30/300 - Train loss: 0.6993 - Test loss: 0.9105 - Test score: 0.1933\n",
      "Epoch 31/300 - Train loss: 0.6947 - Test loss: 0.9380 - Test score: 0.1730\n",
      "Epoch 32/300 - Train loss: 0.6971 - Test loss: 0.9031 - Test score: 0.1988\n",
      "Epoch 33/300 - Train loss: 0.6815 - Test loss: 0.9000 - Test score: 0.1990\n",
      "Epoch 34/300 - Train loss: 0.6723 - Test loss: 0.9391 - Test score: 0.1402\n",
      "Epoch 35/300 - Train loss: 0.6689 - Test loss: 0.8991 - Test score: 0.2049\n",
      "Epoch 36/300 - Train loss: 0.6701 - Test loss: 0.8920 - Test score: 0.2070\n",
      "Epoch 37/300 - Train loss: 0.6597 - Test loss: 0.8952 - Test score: 0.2097\n",
      "Epoch 38/300 - Train loss: 0.6656 - Test loss: 0.9056 - Test score: 0.1803\n",
      "Epoch 39/300 - Train loss: 0.6749 - Test loss: 0.8975 - Test score: 0.2081\n",
      "Epoch 40/300 - Train loss: 0.6527 - Test loss: 0.8831 - Test score: 0.2133\n",
      "Epoch 41/300 - Train loss: 0.6404 - Test loss: 0.8808 - Test score: 0.2195\n",
      "Epoch 42/300 - Train loss: 0.6395 - Test loss: 0.8881 - Test score: 0.1999\n",
      "Epoch 43/300 - Train loss: 0.6301 - Test loss: 0.8742 - Test score: 0.2223\n",
      "Epoch 44/300 - Train loss: 0.6286 - Test loss: 0.8730 - Test score: 0.2222\n",
      "Epoch 45/300 - Train loss: 0.6339 - Test loss: 0.8702 - Test score: 0.2283\n",
      "Epoch 46/300 - Train loss: 0.6230 - Test loss: 0.9153 - Test score: 0.1580\n",
      "Epoch 47/300 - Train loss: 0.6165 - Test loss: 0.8692 - Test score: 0.2208\n",
      "Epoch 48/300 - Train loss: 0.6387 - Test loss: 0.8884 - Test score: 0.2156\n",
      "Epoch 49/300 - Train loss: 0.6038 - Test loss: 0.8615 - Test score: 0.2312\n",
      "Epoch 50/300 - Train loss: 0.6116 - Test loss: 0.9111 - Test score: 0.1587\n",
      "Epoch 51/300 - Train loss: 0.6069 - Test loss: 0.8579 - Test score: 0.2338\n",
      "Epoch 52/300 - Train loss: 0.6074 - Test loss: 0.8849 - Test score: 0.1909\n",
      "Epoch 53/300 - Train loss: 0.5940 - Test loss: 0.8824 - Test score: 0.1942\n",
      "Epoch 54/300 - Train loss: 0.5941 - Test loss: 0.8686 - Test score: 0.2119\n",
      "Epoch 55/300 - Train loss: 0.5972 - Test loss: 0.9555 - Test score: 0.0978\n",
      "Epoch 56/300 - Train loss: 0.5834 - Test loss: 0.8872 - Test score: 0.2144\n",
      "Epoch 57/300 - Train loss: 0.5922 - Test loss: 0.8641 - Test score: 0.2148\n",
      "Epoch 58/300 - Train loss: 0.5844 - Test loss: 0.8660 - Test score: 0.2340\n",
      "Epoch 59/300 - Train loss: 0.5696 - Test loss: 0.8468 - Test score: 0.2488\n",
      "Epoch 60/300 - Train loss: 0.5747 - Test loss: 0.8602 - Test score: 0.2172\n",
      "Epoch 61/300 - Train loss: 0.5682 - Test loss: 0.8384 - Test score: 0.2482\n",
      "Epoch 62/300 - Train loss: 0.5830 - Test loss: 0.8376 - Test score: 0.2514\n",
      "Epoch 63/300 - Train loss: 0.5575 - Test loss: 0.8778 - Test score: 0.2215\n",
      "Epoch 64/300 - Train loss: 0.5681 - Test loss: 0.8345 - Test score: 0.2514\n",
      "Epoch 65/300 - Train loss: 0.5561 - Test loss: 0.8521 - Test score: 0.2444\n",
      "Epoch 66/300 - Train loss: 0.5610 - Test loss: 0.8354 - Test score: 0.2575\n",
      "Epoch 67/300 - Train loss: 0.5467 - Test loss: 0.8497 - Test score: 0.2463\n",
      "Epoch 68/300 - Train loss: 0.5563 - Test loss: 0.8296 - Test score: 0.2608\n",
      "Epoch 69/300 - Train loss: 0.5529 - Test loss: 0.8416 - Test score: 0.2534\n",
      "Epoch 70/300 - Train loss: 0.5312 - Test loss: 0.8258 - Test score: 0.2646\n",
      "Epoch 71/300 - Train loss: 0.5400 - Test loss: 0.8345 - Test score: 0.2431\n",
      "Epoch 72/300 - Train loss: 0.5304 - Test loss: 0.8240 - Test score: 0.2649\n",
      "Epoch 73/300 - Train loss: 0.5261 - Test loss: 0.8259 - Test score: 0.2538\n",
      "Epoch 74/300 - Train loss: 0.5392 - Test loss: 0.8867 - Test score: 0.1699\n",
      "Epoch 75/300 - Train loss: 0.5333 - Test loss: 0.8202 - Test score: 0.2608\n",
      "Epoch 76/300 - Train loss: 0.5165 - Test loss: 0.8183 - Test score: 0.2697\n",
      "Epoch 77/300 - Train loss: 0.5301 - Test loss: 0.8196 - Test score: 0.2599\n",
      "Epoch 78/300 - Train loss: 0.5283 - Test loss: 0.8238 - Test score: 0.2527\n",
      "Epoch 79/300 - Train loss: 0.5152 - Test loss: 0.8226 - Test score: 0.2522\n",
      "Epoch 80/300 - Train loss: 0.5073 - Test loss: 0.8541 - Test score: 0.2095\n",
      "Epoch 81/300 - Train loss: 0.5200 - Test loss: 0.8107 - Test score: 0.2711\n",
      "Epoch 82/300 - Train loss: 0.5238 - Test loss: 0.8122 - Test score: 0.2657\n",
      "Epoch 83/300 - Train loss: 0.5336 - Test loss: 0.8127 - Test score: 0.2740\n",
      "Epoch 84/300 - Train loss: 0.4979 - Test loss: 0.8090 - Test score: 0.2700\n",
      "Epoch 85/300 - Train loss: 0.4983 - Test loss: 0.8072 - Test score: 0.2766\n",
      "Epoch 86/300 - Train loss: 0.4972 - Test loss: 0.8084 - Test score: 0.2731\n",
      "Epoch 87/300 - Train loss: 0.4999 - Test loss: 0.8410 - Test score: 0.2220\n",
      "Epoch 88/300 - Train loss: 0.4984 - Test loss: 0.8056 - Test score: 0.2785\n",
      "Epoch 89/300 - Train loss: 0.4996 - Test loss: 0.8181 - Test score: 0.2512\n",
      "Epoch 90/300 - Train loss: 0.4901 - Test loss: 0.8071 - Test score: 0.2666\n",
      "Epoch 91/300 - Train loss: 0.5023 - Test loss: 0.8315 - Test score: 0.2306\n",
      "Epoch 92/300 - Train loss: 0.5089 - Test loss: 0.8027 - Test score: 0.2733\n",
      "Epoch 93/300 - Train loss: 0.4951 - Test loss: 0.8127 - Test score: 0.2747\n",
      "Epoch 94/300 - Train loss: 0.4883 - Test loss: 0.8023 - Test score: 0.2711\n",
      "Epoch 95/300 - Train loss: 0.4847 - Test loss: 0.8567 - Test score: 0.1960\n",
      "Epoch 96/300 - Train loss: 0.4758 - Test loss: 0.7968 - Test score: 0.2813\n",
      "Epoch 97/300 - Train loss: 0.4754 - Test loss: 0.8025 - Test score: 0.2683\n",
      "Epoch 98/300 - Train loss: 0.4715 - Test loss: 0.7974 - Test score: 0.2765\n",
      "Epoch 99/300 - Train loss: 0.4716 - Test loss: 0.7978 - Test score: 0.2761\n",
      "Epoch 100/300 - Train loss: 0.4667 - Test loss: 0.8073 - Test score: 0.2594\n",
      "Epoch 101/300 - Train loss: 0.4800 - Test loss: 0.8338 - Test score: 0.2212\n",
      "Epoch 102/300 - Train loss: 0.4631 - Test loss: 0.7900 - Test score: 0.2863\n",
      "Epoch 103/300 - Train loss: 0.4691 - Test loss: 0.7981 - Test score: 0.2708\n",
      "Epoch 104/300 - Train loss: 0.4705 - Test loss: 0.7916 - Test score: 0.2829\n",
      "Epoch 105/300 - Train loss: 0.4500 - Test loss: 0.7901 - Test score: 0.2851\n",
      "Epoch 106/300 - Train loss: 0.4525 - Test loss: 0.8125 - Test score: 0.2488\n",
      "Epoch 107/300 - Train loss: 0.4632 - Test loss: 0.7898 - Test score: 0.2892\n",
      "Epoch 108/300 - Train loss: 0.4506 - Test loss: 0.8208 - Test score: 0.2356\n",
      "Epoch 109/300 - Train loss: 0.4532 - Test loss: 0.7866 - Test score: 0.2910\n",
      "Epoch 110/300 - Train loss: 0.4471 - Test loss: 0.7852 - Test score: 0.2896\n",
      "Epoch 111/300 - Train loss: 0.4429 - Test loss: 0.8755 - Test score: 0.1637\n",
      "Epoch 112/300 - Train loss: 0.4421 - Test loss: 0.7951 - Test score: 0.2845\n",
      "Epoch 113/300 - Train loss: 0.4467 - Test loss: 0.8383 - Test score: 0.2457\n",
      "Epoch 114/300 - Train loss: 0.4444 - Test loss: 0.8046 - Test score: 0.2547\n",
      "Epoch 115/300 - Train loss: 0.4441 - Test loss: 0.7929 - Test score: 0.2701\n",
      "Epoch 116/300 - Train loss: 0.4474 - Test loss: 0.7819 - Test score: 0.2904\n",
      "Epoch 117/300 - Train loss: 0.4407 - Test loss: 0.7831 - Test score: 0.2915\n",
      "Epoch 118/300 - Train loss: 0.4384 - Test loss: 0.8060 - Test score: 0.2510\n",
      "Epoch 119/300 - Train loss: 0.4384 - Test loss: 0.8080 - Test score: 0.2726\n",
      "Epoch 120/300 - Train loss: 0.4390 - Test loss: 0.7917 - Test score: 0.2686\n",
      "Epoch 121/300 - Train loss: 0.4307 - Test loss: 0.7791 - Test score: 0.2923\n",
      "Epoch 122/300 - Train loss: 0.4385 - Test loss: 0.8029 - Test score: 0.2765\n",
      "Epoch 123/300 - Train loss: 0.4243 - Test loss: 0.7808 - Test score: 0.2854\n",
      "Epoch 124/300 - Train loss: 0.4234 - Test loss: 0.8558 - Test score: 0.1828\n",
      "Epoch 125/300 - Train loss: 0.4432 - Test loss: 0.7860 - Test score: 0.2883\n",
      "Epoch 126/300 - Train loss: 0.4182 - Test loss: 0.7795 - Test score: 0.2853\n",
      "Epoch 127/300 - Train loss: 0.4187 - Test loss: 0.7887 - Test score: 0.2877\n",
      "Epoch 128/300 - Train loss: 0.4273 - Test loss: 0.7747 - Test score: 0.2943\n",
      "Epoch 129/300 - Train loss: 0.4192 - Test loss: 0.7857 - Test score: 0.2745\n",
      "Epoch 130/300 - Train loss: 0.4181 - Test loss: 0.7932 - Test score: 0.2618\n",
      "Epoch 131/300 - Train loss: 0.4195 - Test loss: 1.0089 - Test score: -0.0096\n",
      "Epoch 132/300 - Train loss: 0.4234 - Test loss: 0.7770 - Test score: 0.2947\n",
      "Epoch 133/300 - Train loss: 0.4158 - Test loss: 0.7781 - Test score: 0.2847\n",
      "Epoch 134/300 - Train loss: 0.4083 - Test loss: 0.7743 - Test score: 0.2929\n",
      "Epoch 135/300 - Train loss: 0.4107 - Test loss: 0.7779 - Test score: 0.2826\n",
      "Epoch 136/300 - Train loss: 0.4145 - Test loss: 0.7848 - Test score: 0.2896\n",
      "Epoch 137/300 - Train loss: 0.4086 - Test loss: 0.7890 - Test score: 0.2856\n",
      "Epoch 138/300 - Train loss: 0.4045 - Test loss: 0.7836 - Test score: 0.2891\n",
      "Epoch 139/300 - Train loss: 0.4021 - Test loss: 0.8268 - Test score: 0.2136\n",
      "Epoch 140/300 - Train loss: 0.4152 - Test loss: 0.8550 - Test score: 0.1781\n",
      "Epoch 141/300 - Train loss: 0.4108 - Test loss: 0.7826 - Test score: 0.2913\n",
      "Epoch 142/300 - Train loss: 0.4044 - Test loss: 0.7706 - Test score: 0.2975\n",
      "Epoch 143/300 - Train loss: 0.4028 - Test loss: 0.7716 - Test score: 0.2957\n",
      "Epoch 144/300 - Train loss: 0.4002 - Test loss: 0.7715 - Test score: 0.2969\n",
      "Epoch 145/300 - Train loss: 0.3966 - Test loss: 0.7687 - Test score: 0.2985\n",
      "Epoch 146/300 - Train loss: 0.3879 - Test loss: 0.7833 - Test score: 0.2891\n",
      "Epoch 147/300 - Train loss: 0.3949 - Test loss: 0.7685 - Test score: 0.2961\n",
      "Epoch 148/300 - Train loss: 0.4028 - Test loss: 0.7896 - Test score: 0.2600\n",
      "Epoch 149/300 - Train loss: 0.3890 - Test loss: 0.7849 - Test score: 0.2672\n",
      "Epoch 150/300 - Train loss: 0.3859 - Test loss: 0.8023 - Test score: 0.2429\n",
      "Epoch 151/300 - Train loss: 0.3928 - Test loss: 0.7681 - Test score: 0.2937\n",
      "Epoch 152/300 - Train loss: 0.3854 - Test loss: 0.7668 - Test score: 0.2973\n",
      "Epoch 153/300 - Train loss: 0.3807 - Test loss: 0.7683 - Test score: 0.2919\n",
      "Epoch 154/300 - Train loss: 0.3892 - Test loss: 0.7906 - Test score: 0.2580\n",
      "Epoch 155/300 - Train loss: 0.3825 - Test loss: 0.8780 - Test score: 0.1440\n",
      "\n",
      "Layer obs - Score: 0.2985\n",
      "Average score over all layers: 0.2554\n",
      "frames until collision vertical\n",
      "Layer 0 - Score: 0.3470\n",
      "Layer 1 - Score: 0.3725\n",
      "Layer 2 - Score: 0.3302\n",
      "Layer 3 - Score: 0.3544\n",
      "Layer 4 - Score: 0.3339\n",
      "Layer 5 - Score: 0.3534\n",
      "Layer 6 - Score: 0.3529\n",
      "Epoch 1/300 - Train loss: 1.7236 - Test loss: 1.3102 - Test score: -0.4557\n",
      "Epoch 2/300 - Train loss: 1.2128 - Test loss: 1.1731 - Test score: -0.2732\n",
      "Epoch 3/300 - Train loss: 1.1245 - Test loss: 1.1159 - Test score: -0.1869\n",
      "Epoch 4/300 - Train loss: 1.0792 - Test loss: 1.0782 - Test score: -0.1238\n",
      "Epoch 5/300 - Train loss: 1.0472 - Test loss: 1.0647 - Test score: -0.0844\n",
      "Epoch 6/300 - Train loss: 1.0173 - Test loss: 1.0307 - Test score: -0.0636\n",
      "Epoch 7/300 - Train loss: 0.9952 - Test loss: 1.0083 - Test score: -0.0286\n",
      "Epoch 8/300 - Train loss: 0.9714 - Test loss: 0.9984 - Test score: -0.0311\n",
      "Epoch 9/300 - Train loss: 0.9539 - Test loss: 0.9746 - Test score: 0.0168\n",
      "Epoch 10/300 - Train loss: 0.9387 - Test loss: 0.9610 - Test score: 0.0398\n",
      "Epoch 11/300 - Train loss: 0.9277 - Test loss: 0.9510 - Test score: 0.0362\n",
      "Epoch 12/300 - Train loss: 0.9138 - Test loss: 0.9391 - Test score: 0.0525\n",
      "Epoch 13/300 - Train loss: 0.8986 - Test loss: 0.9385 - Test score: 0.0418\n",
      "Epoch 14/300 - Train loss: 0.8878 - Test loss: 0.9203 - Test score: 0.0740\n",
      "Epoch 15/300 - Train loss: 0.8852 - Test loss: 0.9194 - Test score: 0.0664\n",
      "Epoch 16/300 - Train loss: 0.8734 - Test loss: 0.9011 - Test score: 0.1104\n",
      "Epoch 17/300 - Train loss: 0.8614 - Test loss: 0.9153 - Test score: 0.0623\n",
      "Epoch 18/300 - Train loss: 0.8534 - Test loss: 0.8870 - Test score: 0.1274\n",
      "Epoch 19/300 - Train loss: 0.8455 - Test loss: 0.9023 - Test score: 0.1300\n",
      "Epoch 20/300 - Train loss: 0.8468 - Test loss: 0.8793 - Test score: 0.1304\n",
      "Epoch 21/300 - Train loss: 0.8360 - Test loss: 0.8715 - Test score: 0.1477\n",
      "Epoch 22/300 - Train loss: 0.8303 - Test loss: 0.8682 - Test score: 0.1567\n",
      "Epoch 23/300 - Train loss: 0.8298 - Test loss: 0.8646 - Test score: 0.1499\n",
      "Epoch 24/300 - Train loss: 0.8193 - Test loss: 0.8609 - Test score: 0.1603\n",
      "Epoch 25/300 - Train loss: 0.8180 - Test loss: 0.8963 - Test score: 0.0720\n",
      "Epoch 26/300 - Train loss: 0.8170 - Test loss: 0.8545 - Test score: 0.1742\n",
      "Epoch 27/300 - Train loss: 0.8077 - Test loss: 0.8534 - Test score: 0.1783\n",
      "Epoch 28/300 - Train loss: 0.8010 - Test loss: 0.8531 - Test score: 0.1551\n",
      "Epoch 29/300 - Train loss: 0.7983 - Test loss: 0.8500 - Test score: 0.1604\n",
      "Epoch 30/300 - Train loss: 0.7960 - Test loss: 0.8430 - Test score: 0.1831\n",
      "Epoch 31/300 - Train loss: 0.7954 - Test loss: 0.8413 - Test score: 0.1889\n",
      "Epoch 32/300 - Train loss: 0.7917 - Test loss: 0.8509 - Test score: 0.1488\n",
      "Epoch 33/300 - Train loss: 0.7903 - Test loss: 0.8384 - Test score: 0.1876\n",
      "Epoch 34/300 - Train loss: 0.7824 - Test loss: 0.8369 - Test score: 0.1944\n",
      "Epoch 35/300 - Train loss: 0.7837 - Test loss: 0.8334 - Test score: 0.1908\n",
      "Epoch 36/300 - Train loss: 0.7792 - Test loss: 0.8333 - Test score: 0.1971\n",
      "Epoch 37/300 - Train loss: 0.7814 - Test loss: 0.8349 - Test score: 0.1776\n",
      "Epoch 38/300 - Train loss: 0.7747 - Test loss: 0.8370 - Test score: 0.2029\n",
      "Epoch 39/300 - Train loss: 0.7820 - Test loss: 0.8270 - Test score: 0.1954\n",
      "Epoch 40/300 - Train loss: 0.7688 - Test loss: 0.8257 - Test score: 0.2031\n",
      "Epoch 41/300 - Train loss: 0.7783 - Test loss: 0.8316 - Test score: 0.2073\n",
      "Epoch 42/300 - Train loss: 0.7689 - Test loss: 0.8347 - Test score: 0.1690\n",
      "Epoch 43/300 - Train loss: 0.7680 - Test loss: 0.8342 - Test score: 0.1686\n",
      "Epoch 44/300 - Train loss: 0.7667 - Test loss: 0.8214 - Test score: 0.2107\n",
      "Epoch 45/300 - Train loss: 0.7648 - Test loss: 0.8216 - Test score: 0.2103\n",
      "Epoch 46/300 - Train loss: 0.7624 - Test loss: 0.8218 - Test score: 0.1989\n",
      "Epoch 47/300 - Train loss: 0.7624 - Test loss: 0.8196 - Test score: 0.2022\n",
      "Epoch 48/300 - Train loss: 0.7671 - Test loss: 0.8257 - Test score: 0.1829\n",
      "Epoch 49/300 - Train loss: 0.7624 - Test loss: 0.8163 - Test score: 0.2146\n",
      "Epoch 50/300 - Train loss: 0.7583 - Test loss: 0.8319 - Test score: 0.2125\n",
      "Epoch 51/300 - Train loss: 0.7616 - Test loss: 0.8175 - Test score: 0.2046\n",
      "Epoch 52/300 - Train loss: 0.7553 - Test loss: 0.8142 - Test score: 0.2187\n",
      "Epoch 53/300 - Train loss: 0.7587 - Test loss: 0.8129 - Test score: 0.2140\n",
      "Epoch 54/300 - Train loss: 0.7565 - Test loss: 0.8221 - Test score: 0.1870\n",
      "Epoch 55/300 - Train loss: 0.7528 - Test loss: 0.8132 - Test score: 0.2202\n",
      "Epoch 56/300 - Train loss: 0.7522 - Test loss: 0.8164 - Test score: 0.2221\n",
      "Epoch 57/300 - Train loss: 0.7511 - Test loss: 0.8102 - Test score: 0.2173\n",
      "Epoch 58/300 - Train loss: 0.7458 - Test loss: 0.8093 - Test score: 0.2239\n",
      "Epoch 59/300 - Train loss: 0.7532 - Test loss: 0.8108 - Test score: 0.2237\n",
      "Epoch 60/300 - Train loss: 0.7498 - Test loss: 0.8090 - Test score: 0.2270\n",
      "Epoch 61/300 - Train loss: 0.7453 - Test loss: 0.8141 - Test score: 0.2235\n",
      "Epoch 62/300 - Train loss: 0.7465 - Test loss: 0.8079 - Test score: 0.2226\n",
      "Epoch 63/300 - Train loss: 0.7418 - Test loss: 0.8132 - Test score: 0.2289\n",
      "Epoch 64/300 - Train loss: 0.7474 - Test loss: 0.8066 - Test score: 0.2181\n",
      "Epoch 65/300 - Train loss: 0.7424 - Test loss: 0.8208 - Test score: 0.1809\n",
      "Epoch 66/300 - Train loss: 0.7500 - Test loss: 0.8064 - Test score: 0.2178\n",
      "Epoch 67/300 - Train loss: 0.7439 - Test loss: 0.8116 - Test score: 0.2265\n",
      "Epoch 68/300 - Train loss: 0.7393 - Test loss: 0.8048 - Test score: 0.2211\n",
      "Epoch 69/300 - Train loss: 0.7364 - Test loss: 0.8058 - Test score: 0.2323\n",
      "Epoch 70/300 - Train loss: 0.7374 - Test loss: 0.8041 - Test score: 0.2260\n",
      "Epoch 71/300 - Train loss: 0.7408 - Test loss: 0.8047 - Test score: 0.2333\n",
      "Epoch 72/300 - Train loss: 0.7376 - Test loss: 0.8123 - Test score: 0.1988\n",
      "Epoch 73/300 - Train loss: 0.7434 - Test loss: 0.8030 - Test score: 0.2254\n",
      "Epoch 74/300 - Train loss: 0.7426 - Test loss: 0.8022 - Test score: 0.2253\n",
      "Epoch 75/300 - Train loss: 0.7355 - Test loss: 0.8071 - Test score: 0.2350\n",
      "Epoch 76/300 - Train loss: 0.7393 - Test loss: 0.8006 - Test score: 0.2325\n",
      "Epoch 77/300 - Train loss: 0.7335 - Test loss: 0.8260 - Test score: 0.2222\n",
      "Epoch 78/300 - Train loss: 0.7380 - Test loss: 0.8013 - Test score: 0.2214\n",
      "Epoch 79/300 - Train loss: 0.7343 - Test loss: 0.8013 - Test score: 0.2246\n",
      "Epoch 80/300 - Train loss: 0.7307 - Test loss: 0.7993 - Test score: 0.2343\n",
      "Epoch 81/300 - Train loss: 0.7330 - Test loss: 0.8039 - Test score: 0.2115\n",
      "Epoch 82/300 - Train loss: 0.7318 - Test loss: 0.8048 - Test score: 0.2389\n",
      "Epoch 83/300 - Train loss: 0.7292 - Test loss: 0.8182 - Test score: 0.2289\n",
      "Epoch 84/300 - Train loss: 0.7281 - Test loss: 0.8008 - Test score: 0.2394\n",
      "Epoch 85/300 - Train loss: 0.7341 - Test loss: 0.8064 - Test score: 0.2047\n",
      "Epoch 86/300 - Train loss: 0.7281 - Test loss: 0.8382 - Test score: 0.1391\n",
      "Epoch 87/300 - Train loss: 0.7312 - Test loss: 0.8082 - Test score: 0.1993\n",
      "Epoch 88/300 - Train loss: 0.7278 - Test loss: 0.8011 - Test score: 0.2404\n",
      "Epoch 89/300 - Train loss: 0.7285 - Test loss: 0.8245 - Test score: 0.2247\n",
      "Epoch 90/300 - Train loss: 0.7283 - Test loss: 0.7966 - Test score: 0.2287\n",
      "Epoch 91/300 - Train loss: 0.7281 - Test loss: 0.7951 - Test score: 0.2364\n",
      "Epoch 92/300 - Train loss: 0.7238 - Test loss: 0.8412 - Test score: 0.1340\n",
      "Epoch 93/300 - Train loss: 0.7256 - Test loss: 0.8002 - Test score: 0.2186\n",
      "Epoch 94/300 - Train loss: 0.7267 - Test loss: 0.8060 - Test score: 0.2057\n",
      "Epoch 95/300 - Train loss: 0.7273 - Test loss: 0.7966 - Test score: 0.2271\n",
      "Epoch 96/300 - Train loss: 0.7272 - Test loss: 0.7992 - Test score: 0.2436\n",
      "Epoch 97/300 - Train loss: 0.7237 - Test loss: 0.7956 - Test score: 0.2408\n",
      "Epoch 98/300 - Train loss: 0.7262 - Test loss: 0.7958 - Test score: 0.2300\n",
      "Epoch 99/300 - Train loss: 0.7222 - Test loss: 0.7924 - Test score: 0.2384\n",
      "Epoch 100/300 - Train loss: 0.7222 - Test loss: 0.7952 - Test score: 0.2292\n",
      "Epoch 101/300 - Train loss: 0.7219 - Test loss: 0.8136 - Test score: 0.2349\n",
      "Epoch 102/300 - Train loss: 0.7245 - Test loss: 0.7922 - Test score: 0.2417\n",
      "Epoch 103/300 - Train loss: 0.7193 - Test loss: 0.7914 - Test score: 0.2394\n",
      "Epoch 104/300 - Train loss: 0.7258 - Test loss: 0.7931 - Test score: 0.2422\n",
      "Epoch 105/300 - Train loss: 0.7268 - Test loss: 0.7961 - Test score: 0.2236\n",
      "Epoch 106/300 - Train loss: 0.7299 - Test loss: 0.7960 - Test score: 0.2252\n",
      "\n",
      "Layer 7 - Score: 0.2436\n",
      "Epoch 1/300 - Train loss: 2.9842 - Test loss: 2.0531 - Test score: -1.3308\n",
      "Epoch 2/300 - Train loss: 1.6326 - Test loss: 1.3420 - Test score: -0.3898\n",
      "Epoch 3/300 - Train loss: 1.2202 - Test loss: 1.1346 - Test score: -0.1328\n",
      "Epoch 4/300 - Train loss: 1.0786 - Test loss: 1.0580 - Test score: -0.0409\n",
      "Epoch 5/300 - Train loss: 1.0146 - Test loss: 1.0231 - Test score: 0.0010\n",
      "Epoch 6/300 - Train loss: 0.9847 - Test loss: 1.0051 - Test score: 0.0226\n",
      "Epoch 7/300 - Train loss: 0.9558 - Test loss: 0.9956 - Test score: 0.0321\n",
      "Epoch 8/300 - Train loss: 0.9422 - Test loss: 0.9900 - Test score: 0.0369\n",
      "Epoch 9/300 - Train loss: 0.9318 - Test loss: 0.9865 - Test score: 0.0426\n",
      "Epoch 10/300 - Train loss: 0.9300 - Test loss: 0.9829 - Test score: 0.0453\n",
      "Epoch 11/300 - Train loss: 0.9179 - Test loss: 0.9796 - Test score: 0.0498\n",
      "Epoch 12/300 - Train loss: 0.9179 - Test loss: 0.9761 - Test score: 0.0518\n",
      "Epoch 13/300 - Train loss: 0.9219 - Test loss: 0.9730 - Test score: 0.0566\n",
      "Epoch 14/300 - Train loss: 0.9045 - Test loss: 0.9697 - Test score: 0.0608\n",
      "Epoch 15/300 - Train loss: 0.8974 - Test loss: 0.9668 - Test score: 0.0659\n",
      "Epoch 16/300 - Train loss: 0.8952 - Test loss: 0.9635 - Test score: 0.0698\n",
      "Epoch 17/300 - Train loss: 0.8900 - Test loss: 0.9600 - Test score: 0.0714\n",
      "Epoch 18/300 - Train loss: 0.8870 - Test loss: 0.9577 - Test score: 0.0780\n",
      "Epoch 19/300 - Train loss: 0.8848 - Test loss: 0.9547 - Test score: 0.0775\n",
      "Epoch 20/300 - Train loss: 0.8832 - Test loss: 0.9531 - Test score: 0.0853\n",
      "Epoch 21/300 - Train loss: 0.8777 - Test loss: 0.9496 - Test score: 0.0855\n",
      "Epoch 22/300 - Train loss: 0.8763 - Test loss: 0.9471 - Test score: 0.0884\n",
      "Epoch 23/300 - Train loss: 0.8745 - Test loss: 0.9455 - Test score: 0.0926\n",
      "Epoch 24/300 - Train loss: 0.8767 - Test loss: 0.9426 - Test score: 0.0937\n",
      "Epoch 25/300 - Train loss: 0.8677 - Test loss: 0.9409 - Test score: 0.0939\n",
      "Epoch 26/300 - Train loss: 0.8660 - Test loss: 0.9394 - Test score: 0.0978\n",
      "Epoch 27/300 - Train loss: 0.8637 - Test loss: 0.9379 - Test score: 0.0990\n",
      "Epoch 28/300 - Train loss: 0.8698 - Test loss: 0.9363 - Test score: 0.0987\n",
      "Epoch 29/300 - Train loss: 0.8619 - Test loss: 0.9343 - Test score: 0.1015\n",
      "Epoch 30/300 - Train loss: 0.8658 - Test loss: 0.9327 - Test score: 0.1016\n",
      "Epoch 31/300 - Train loss: 0.8569 - Test loss: 0.9316 - Test score: 0.1066\n",
      "Epoch 32/300 - Train loss: 0.8553 - Test loss: 0.9301 - Test score: 0.1051\n",
      "Epoch 33/300 - Train loss: 0.8556 - Test loss: 0.9288 - Test score: 0.1094\n",
      "Epoch 34/300 - Train loss: 0.8589 - Test loss: 0.9279 - Test score: 0.1067\n",
      "Epoch 35/300 - Train loss: 0.8596 - Test loss: 0.9267 - Test score: 0.1105\n",
      "Epoch 36/300 - Train loss: 0.8520 - Test loss: 0.9252 - Test score: 0.1105\n",
      "Epoch 37/300 - Train loss: 0.8552 - Test loss: 0.9243 - Test score: 0.1092\n",
      "Epoch 38/300 - Train loss: 0.8507 - Test loss: 0.9230 - Test score: 0.1143\n",
      "Epoch 39/300 - Train loss: 0.8533 - Test loss: 0.9238 - Test score: 0.1166\n",
      "Epoch 40/300 - Train loss: 0.8481 - Test loss: 0.9213 - Test score: 0.1161\n",
      "Epoch 41/300 - Train loss: 0.8451 - Test loss: 0.9214 - Test score: 0.1079\n",
      "Epoch 42/300 - Train loss: 0.8455 - Test loss: 0.9192 - Test score: 0.1125\n",
      "Epoch 43/300 - Train loss: 0.8444 - Test loss: 0.9182 - Test score: 0.1169\n",
      "Epoch 44/300 - Train loss: 0.8434 - Test loss: 0.9175 - Test score: 0.1172\n",
      "Epoch 45/300 - Train loss: 0.8488 - Test loss: 0.9173 - Test score: 0.1124\n",
      "Epoch 46/300 - Train loss: 0.8406 - Test loss: 0.9166 - Test score: 0.1161\n",
      "Epoch 47/300 - Train loss: 0.8399 - Test loss: 0.9158 - Test score: 0.1190\n",
      "Epoch 48/300 - Train loss: 0.8388 - Test loss: 0.9154 - Test score: 0.1204\n",
      "Epoch 49/300 - Train loss: 0.8382 - Test loss: 0.9139 - Test score: 0.1212\n",
      "Epoch 50/300 - Train loss: 0.8379 - Test loss: 0.9137 - Test score: 0.1171\n",
      "Epoch 51/300 - Train loss: 0.8520 - Test loss: 0.9143 - Test score: 0.1219\n",
      "Epoch 52/300 - Train loss: 0.8361 - Test loss: 0.9124 - Test score: 0.1194\n",
      "Epoch 53/300 - Train loss: 0.8351 - Test loss: 0.9122 - Test score: 0.1226\n",
      "Epoch 54/300 - Train loss: 0.8412 - Test loss: 0.9108 - Test score: 0.1226\n",
      "Epoch 55/300 - Train loss: 0.8374 - Test loss: 0.9106 - Test score: 0.1223\n",
      "Epoch 56/300 - Train loss: 0.8341 - Test loss: 0.9109 - Test score: 0.1176\n",
      "Epoch 57/300 - Train loss: 0.8333 - Test loss: 0.9103 - Test score: 0.1234\n",
      "Epoch 58/300 - Train loss: 0.8336 - Test loss: 0.9104 - Test score: 0.1261\n",
      "Epoch 59/300 - Train loss: 0.8374 - Test loss: 0.9089 - Test score: 0.1266\n",
      "Epoch 60/300 - Train loss: 0.8320 - Test loss: 0.9098 - Test score: 0.1164\n",
      "Epoch 61/300 - Train loss: 0.8364 - Test loss: 0.9084 - Test score: 0.1260\n",
      "Epoch 62/300 - Train loss: 0.8315 - Test loss: 0.9076 - Test score: 0.1273\n",
      "Epoch 63/300 - Train loss: 0.8298 - Test loss: 0.9073 - Test score: 0.1275\n",
      "Epoch 64/300 - Train loss: 0.8286 - Test loss: 0.9072 - Test score: 0.1222\n",
      "Epoch 65/300 - Train loss: 0.8306 - Test loss: 0.9065 - Test score: 0.1257\n",
      "Epoch 66/300 - Train loss: 0.8293 - Test loss: 0.9066 - Test score: 0.1285\n",
      "Epoch 67/300 - Train loss: 0.8315 - Test loss: 0.9059 - Test score: 0.1282\n",
      "Epoch 68/300 - Train loss: 0.8276 - Test loss: 0.9061 - Test score: 0.1244\n",
      "Epoch 69/300 - Train loss: 0.8331 - Test loss: 0.9053 - Test score: 0.1256\n",
      "Epoch 70/300 - Train loss: 0.8330 - Test loss: 0.9052 - Test score: 0.1282\n",
      "Epoch 71/300 - Train loss: 0.8325 - Test loss: 0.9048 - Test score: 0.1289\n",
      "Epoch 72/300 - Train loss: 0.8264 - Test loss: 0.9041 - Test score: 0.1307\n",
      "Epoch 73/300 - Train loss: 0.8252 - Test loss: 0.9040 - Test score: 0.1310\n",
      "Epoch 74/300 - Train loss: 0.8266 - Test loss: 0.9039 - Test score: 0.1294\n",
      "Epoch 75/300 - Train loss: 0.8397 - Test loss: 0.9040 - Test score: 0.1316\n",
      "Epoch 76/300 - Train loss: 0.8244 - Test loss: 0.9030 - Test score: 0.1313\n",
      "Epoch 77/300 - Train loss: 0.8233 - Test loss: 0.9050 - Test score: 0.1322\n",
      "Epoch 78/300 - Train loss: 0.8241 - Test loss: 0.9031 - Test score: 0.1294\n",
      "Epoch 79/300 - Train loss: 0.8238 - Test loss: 0.9033 - Test score: 0.1237\n",
      "Epoch 80/300 - Train loss: 0.8229 - Test loss: 0.9041 - Test score: 0.1325\n",
      "Epoch 81/300 - Train loss: 0.8233 - Test loss: 0.9017 - Test score: 0.1275\n",
      "Epoch 82/300 - Train loss: 0.8292 - Test loss: 0.9022 - Test score: 0.1275\n",
      "Epoch 83/300 - Train loss: 0.8229 - Test loss: 0.9020 - Test score: 0.1309\n",
      "Epoch 84/300 - Train loss: 0.8215 - Test loss: 0.9019 - Test score: 0.1316\n",
      "Epoch 85/300 - Train loss: 0.8238 - Test loss: 0.9018 - Test score: 0.1266\n",
      "Epoch 86/300 - Train loss: 0.8214 - Test loss: 0.9017 - Test score: 0.1266\n",
      "Epoch 87/300 - Train loss: 0.8216 - Test loss: 0.9013 - Test score: 0.1265\n",
      "Epoch 88/300 - Train loss: 0.8214 - Test loss: 0.9009 - Test score: 0.1300\n",
      "Epoch 89/300 - Train loss: 0.8221 - Test loss: 0.9010 - Test score: 0.1341\n",
      "Epoch 90/300 - Train loss: 0.8216 - Test loss: 0.9003 - Test score: 0.1314\n",
      "Epoch 91/300 - Train loss: 0.8207 - Test loss: 0.9004 - Test score: 0.1313\n",
      "Epoch 92/300 - Train loss: 0.8204 - Test loss: 0.9011 - Test score: 0.1344\n",
      "Epoch 93/300 - Train loss: 0.8202 - Test loss: 0.9000 - Test score: 0.1319\n",
      "Epoch 94/300 - Train loss: 0.8195 - Test loss: 0.9001 - Test score: 0.1329\n",
      "Epoch 95/300 - Train loss: 0.8192 - Test loss: 0.8996 - Test score: 0.1325\n",
      "Epoch 96/300 - Train loss: 0.8261 - Test loss: 0.9003 - Test score: 0.1338\n",
      "Epoch 97/300 - Train loss: 0.8201 - Test loss: 0.9014 - Test score: 0.1342\n",
      "Epoch 98/300 - Train loss: 0.8182 - Test loss: 0.9002 - Test score: 0.1336\n",
      "Epoch 99/300 - Train loss: 0.8210 - Test loss: 0.8988 - Test score: 0.1313\n",
      "Epoch 100/300 - Train loss: 0.8190 - Test loss: 0.8996 - Test score: 0.1336\n",
      "Epoch 101/300 - Train loss: 0.8178 - Test loss: 0.8999 - Test score: 0.1334\n",
      "Epoch 102/300 - Train loss: 0.8192 - Test loss: 0.8995 - Test score: 0.1344\n",
      "Epoch 103/300 - Train loss: 0.8175 - Test loss: 0.8996 - Test score: 0.1350\n",
      "Epoch 104/300 - Train loss: 0.8168 - Test loss: 0.8994 - Test score: 0.1336\n",
      "Epoch 105/300 - Train loss: 0.8236 - Test loss: 0.8986 - Test score: 0.1297\n",
      "Epoch 106/300 - Train loss: 0.8237 - Test loss: 0.8986 - Test score: 0.1337\n",
      "Epoch 107/300 - Train loss: 0.8167 - Test loss: 0.8984 - Test score: 0.1307\n",
      "Epoch 108/300 - Train loss: 0.8159 - Test loss: 0.8985 - Test score: 0.1333\n",
      "Epoch 109/300 - Train loss: 0.8191 - Test loss: 0.8983 - Test score: 0.1338\n",
      "Epoch 110/300 - Train loss: 0.8155 - Test loss: 0.8974 - Test score: 0.1316\n",
      "Epoch 111/300 - Train loss: 0.8225 - Test loss: 0.8977 - Test score: 0.1328\n",
      "Epoch 112/300 - Train loss: 0.8171 - Test loss: 0.8972 - Test score: 0.1329\n",
      "Epoch 113/300 - Train loss: 0.8150 - Test loss: 0.8981 - Test score: 0.1346\n",
      "\n",
      "Layer 8 - Score: 0.1350\n",
      "Epoch 1/300 - Train loss: 1.0261 - Test loss: 1.0425 - Test score: -0.0195\n",
      "Epoch 2/300 - Train loss: 0.9861 - Test loss: 1.0450 - Test score: -0.0840\n",
      "Epoch 3/300 - Train loss: 0.9575 - Test loss: 1.1054 - Test score: -0.0862\n",
      "Epoch 4/300 - Train loss: 0.9413 - Test loss: 1.0014 - Test score: 0.0032\n",
      "Epoch 5/300 - Train loss: 0.9305 - Test loss: 1.0104 - Test score: -0.0390\n",
      "Epoch 6/300 - Train loss: 0.9288 - Test loss: 1.0381 - Test score: -0.0132\n",
      "Epoch 7/300 - Train loss: 0.9225 - Test loss: 1.0015 - Test score: -0.0334\n",
      "Epoch 8/300 - Train loss: 0.9139 - Test loss: 0.9921 - Test score: 0.0312\n",
      "Epoch 9/300 - Train loss: 0.9140 - Test loss: 1.0930 - Test score: -0.0769\n",
      "Epoch 10/300 - Train loss: 0.9016 - Test loss: 0.9771 - Test score: 0.0457\n",
      "Epoch 11/300 - Train loss: 0.8664 - Test loss: 1.2283 - Test score: -0.4418\n",
      "Epoch 12/300 - Train loss: 0.8857 - Test loss: 1.0451 - Test score: -0.1348\n",
      "Epoch 13/300 - Train loss: 0.8563 - Test loss: 0.9506 - Test score: 0.0677\n",
      "Epoch 14/300 - Train loss: 0.8402 - Test loss: 0.9939 - Test score: -0.0518\n",
      "Epoch 15/300 - Train loss: 0.8522 - Test loss: 0.9365 - Test score: 0.0710\n",
      "Epoch 16/300 - Train loss: 0.8248 - Test loss: 0.9704 - Test score: 0.0597\n",
      "Epoch 17/300 - Train loss: 0.8169 - Test loss: 0.9566 - Test score: 0.0091\n",
      "Epoch 18/300 - Train loss: 0.8241 - Test loss: 0.9287 - Test score: 0.0665\n",
      "Epoch 19/300 - Train loss: 0.8115 - Test loss: 0.9728 - Test score: 0.0594\n",
      "Epoch 20/300 - Train loss: 0.8054 - Test loss: 0.9175 - Test score: 0.1051\n",
      "Epoch 21/300 - Train loss: 0.7900 - Test loss: 0.9964 - Test score: -0.0770\n",
      "Epoch 22/300 - Train loss: 0.7927 - Test loss: 0.9101 - Test score: 0.0887\n",
      "Epoch 23/300 - Train loss: 0.7959 - Test loss: 0.9039 - Test score: 0.1000\n",
      "Epoch 24/300 - Train loss: 0.7787 - Test loss: 0.9063 - Test score: 0.0874\n",
      "Epoch 25/300 - Train loss: 0.7734 - Test loss: 0.9363 - Test score: 0.0221\n",
      "Epoch 26/300 - Train loss: 0.7723 - Test loss: 0.9573 - Test score: 0.0772\n",
      "Epoch 27/300 - Train loss: 0.7618 - Test loss: 0.8872 - Test score: 0.1379\n",
      "Epoch 28/300 - Train loss: 0.7475 - Test loss: 0.8915 - Test score: 0.1052\n",
      "Epoch 29/300 - Train loss: 0.7542 - Test loss: 0.9290 - Test score: 0.1073\n",
      "Epoch 30/300 - Train loss: 0.7527 - Test loss: 0.8832 - Test score: 0.1498\n",
      "Epoch 31/300 - Train loss: 0.7295 - Test loss: 0.8724 - Test score: 0.1513\n",
      "Epoch 32/300 - Train loss: 0.7288 - Test loss: 0.8679 - Test score: 0.1540\n",
      "Epoch 33/300 - Train loss: 0.7204 - Test loss: 0.9381 - Test score: 0.0007\n",
      "Epoch 34/300 - Train loss: 0.7422 - Test loss: 0.8697 - Test score: 0.1645\n",
      "Epoch 35/300 - Train loss: 0.7211 - Test loss: 0.8629 - Test score: 0.1681\n",
      "Epoch 36/300 - Train loss: 0.7221 - Test loss: 0.8779 - Test score: 0.1066\n",
      "Epoch 37/300 - Train loss: 0.7086 - Test loss: 0.8983 - Test score: 0.0651\n",
      "Epoch 38/300 - Train loss: 0.7209 - Test loss: 0.8740 - Test score: 0.1117\n",
      "Epoch 39/300 - Train loss: 0.7233 - Test loss: 0.9551 - Test score: 0.0790\n",
      "Epoch 40/300 - Train loss: 0.7119 - Test loss: 0.8451 - Test score: 0.1807\n",
      "Epoch 41/300 - Train loss: 0.6912 - Test loss: 0.8491 - Test score: 0.1882\n",
      "Epoch 42/300 - Train loss: 0.6836 - Test loss: 0.8563 - Test score: 0.1364\n",
      "Epoch 43/300 - Train loss: 0.6940 - Test loss: 0.8446 - Test score: 0.1604\n",
      "Epoch 44/300 - Train loss: 0.6823 - Test loss: 0.9105 - Test score: 0.0311\n",
      "Epoch 45/300 - Train loss: 0.6940 - Test loss: 0.8383 - Test score: 0.1698\n",
      "Epoch 46/300 - Train loss: 0.6834 - Test loss: 0.8703 - Test score: 0.1734\n",
      "Epoch 47/300 - Train loss: 0.6621 - Test loss: 0.8288 - Test score: 0.2026\n",
      "Epoch 48/300 - Train loss: 0.7088 - Test loss: 0.9589 - Test score: -0.0577\n",
      "Epoch 49/300 - Train loss: 0.6760 - Test loss: 0.8334 - Test score: 0.1712\n",
      "Epoch 50/300 - Train loss: 0.6560 - Test loss: 0.8425 - Test score: 0.2009\n",
      "Epoch 51/300 - Train loss: 0.6465 - Test loss: 0.8285 - Test score: 0.1760\n",
      "Epoch 52/300 - Train loss: 0.6593 - Test loss: 0.8216 - Test score: 0.2152\n",
      "Epoch 53/300 - Train loss: 0.6421 - Test loss: 0.8219 - Test score: 0.2174\n",
      "Epoch 54/300 - Train loss: 0.6479 - Test loss: 0.8130 - Test score: 0.2184\n",
      "Epoch 55/300 - Train loss: 0.6383 - Test loss: 0.8741 - Test score: 0.1678\n",
      "Epoch 56/300 - Train loss: 0.6481 - Test loss: 0.8299 - Test score: 0.1650\n",
      "Epoch 57/300 - Train loss: 0.6306 - Test loss: 0.8138 - Test score: 0.2246\n",
      "Epoch 58/300 - Train loss: 0.6325 - Test loss: 0.8128 - Test score: 0.1993\n",
      "Epoch 59/300 - Train loss: 0.6329 - Test loss: 0.8594 - Test score: 0.1029\n",
      "Epoch 60/300 - Train loss: 0.6204 - Test loss: 0.8026 - Test score: 0.2266\n",
      "Epoch 61/300 - Train loss: 0.6176 - Test loss: 0.8040 - Test score: 0.2337\n",
      "Epoch 62/300 - Train loss: 0.6309 - Test loss: 0.8063 - Test score: 0.2040\n",
      "Epoch 63/300 - Train loss: 0.6307 - Test loss: 0.8098 - Test score: 0.2288\n",
      "Epoch 64/300 - Train loss: 0.6120 - Test loss: 0.8105 - Test score: 0.1900\n",
      "Epoch 65/300 - Train loss: 0.6037 - Test loss: 0.8261 - Test score: 0.2192\n",
      "Epoch 66/300 - Train loss: 0.6115 - Test loss: 0.8072 - Test score: 0.1939\n",
      "Epoch 67/300 - Train loss: 0.6169 - Test loss: 0.7918 - Test score: 0.2315\n",
      "Epoch 68/300 - Train loss: 0.6146 - Test loss: 0.8054 - Test score: 0.2388\n",
      "Epoch 69/300 - Train loss: 0.6045 - Test loss: 0.7892 - Test score: 0.2433\n",
      "Epoch 70/300 - Train loss: 0.5986 - Test loss: 0.8281 - Test score: 0.2185\n",
      "Epoch 71/300 - Train loss: 0.6252 - Test loss: 0.8242 - Test score: 0.1530\n",
      "Epoch 72/300 - Train loss: 0.5823 - Test loss: 0.7940 - Test score: 0.2496\n",
      "Epoch 73/300 - Train loss: 0.5918 - Test loss: 0.8051 - Test score: 0.1915\n",
      "Epoch 74/300 - Train loss: 0.5838 - Test loss: 0.7805 - Test score: 0.2510\n",
      "Epoch 75/300 - Train loss: 0.5860 - Test loss: 0.7823 - Test score: 0.2384\n",
      "Epoch 76/300 - Train loss: 0.5897 - Test loss: 0.8174 - Test score: 0.1614\n",
      "Epoch 77/300 - Train loss: 0.5849 - Test loss: 0.7799 - Test score: 0.2387\n",
      "Epoch 78/300 - Train loss: 0.5735 - Test loss: 0.7773 - Test score: 0.2445\n",
      "Epoch 79/300 - Train loss: 0.5847 - Test loss: 0.7831 - Test score: 0.2258\n",
      "Epoch 80/300 - Train loss: 0.5737 - Test loss: 0.8093 - Test score: 0.1738\n",
      "Epoch 81/300 - Train loss: 0.5776 - Test loss: 0.8172 - Test score: 0.1577\n",
      "Epoch 82/300 - Train loss: 0.5655 - Test loss: 0.7837 - Test score: 0.2219\n",
      "Epoch 83/300 - Train loss: 0.5653 - Test loss: 0.8295 - Test score: 0.2161\n",
      "Epoch 84/300 - Train loss: 0.5622 - Test loss: 0.7704 - Test score: 0.2651\n",
      "Epoch 85/300 - Train loss: 0.5723 - Test loss: 0.7788 - Test score: 0.2624\n",
      "Epoch 86/300 - Train loss: 0.5730 - Test loss: 0.7681 - Test score: 0.2563\n",
      "Epoch 87/300 - Train loss: 0.5541 - Test loss: 0.7831 - Test score: 0.2606\n",
      "Epoch 88/300 - Train loss: 0.5586 - Test loss: 0.8413 - Test score: 0.1082\n",
      "Epoch 89/300 - Train loss: 0.5485 - Test loss: 0.7644 - Test score: 0.2661\n",
      "Epoch 90/300 - Train loss: 0.5497 - Test loss: 0.7674 - Test score: 0.2704\n",
      "Epoch 91/300 - Train loss: 0.5423 - Test loss: 0.7692 - Test score: 0.2418\n",
      "Epoch 92/300 - Train loss: 0.5478 - Test loss: 0.7712 - Test score: 0.2360\n",
      "Epoch 93/300 - Train loss: 0.5596 - Test loss: 0.7679 - Test score: 0.2722\n",
      "Epoch 94/300 - Train loss: 0.5452 - Test loss: 0.8058 - Test score: 0.1674\n",
      "Epoch 95/300 - Train loss: 0.5450 - Test loss: 0.8468 - Test score: 0.0940\n",
      "Epoch 96/300 - Train loss: 0.5412 - Test loss: 0.7795 - Test score: 0.2151\n",
      "Epoch 97/300 - Train loss: 0.5372 - Test loss: 0.7867 - Test score: 0.2571\n",
      "Epoch 98/300 - Train loss: 0.5427 - Test loss: 0.7567 - Test score: 0.2698\n",
      "Epoch 99/300 - Train loss: 0.5249 - Test loss: 0.7580 - Test score: 0.2631\n",
      "Epoch 100/300 - Train loss: 0.5416 - Test loss: 0.7549 - Test score: 0.2714\n",
      "Epoch 101/300 - Train loss: 0.5461 - Test loss: 0.7824 - Test score: 0.2602\n",
      "Epoch 102/300 - Train loss: 0.5310 - Test loss: 0.7586 - Test score: 0.2561\n",
      "Epoch 103/300 - Train loss: 0.5237 - Test loss: 0.7663 - Test score: 0.2752\n",
      "Epoch 104/300 - Train loss: 0.5383 - Test loss: 0.7714 - Test score: 0.2703\n",
      "Epoch 105/300 - Train loss: 0.5140 - Test loss: 0.7561 - Test score: 0.2586\n",
      "Epoch 106/300 - Train loss: 0.5558 - Test loss: 0.7770 - Test score: 0.2641\n",
      "Epoch 107/300 - Train loss: 0.5199 - Test loss: 0.7559 - Test score: 0.2565\n",
      "Epoch 108/300 - Train loss: 0.5224 - Test loss: 0.7911 - Test score: 0.1842\n",
      "Epoch 109/300 - Train loss: 0.5208 - Test loss: 0.7508 - Test score: 0.2676\n",
      "Epoch 110/300 - Train loss: 0.5169 - Test loss: 0.7498 - Test score: 0.2828\n",
      "Epoch 111/300 - Train loss: 0.5075 - Test loss: 0.7581 - Test score: 0.2483\n",
      "Epoch 112/300 - Train loss: 0.5056 - Test loss: 0.7517 - Test score: 0.2626\n",
      "Epoch 113/300 - Train loss: 0.5168 - Test loss: 0.7538 - Test score: 0.2843\n",
      "Epoch 114/300 - Train loss: 0.5058 - Test loss: 0.7602 - Test score: 0.2797\n",
      "Epoch 115/300 - Train loss: 0.5016 - Test loss: 0.7466 - Test score: 0.2731\n",
      "Epoch 116/300 - Train loss: 0.4982 - Test loss: 0.7879 - Test score: 0.1851\n",
      "Epoch 117/300 - Train loss: 0.5102 - Test loss: 0.7445 - Test score: 0.2804\n",
      "Epoch 118/300 - Train loss: 0.4949 - Test loss: 0.7453 - Test score: 0.2724\n",
      "Epoch 119/300 - Train loss: 0.5139 - Test loss: 0.7453 - Test score: 0.2867\n",
      "Epoch 120/300 - Train loss: 0.5127 - Test loss: 0.7617 - Test score: 0.2327\n",
      "Epoch 121/300 - Train loss: 0.4959 - Test loss: 0.7435 - Test score: 0.2892\n",
      "Epoch 122/300 - Train loss: 0.5018 - Test loss: 0.7510 - Test score: 0.2857\n",
      "Epoch 123/300 - Train loss: 0.5062 - Test loss: 0.7546 - Test score: 0.2469\n",
      "Epoch 124/300 - Train loss: 0.4943 - Test loss: 0.7467 - Test score: 0.2630\n",
      "Epoch 125/300 - Train loss: 0.4879 - Test loss: 0.7545 - Test score: 0.2456\n",
      "Epoch 126/300 - Train loss: 0.4945 - Test loss: 0.8195 - Test score: 0.1235\n",
      "Epoch 127/300 - Train loss: 0.4877 - Test loss: 0.7946 - Test score: 0.1688\n",
      "Epoch 128/300 - Train loss: 0.4985 - Test loss: 0.7686 - Test score: 0.2159\n",
      "Epoch 129/300 - Train loss: 0.4984 - Test loss: 0.7639 - Test score: 0.2226\n",
      "Epoch 130/300 - Train loss: 0.4880 - Test loss: 0.7528 - Test score: 0.2448\n",
      "Epoch 131/300 - Train loss: 0.4738 - Test loss: 0.7664 - Test score: 0.2177\n",
      "\n",
      "Layer obs - Score: 0.2892\n",
      "Average score over all layers: 0.3112\n",
      "paddle x\n",
      "Layer 0 - Score: 0.9946\n",
      "Layer 1 - Score: 0.9985\n",
      "Layer 2 - Score: 0.9956\n",
      "Layer 3 - Score: 0.9901\n",
      "Layer 4 - Score: 0.9787\n",
      "Layer 5 - Score: 0.9587\n",
      "Layer 6 - Score: 0.9586\n",
      "Layer 7 - Score: 0.9078\n",
      "Layer 8 - Score: 0.3113\n",
      "Layer obs - Score: 0.9937\n",
      "Average score over all layers: 0.9088\n",
      "ball speed horizontal\n",
      "Layer 0 - Score: 0.4345\n",
      "Layer 1 - Score: 0.5643\n",
      "Layer 2 - Score: 0.5472\n",
      "Layer 3 - Score: 0.6140\n",
      "Layer 4 - Score: 0.5730\n",
      "Layer 5 - Score: 0.6466\n",
      "Layer 6 - Score: 0.6451\n",
      "Layer 7 - Score: 0.4448\n",
      "Epoch 1/300 - Train loss: 10.2939 - Test loss: 8.3261 - Test score: -7.5063\n",
      "Epoch 2/300 - Train loss: 6.4335 - Test loss: 5.3290 - Test score: -4.4444\n",
      "Epoch 3/300 - Train loss: 4.1659 - Test loss: 3.6302 - Test score: -2.7069\n",
      "Epoch 4/300 - Train loss: 2.9337 - Test loss: 2.7177 - Test score: -1.7720\n",
      "Epoch 5/300 - Train loss: 2.2790 - Test loss: 2.2109 - Test score: -1.2519\n",
      "Epoch 6/300 - Train loss: 1.9117 - Test loss: 1.9010 - Test score: -0.9334\n",
      "Epoch 7/300 - Train loss: 1.6756 - Test loss: 1.6851 - Test score: -0.7114\n",
      "Epoch 8/300 - Train loss: 1.5102 - Test loss: 1.5312 - Test score: -0.5531\n",
      "Epoch 9/300 - Train loss: 1.3906 - Test loss: 1.4141 - Test score: -0.4326\n",
      "Epoch 10/300 - Train loss: 1.2990 - Test loss: 1.3249 - Test score: -0.3409\n",
      "Epoch 11/300 - Train loss: 1.2325 - Test loss: 1.2569 - Test score: -0.2709\n",
      "Epoch 12/300 - Train loss: 1.1798 - Test loss: 1.2061 - Test score: -0.2185\n",
      "Epoch 13/300 - Train loss: 1.1388 - Test loss: 1.1665 - Test score: -0.1777\n",
      "Epoch 14/300 - Train loss: 1.1091 - Test loss: 1.1350 - Test score: -0.1452\n",
      "Epoch 15/300 - Train loss: 1.0826 - Test loss: 1.1101 - Test score: -0.1195\n",
      "Epoch 16/300 - Train loss: 1.0627 - Test loss: 1.0905 - Test score: -0.0993\n",
      "Epoch 17/300 - Train loss: 1.0463 - Test loss: 1.0734 - Test score: -0.0816\n",
      "Epoch 18/300 - Train loss: 1.0303 - Test loss: 1.0589 - Test score: -0.0665\n",
      "Epoch 19/300 - Train loss: 1.0179 - Test loss: 1.0466 - Test score: -0.0538\n",
      "Epoch 20/300 - Train loss: 1.0064 - Test loss: 1.0356 - Test score: -0.0425\n",
      "Epoch 21/300 - Train loss: 0.9970 - Test loss: 1.0251 - Test score: -0.0316\n",
      "Epoch 22/300 - Train loss: 0.9868 - Test loss: 1.0164 - Test score: -0.0226\n",
      "Epoch 23/300 - Train loss: 0.9785 - Test loss: 1.0086 - Test score: -0.0145\n",
      "Epoch 24/300 - Train loss: 0.9719 - Test loss: 1.0007 - Test score: -0.0063\n",
      "Epoch 25/300 - Train loss: 0.9649 - Test loss: 0.9946 - Test score: 0.0000\n",
      "Epoch 26/300 - Train loss: 0.9567 - Test loss: 0.9879 - Test score: 0.0069\n",
      "Epoch 27/300 - Train loss: 0.9516 - Test loss: 0.9823 - Test score: 0.0127\n",
      "Epoch 28/300 - Train loss: 0.9434 - Test loss: 0.9761 - Test score: 0.0191\n",
      "Epoch 29/300 - Train loss: 0.9382 - Test loss: 0.9707 - Test score: 0.0247\n",
      "Epoch 30/300 - Train loss: 0.9331 - Test loss: 0.9642 - Test score: 0.0315\n",
      "Epoch 31/300 - Train loss: 0.9282 - Test loss: 0.9595 - Test score: 0.0364\n",
      "Epoch 32/300 - Train loss: 0.9223 - Test loss: 0.9562 - Test score: 0.0398\n",
      "Epoch 33/300 - Train loss: 0.9178 - Test loss: 0.9517 - Test score: 0.0445\n",
      "Epoch 34/300 - Train loss: 0.9135 - Test loss: 0.9473 - Test score: 0.0490\n",
      "Epoch 35/300 - Train loss: 0.9093 - Test loss: 0.9441 - Test score: 0.0523\n",
      "Epoch 36/300 - Train loss: 0.9042 - Test loss: 0.9390 - Test score: 0.0576\n",
      "Epoch 37/300 - Train loss: 0.9018 - Test loss: 0.9369 - Test score: 0.0597\n",
      "Epoch 38/300 - Train loss: 0.8968 - Test loss: 0.9346 - Test score: 0.0621\n",
      "Epoch 39/300 - Train loss: 0.8950 - Test loss: 0.9300 - Test score: 0.0669\n",
      "Epoch 40/300 - Train loss: 0.8906 - Test loss: 0.9258 - Test score: 0.0713\n",
      "Epoch 41/300 - Train loss: 0.8871 - Test loss: 0.9234 - Test score: 0.0738\n",
      "Epoch 42/300 - Train loss: 0.8847 - Test loss: 0.9207 - Test score: 0.0766\n",
      "Epoch 43/300 - Train loss: 0.8814 - Test loss: 0.9212 - Test score: 0.0760\n",
      "Epoch 44/300 - Train loss: 0.8783 - Test loss: 0.9179 - Test score: 0.0795\n",
      "Epoch 45/300 - Train loss: 0.8757 - Test loss: 0.9139 - Test score: 0.0836\n",
      "Epoch 46/300 - Train loss: 0.8742 - Test loss: 0.9109 - Test score: 0.0868\n",
      "Epoch 47/300 - Train loss: 0.8721 - Test loss: 0.9109 - Test score: 0.0867\n",
      "Epoch 48/300 - Train loss: 0.8697 - Test loss: 0.9059 - Test score: 0.0920\n",
      "Epoch 49/300 - Train loss: 0.8657 - Test loss: 0.9050 - Test score: 0.0929\n",
      "Epoch 50/300 - Train loss: 0.8644 - Test loss: 0.9047 - Test score: 0.0932\n",
      "Epoch 51/300 - Train loss: 0.8618 - Test loss: 0.9029 - Test score: 0.0950\n",
      "Epoch 52/300 - Train loss: 0.8590 - Test loss: 0.9006 - Test score: 0.0974\n",
      "Epoch 53/300 - Train loss: 0.8596 - Test loss: 0.8989 - Test score: 0.0992\n",
      "Epoch 54/300 - Train loss: 0.8563 - Test loss: 0.8979 - Test score: 0.1002\n",
      "Epoch 55/300 - Train loss: 0.8533 - Test loss: 0.8980 - Test score: 0.1000\n",
      "Epoch 56/300 - Train loss: 0.8536 - Test loss: 0.8943 - Test score: 0.1040\n",
      "Epoch 57/300 - Train loss: 0.8505 - Test loss: 0.9004 - Test score: 0.0974\n",
      "Epoch 58/300 - Train loss: 0.8505 - Test loss: 0.8971 - Test score: 0.1008\n",
      "Epoch 59/300 - Train loss: 0.8483 - Test loss: 0.8948 - Test score: 0.1032\n",
      "Epoch 60/300 - Train loss: 0.8471 - Test loss: 0.8952 - Test score: 0.1028\n",
      "Epoch 61/300 - Train loss: 0.8457 - Test loss: 0.8908 - Test score: 0.1075\n",
      "Epoch 62/300 - Train loss: 0.8450 - Test loss: 0.8896 - Test score: 0.1087\n",
      "Epoch 63/300 - Train loss: 0.8425 - Test loss: 0.8933 - Test score: 0.1047\n",
      "Epoch 64/300 - Train loss: 0.8412 - Test loss: 0.8880 - Test score: 0.1103\n",
      "Epoch 65/300 - Train loss: 0.8401 - Test loss: 0.8885 - Test score: 0.1097\n",
      "Epoch 66/300 - Train loss: 0.8395 - Test loss: 0.8885 - Test score: 0.1097\n",
      "Epoch 67/300 - Train loss: 0.8383 - Test loss: 0.8858 - Test score: 0.1125\n",
      "Epoch 68/300 - Train loss: 0.8378 - Test loss: 0.8879 - Test score: 0.1103\n",
      "Epoch 69/300 - Train loss: 0.8357 - Test loss: 0.8841 - Test score: 0.1143\n",
      "Epoch 70/300 - Train loss: 0.8354 - Test loss: 0.8830 - Test score: 0.1155\n",
      "Epoch 71/300 - Train loss: 0.8340 - Test loss: 0.8873 - Test score: 0.1108\n",
      "Epoch 72/300 - Train loss: 0.8330 - Test loss: 0.8819 - Test score: 0.1166\n",
      "Epoch 73/300 - Train loss: 0.8320 - Test loss: 0.8836 - Test score: 0.1147\n",
      "Epoch 74/300 - Train loss: 0.8326 - Test loss: 0.8811 - Test score: 0.1174\n",
      "Epoch 75/300 - Train loss: 0.8305 - Test loss: 0.8808 - Test score: 0.1177\n",
      "Epoch 76/300 - Train loss: 0.8302 - Test loss: 0.8805 - Test score: 0.1180\n",
      "Epoch 77/300 - Train loss: 0.8292 - Test loss: 0.8811 - Test score: 0.1173\n",
      "Epoch 78/300 - Train loss: 0.8297 - Test loss: 0.8854 - Test score: 0.1127\n",
      "Epoch 79/300 - Train loss: 0.8285 - Test loss: 0.8787 - Test score: 0.1198\n",
      "Epoch 80/300 - Train loss: 0.8277 - Test loss: 0.8804 - Test score: 0.1180\n",
      "Epoch 81/300 - Train loss: 0.8265 - Test loss: 0.8794 - Test score: 0.1190\n",
      "Epoch 82/300 - Train loss: 0.8265 - Test loss: 0.8798 - Test score: 0.1186\n",
      "Epoch 83/300 - Train loss: 0.8253 - Test loss: 0.8774 - Test score: 0.1211\n",
      "Epoch 84/300 - Train loss: 0.8234 - Test loss: 0.8786 - Test score: 0.1198\n",
      "Epoch 85/300 - Train loss: 0.8238 - Test loss: 0.8805 - Test score: 0.1177\n",
      "Epoch 86/300 - Train loss: 0.8231 - Test loss: 0.8781 - Test score: 0.1203\n",
      "Epoch 87/300 - Train loss: 0.8228 - Test loss: 0.8812 - Test score: 0.1169\n",
      "Epoch 88/300 - Train loss: 0.8228 - Test loss: 0.8773 - Test score: 0.1212\n",
      "Epoch 89/300 - Train loss: 0.8229 - Test loss: 0.8821 - Test score: 0.1159\n",
      "Epoch 90/300 - Train loss: 0.8211 - Test loss: 0.8750 - Test score: 0.1236\n",
      "Epoch 91/300 - Train loss: 0.8213 - Test loss: 0.8800 - Test score: 0.1181\n",
      "Epoch 92/300 - Train loss: 0.8195 - Test loss: 0.8736 - Test score: 0.1250\n",
      "Epoch 93/300 - Train loss: 0.8200 - Test loss: 0.8743 - Test score: 0.1242\n",
      "Epoch 94/300 - Train loss: 0.8201 - Test loss: 0.8745 - Test score: 0.1239\n",
      "Epoch 95/300 - Train loss: 0.8184 - Test loss: 0.8742 - Test score: 0.1243\n",
      "Epoch 96/300 - Train loss: 0.8186 - Test loss: 0.8756 - Test score: 0.1228\n",
      "Epoch 97/300 - Train loss: 0.8180 - Test loss: 0.8764 - Test score: 0.1218\n",
      "Epoch 98/300 - Train loss: 0.8170 - Test loss: 0.8755 - Test score: 0.1228\n",
      "Epoch 99/300 - Train loss: 0.8171 - Test loss: 0.8761 - Test score: 0.1221\n",
      "Epoch 100/300 - Train loss: 0.8167 - Test loss: 0.8749 - Test score: 0.1234\n",
      "Epoch 101/300 - Train loss: 0.8158 - Test loss: 0.8770 - Test score: 0.1212\n",
      "Epoch 102/300 - Train loss: 0.8157 - Test loss: 0.8746 - Test score: 0.1237\n",
      "\n",
      "Layer 8 - Score: 0.1250\n",
      "Layer obs - Score: 0.4562\n",
      "Average score over all layers: 0.5051\n",
      "ball speed vertical\n",
      "Epoch 1/300 - Train loss: 1.2840 - Test loss: 0.9750 - Test score: -0.0036\n",
      "Epoch 2/300 - Train loss: 0.9649 - Test loss: 0.9316 - Test score: 0.0415\n",
      "Epoch 3/300 - Train loss: 0.9359 - Test loss: 0.9097 - Test score: 0.0642\n",
      "Epoch 4/300 - Train loss: 0.9071 - Test loss: 0.9127 - Test score: 0.0614\n",
      "Epoch 5/300 - Train loss: 0.8828 - Test loss: 0.8789 - Test score: 0.0962\n",
      "Epoch 6/300 - Train loss: 0.8770 - Test loss: 0.8666 - Test score: 0.1087\n",
      "Epoch 7/300 - Train loss: 0.8510 - Test loss: 0.8743 - Test score: 0.1011\n",
      "Epoch 8/300 - Train loss: 0.8406 - Test loss: 0.8498 - Test score: 0.1262\n",
      "Epoch 9/300 - Train loss: 0.8164 - Test loss: 0.8372 - Test score: 0.1390\n",
      "Epoch 10/300 - Train loss: 0.8296 - Test loss: 0.8378 - Test score: 0.1379\n",
      "Epoch 11/300 - Train loss: 0.8037 - Test loss: 0.8416 - Test score: 0.1334\n",
      "Epoch 12/300 - Train loss: 0.8085 - Test loss: 0.8537 - Test score: 0.1220\n",
      "Epoch 13/300 - Train loss: 0.7852 - Test loss: 0.8114 - Test score: 0.1651\n",
      "Epoch 14/300 - Train loss: 0.7821 - Test loss: 0.8091 - Test score: 0.1676\n",
      "Epoch 15/300 - Train loss: 0.7816 - Test loss: 0.8015 - Test score: 0.1752\n",
      "Epoch 16/300 - Train loss: 0.7562 - Test loss: 0.7961 - Test score: 0.1807\n",
      "Epoch 17/300 - Train loss: 0.7461 - Test loss: 0.7921 - Test score: 0.1847\n",
      "Epoch 18/300 - Train loss: 0.7523 - Test loss: 0.8140 - Test score: 0.1625\n",
      "Epoch 19/300 - Train loss: 0.7440 - Test loss: 0.7873 - Test score: 0.1895\n",
      "Epoch 20/300 - Train loss: 0.7404 - Test loss: 0.8874 - Test score: 0.0840\n",
      "Epoch 21/300 - Train loss: 0.7353 - Test loss: 0.7850 - Test score: 0.1915\n",
      "Epoch 22/300 - Train loss: 0.7285 - Test loss: 0.7977 - Test score: 0.1780\n",
      "Epoch 23/300 - Train loss: 0.7184 - Test loss: 0.7766 - Test score: 0.2002\n",
      "Epoch 24/300 - Train loss: 0.7071 - Test loss: 0.7714 - Test score: 0.2055\n",
      "Epoch 25/300 - Train loss: 0.7005 - Test loss: 0.7684 - Test score: 0.2085\n",
      "Epoch 26/300 - Train loss: 0.6936 - Test loss: 0.7774 - Test score: 0.1998\n",
      "Epoch 27/300 - Train loss: 0.7153 - Test loss: 0.8464 - Test score: 0.1288\n",
      "Epoch 28/300 - Train loss: 0.7217 - Test loss: 0.8123 - Test score: 0.1621\n",
      "Epoch 29/300 - Train loss: 0.7082 - Test loss: 0.7635 - Test score: 0.2135\n",
      "Epoch 30/300 - Train loss: 0.6748 - Test loss: 0.7591 - Test score: 0.2181\n",
      "Epoch 31/300 - Train loss: 0.6693 - Test loss: 0.7979 - Test score: 0.1786\n",
      "Epoch 32/300 - Train loss: 0.6768 - Test loss: 0.8703 - Test score: 0.1013\n",
      "Epoch 33/300 - Train loss: 0.6661 - Test loss: 0.7773 - Test score: 0.1998\n",
      "Epoch 34/300 - Train loss: 0.6815 - Test loss: 0.7669 - Test score: 0.2105\n",
      "Epoch 35/300 - Train loss: 0.7060 - Test loss: 0.7535 - Test score: 0.2239\n",
      "Epoch 36/300 - Train loss: 0.6759 - Test loss: 0.7493 - Test score: 0.2279\n",
      "Epoch 37/300 - Train loss: 0.6531 - Test loss: 0.8537 - Test score: 0.1208\n",
      "Epoch 38/300 - Train loss: 0.6694 - Test loss: 0.7483 - Test score: 0.2290\n",
      "Epoch 39/300 - Train loss: 0.6528 - Test loss: 0.7567 - Test score: 0.2200\n",
      "Epoch 40/300 - Train loss: 0.6449 - Test loss: 0.7621 - Test score: 0.2143\n",
      "Epoch 41/300 - Train loss: 0.6608 - Test loss: 0.7477 - Test score: 0.2299\n",
      "Epoch 42/300 - Train loss: 0.6362 - Test loss: 0.7490 - Test score: 0.2285\n",
      "Epoch 43/300 - Train loss: 0.6468 - Test loss: 0.7509 - Test score: 0.2266\n",
      "Epoch 44/300 - Train loss: 0.6473 - Test loss: 0.7731 - Test score: 0.2038\n",
      "Epoch 45/300 - Train loss: 0.6517 - Test loss: 0.7598 - Test score: 0.2163\n",
      "Epoch 46/300 - Train loss: 0.6393 - Test loss: 0.7667 - Test score: 0.2103\n",
      "Epoch 47/300 - Train loss: 0.6455 - Test loss: 0.9283 - Test score: 0.0400\n",
      "Epoch 48/300 - Train loss: 0.6593 - Test loss: 0.7414 - Test score: 0.2356\n",
      "Epoch 49/300 - Train loss: 0.6409 - Test loss: 0.8084 - Test score: 0.1673\n",
      "Epoch 50/300 - Train loss: 0.6281 - Test loss: 0.7421 - Test score: 0.2356\n",
      "Epoch 51/300 - Train loss: 0.6299 - Test loss: 0.8681 - Test score: 0.1056\n",
      "Epoch 52/300 - Train loss: 0.6191 - Test loss: 0.7454 - Test score: 0.2314\n",
      "Epoch 53/300 - Train loss: 0.6211 - Test loss: 0.7356 - Test score: 0.2420\n",
      "Epoch 54/300 - Train loss: 0.6099 - Test loss: 0.7619 - Test score: 0.2139\n",
      "Epoch 55/300 - Train loss: 0.6123 - Test loss: 0.8235 - Test score: 0.1492\n",
      "Epoch 56/300 - Train loss: 0.6242 - Test loss: 0.8243 - Test score: 0.1507\n",
      "Epoch 57/300 - Train loss: 0.6368 - Test loss: 0.7772 - Test score: 0.1976\n",
      "Epoch 58/300 - Train loss: 0.6025 - Test loss: 0.7691 - Test score: 0.2076\n",
      "Epoch 59/300 - Train loss: 0.6034 - Test loss: 0.7552 - Test score: 0.2210\n",
      "Epoch 60/300 - Train loss: 0.6259 - Test loss: 0.7313 - Test score: 0.2461\n",
      "Epoch 61/300 - Train loss: 0.6036 - Test loss: 0.7536 - Test score: 0.2234\n",
      "Epoch 62/300 - Train loss: 0.5974 - Test loss: 0.7749 - Test score: 0.2015\n",
      "Epoch 63/300 - Train loss: 0.5993 - Test loss: 0.7306 - Test score: 0.2467\n",
      "Epoch 64/300 - Train loss: 0.6132 - Test loss: 0.7307 - Test score: 0.2468\n",
      "Epoch 65/300 - Train loss: 0.5974 - Test loss: 0.7290 - Test score: 0.2484\n",
      "Epoch 66/300 - Train loss: 0.5934 - Test loss: 0.7404 - Test score: 0.2370\n",
      "Epoch 67/300 - Train loss: 0.5945 - Test loss: 0.7332 - Test score: 0.2439\n",
      "Epoch 68/300 - Train loss: 0.5975 - Test loss: 0.7483 - Test score: 0.2289\n",
      "Epoch 69/300 - Train loss: 0.6048 - Test loss: 0.7372 - Test score: 0.2395\n",
      "Epoch 70/300 - Train loss: 0.5829 - Test loss: 0.7458 - Test score: 0.2305\n",
      "Epoch 71/300 - Train loss: 0.5841 - Test loss: 0.7274 - Test score: 0.2500\n",
      "Epoch 72/300 - Train loss: 0.5855 - Test loss: 0.7299 - Test score: 0.2472\n",
      "Epoch 73/300 - Train loss: 0.5898 - Test loss: 0.7328 - Test score: 0.2445\n",
      "Epoch 74/300 - Train loss: 0.5983 - Test loss: 0.7550 - Test score: 0.2218\n",
      "Epoch 75/300 - Train loss: 0.5887 - Test loss: 0.7282 - Test score: 0.2490\n",
      "Epoch 76/300 - Train loss: 0.5882 - Test loss: 0.7295 - Test score: 0.2476\n",
      "Epoch 77/300 - Train loss: 0.6066 - Test loss: 0.7825 - Test score: 0.1935\n",
      "Epoch 78/300 - Train loss: 0.5773 - Test loss: 0.7264 - Test score: 0.2509\n",
      "Epoch 79/300 - Train loss: 0.5804 - Test loss: 0.7271 - Test score: 0.2502\n",
      "Epoch 80/300 - Train loss: 0.5765 - Test loss: 0.7243 - Test score: 0.2531\n",
      "Epoch 81/300 - Train loss: 0.5769 - Test loss: 0.7264 - Test score: 0.2508\n",
      "Epoch 82/300 - Train loss: 0.5832 - Test loss: 0.7246 - Test score: 0.2528\n",
      "Epoch 83/300 - Train loss: 0.5692 - Test loss: 0.7337 - Test score: 0.2429\n",
      "Epoch 84/300 - Train loss: 0.5650 - Test loss: 0.7353 - Test score: 0.2416\n",
      "Epoch 85/300 - Train loss: 0.5648 - Test loss: 0.7258 - Test score: 0.2516\n",
      "Epoch 86/300 - Train loss: 0.5685 - Test loss: 0.7236 - Test score: 0.2536\n",
      "Epoch 87/300 - Train loss: 0.5677 - Test loss: 0.7278 - Test score: 0.2497\n",
      "Epoch 88/300 - Train loss: 0.5634 - Test loss: 0.7281 - Test score: 0.2491\n",
      "Epoch 89/300 - Train loss: 0.5755 - Test loss: 0.7457 - Test score: 0.2312\n",
      "Epoch 90/300 - Train loss: 0.5688 - Test loss: 0.7331 - Test score: 0.2441\n",
      "Epoch 91/300 - Train loss: 0.5645 - Test loss: 0.7256 - Test score: 0.2514\n",
      "Epoch 92/300 - Train loss: 0.5588 - Test loss: 0.7623 - Test score: 0.2140\n",
      "Epoch 93/300 - Train loss: 0.5892 - Test loss: 0.7552 - Test score: 0.2202\n",
      "Epoch 94/300 - Train loss: 0.5601 - Test loss: 0.7253 - Test score: 0.2517\n",
      "Epoch 95/300 - Train loss: 0.5908 - Test loss: 0.7466 - Test score: 0.2294\n",
      "Epoch 96/300 - Train loss: 0.5602 - Test loss: 0.7249 - Test score: 0.2519\n",
      "\n",
      "Layer 0 - Score: 0.2536\n",
      "Layer 1 - Score: 0.4459\n",
      "Layer 2 - Score: 0.4167\n",
      "Layer 3 - Score: 0.5777\n",
      "Layer 4 - Score: 0.5522\n",
      "Layer 5 - Score: 0.6433\n",
      "Layer 6 - Score: 0.6431\n",
      "Layer 7 - Score: 0.3727\n",
      "Epoch 1/300 - Train loss: 5.9189 - Test loss: 4.4031 - Test score: -3.5594\n",
      "Epoch 2/300 - Train loss: 3.6039 - Test loss: 2.8422 - Test score: -1.9391\n",
      "Epoch 3/300 - Train loss: 2.4956 - Test loss: 2.1019 - Test score: -1.1724\n",
      "Epoch 4/300 - Train loss: 1.9313 - Test loss: 1.6985 - Test score: -0.7550\n",
      "Epoch 5/300 - Train loss: 1.6039 - Test loss: 1.4575 - Test score: -0.5056\n",
      "Epoch 6/300 - Train loss: 1.3990 - Test loss: 1.3034 - Test score: -0.3460\n",
      "Epoch 7/300 - Train loss: 1.2676 - Test loss: 1.2071 - Test score: -0.2463\n",
      "Epoch 8/300 - Train loss: 1.1840 - Test loss: 1.1444 - Test score: -0.1812\n",
      "Epoch 9/300 - Train loss: 1.1301 - Test loss: 1.1027 - Test score: -0.1380\n",
      "Epoch 10/300 - Train loss: 1.0943 - Test loss: 1.0735 - Test score: -0.1077\n",
      "Epoch 11/300 - Train loss: 1.0690 - Test loss: 1.0527 - Test score: -0.0861\n",
      "Epoch 12/300 - Train loss: 1.0497 - Test loss: 1.0365 - Test score: -0.0693\n",
      "Epoch 13/300 - Train loss: 1.0355 - Test loss: 1.0233 - Test score: -0.0556\n",
      "Epoch 14/300 - Train loss: 1.0218 - Test loss: 1.0125 - Test score: -0.0443\n",
      "Epoch 15/300 - Train loss: 1.0126 - Test loss: 1.0033 - Test score: -0.0347\n",
      "Epoch 16/300 - Train loss: 1.0035 - Test loss: 0.9954 - Test score: -0.0264\n",
      "Epoch 17/300 - Train loss: 0.9959 - Test loss: 0.9882 - Test score: -0.0190\n",
      "Epoch 18/300 - Train loss: 0.9881 - Test loss: 0.9818 - Test score: -0.0123\n",
      "Epoch 19/300 - Train loss: 0.9823 - Test loss: 0.9761 - Test score: -0.0064\n",
      "Epoch 20/300 - Train loss: 0.9749 - Test loss: 0.9708 - Test score: -0.0009\n",
      "Epoch 21/300 - Train loss: 0.9709 - Test loss: 0.9657 - Test score: 0.0043\n",
      "Epoch 22/300 - Train loss: 0.9645 - Test loss: 0.9612 - Test score: 0.0091\n",
      "Epoch 23/300 - Train loss: 0.9602 - Test loss: 0.9569 - Test score: 0.0136\n",
      "Epoch 24/300 - Train loss: 0.9545 - Test loss: 0.9532 - Test score: 0.0174\n",
      "Epoch 25/300 - Train loss: 0.9508 - Test loss: 0.9499 - Test score: 0.0209\n",
      "Epoch 26/300 - Train loss: 0.9453 - Test loss: 0.9460 - Test score: 0.0249\n",
      "Epoch 27/300 - Train loss: 0.9427 - Test loss: 0.9432 - Test score: 0.0278\n",
      "Epoch 28/300 - Train loss: 0.9391 - Test loss: 0.9399 - Test score: 0.0312\n",
      "Epoch 29/300 - Train loss: 0.9364 - Test loss: 0.9376 - Test score: 0.0337\n",
      "Epoch 30/300 - Train loss: 0.9310 - Test loss: 0.9345 - Test score: 0.0369\n",
      "Epoch 31/300 - Train loss: 0.9275 - Test loss: 0.9322 - Test score: 0.0393\n",
      "Epoch 32/300 - Train loss: 0.9250 - Test loss: 0.9298 - Test score: 0.0418\n",
      "Epoch 33/300 - Train loss: 0.9220 - Test loss: 0.9282 - Test score: 0.0435\n",
      "Epoch 34/300 - Train loss: 0.9191 - Test loss: 0.9261 - Test score: 0.0456\n",
      "Epoch 35/300 - Train loss: 0.9156 - Test loss: 0.9237 - Test score: 0.0480\n",
      "Epoch 36/300 - Train loss: 0.9130 - Test loss: 0.9225 - Test score: 0.0495\n",
      "Epoch 37/300 - Train loss: 0.9112 - Test loss: 0.9206 - Test score: 0.0514\n",
      "Epoch 38/300 - Train loss: 0.9089 - Test loss: 0.9190 - Test score: 0.0531\n",
      "Epoch 39/300 - Train loss: 0.9063 - Test loss: 0.9176 - Test score: 0.0545\n",
      "Epoch 40/300 - Train loss: 0.9041 - Test loss: 0.9161 - Test score: 0.0561\n",
      "Epoch 41/300 - Train loss: 0.9030 - Test loss: 0.9147 - Test score: 0.0576\n",
      "Epoch 42/300 - Train loss: 0.9019 - Test loss: 0.9138 - Test score: 0.0585\n",
      "Epoch 43/300 - Train loss: 0.8994 - Test loss: 0.9125 - Test score: 0.0599\n",
      "Epoch 44/300 - Train loss: 0.8976 - Test loss: 0.9118 - Test score: 0.0606\n",
      "Epoch 45/300 - Train loss: 0.8952 - Test loss: 0.9105 - Test score: 0.0619\n",
      "Epoch 46/300 - Train loss: 0.8937 - Test loss: 0.9098 - Test score: 0.0627\n",
      "Epoch 47/300 - Train loss: 0.8927 - Test loss: 0.9094 - Test score: 0.0632\n",
      "Epoch 48/300 - Train loss: 0.8924 - Test loss: 0.9086 - Test score: 0.0640\n",
      "Epoch 49/300 - Train loss: 0.8902 - Test loss: 0.9069 - Test score: 0.0657\n",
      "Epoch 50/300 - Train loss: 0.8882 - Test loss: 0.9071 - Test score: 0.0656\n",
      "Epoch 51/300 - Train loss: 0.8861 - Test loss: 0.9064 - Test score: 0.0663\n",
      "Epoch 52/300 - Train loss: 0.8864 - Test loss: 0.9050 - Test score: 0.0677\n",
      "Epoch 53/300 - Train loss: 0.8858 - Test loss: 0.9046 - Test score: 0.0682\n",
      "Epoch 54/300 - Train loss: 0.8841 - Test loss: 0.9040 - Test score: 0.0688\n",
      "Epoch 55/300 - Train loss: 0.8814 - Test loss: 0.9032 - Test score: 0.0696\n",
      "Epoch 56/300 - Train loss: 0.8823 - Test loss: 0.9034 - Test score: 0.0695\n",
      "Epoch 57/300 - Train loss: 0.8804 - Test loss: 0.9025 - Test score: 0.0704\n",
      "Epoch 58/300 - Train loss: 0.8795 - Test loss: 0.9023 - Test score: 0.0706\n",
      "Epoch 59/300 - Train loss: 0.8777 - Test loss: 0.9014 - Test score: 0.0715\n",
      "Epoch 60/300 - Train loss: 0.8765 - Test loss: 0.9012 - Test score: 0.0718\n",
      "Epoch 61/300 - Train loss: 0.8762 - Test loss: 0.9009 - Test score: 0.0722\n",
      "Epoch 62/300 - Train loss: 0.8755 - Test loss: 0.9003 - Test score: 0.0727\n",
      "Epoch 63/300 - Train loss: 0.8752 - Test loss: 0.8997 - Test score: 0.0733\n",
      "Epoch 64/300 - Train loss: 0.8739 - Test loss: 0.8995 - Test score: 0.0736\n",
      "Epoch 65/300 - Train loss: 0.8726 - Test loss: 0.8994 - Test score: 0.0737\n",
      "Epoch 66/300 - Train loss: 0.8709 - Test loss: 0.8990 - Test score: 0.0741\n",
      "Epoch 67/300 - Train loss: 0.8712 - Test loss: 0.8997 - Test score: 0.0735\n",
      "Epoch 68/300 - Train loss: 0.8705 - Test loss: 0.8986 - Test score: 0.0746\n",
      "Epoch 69/300 - Train loss: 0.8687 - Test loss: 0.8981 - Test score: 0.0751\n",
      "Epoch 70/300 - Train loss: 0.8695 - Test loss: 0.8990 - Test score: 0.0742\n",
      "Epoch 71/300 - Train loss: 0.8682 - Test loss: 0.8979 - Test score: 0.0754\n",
      "Epoch 72/300 - Train loss: 0.8691 - Test loss: 0.8987 - Test score: 0.0746\n",
      "Epoch 73/300 - Train loss: 0.8673 - Test loss: 0.8973 - Test score: 0.0760\n",
      "Epoch 74/300 - Train loss: 0.8668 - Test loss: 0.8973 - Test score: 0.0760\n",
      "Epoch 75/300 - Train loss: 0.8669 - Test loss: 0.8971 - Test score: 0.0763\n",
      "Epoch 76/300 - Train loss: 0.8650 - Test loss: 0.8980 - Test score: 0.0754\n",
      "Epoch 77/300 - Train loss: 0.8641 - Test loss: 0.8968 - Test score: 0.0766\n",
      "Epoch 78/300 - Train loss: 0.8645 - Test loss: 0.8972 - Test score: 0.0762\n",
      "Epoch 79/300 - Train loss: 0.8640 - Test loss: 0.8966 - Test score: 0.0768\n",
      "Epoch 80/300 - Train loss: 0.8646 - Test loss: 0.8975 - Test score: 0.0759\n",
      "Epoch 81/300 - Train loss: 0.8628 - Test loss: 0.8968 - Test score: 0.0766\n",
      "Epoch 82/300 - Train loss: 0.8614 - Test loss: 0.8971 - Test score: 0.0764\n",
      "Epoch 83/300 - Train loss: 0.8615 - Test loss: 0.8961 - Test score: 0.0774\n",
      "Epoch 84/300 - Train loss: 0.8619 - Test loss: 0.8962 - Test score: 0.0772\n",
      "Epoch 85/300 - Train loss: 0.8619 - Test loss: 0.8963 - Test score: 0.0772\n",
      "Epoch 86/300 - Train loss: 0.8605 - Test loss: 0.8958 - Test score: 0.0777\n",
      "Epoch 87/300 - Train loss: 0.8601 - Test loss: 0.8958 - Test score: 0.0777\n",
      "Epoch 88/300 - Train loss: 0.8599 - Test loss: 0.8964 - Test score: 0.0771\n",
      "Epoch 89/300 - Train loss: 0.8588 - Test loss: 0.8957 - Test score: 0.0778\n",
      "Epoch 90/300 - Train loss: 0.8582 - Test loss: 0.8957 - Test score: 0.0778\n",
      "Epoch 91/300 - Train loss: 0.8578 - Test loss: 0.8956 - Test score: 0.0779\n",
      "Epoch 92/300 - Train loss: 0.8576 - Test loss: 0.8971 - Test score: 0.0764\n",
      "Epoch 93/300 - Train loss: 0.8587 - Test loss: 0.8953 - Test score: 0.0782\n",
      "Epoch 94/300 - Train loss: 0.8566 - Test loss: 0.8977 - Test score: 0.0758\n",
      "Epoch 95/300 - Train loss: 0.8585 - Test loss: 0.8954 - Test score: 0.0781\n",
      "Epoch 96/300 - Train loss: 0.8558 - Test loss: 0.8953 - Test score: 0.0783\n",
      "Epoch 97/300 - Train loss: 0.8555 - Test loss: 0.8974 - Test score: 0.0761\n",
      "Epoch 98/300 - Train loss: 0.8564 - Test loss: 0.8950 - Test score: 0.0786\n",
      "Epoch 99/300 - Train loss: 0.8548 - Test loss: 0.8949 - Test score: 0.0787\n",
      "Epoch 100/300 - Train loss: 0.8556 - Test loss: 0.8950 - Test score: 0.0785\n",
      "Epoch 101/300 - Train loss: 0.8541 - Test loss: 0.8950 - Test score: 0.0786\n",
      "Epoch 102/300 - Train loss: 0.8547 - Test loss: 0.8955 - Test score: 0.0782\n",
      "Epoch 103/300 - Train loss: 0.8533 - Test loss: 0.8952 - Test score: 0.0785\n",
      "Epoch 104/300 - Train loss: 0.8539 - Test loss: 0.8954 - Test score: 0.0783\n",
      "Epoch 105/300 - Train loss: 0.8530 - Test loss: 0.8953 - Test score: 0.0783\n",
      "Epoch 106/300 - Train loss: 0.8538 - Test loss: 0.8952 - Test score: 0.0785\n",
      "Epoch 107/300 - Train loss: 0.8522 - Test loss: 0.8958 - Test score: 0.0778\n",
      "Epoch 108/300 - Train loss: 0.8530 - Test loss: 0.8956 - Test score: 0.0781\n",
      "Epoch 109/300 - Train loss: 0.8520 - Test loss: 0.8951 - Test score: 0.0786\n",
      "\n",
      "Layer 8 - Score: 0.0787\n",
      "Epoch 1/300 - Train loss: 1.3706 - Test loss: 0.9610 - Test score: 0.0109\n",
      "Epoch 2/300 - Train loss: 0.9674 - Test loss: 0.9345 - Test score: 0.0385\n",
      "Epoch 3/300 - Train loss: 0.9422 - Test loss: 0.9209 - Test score: 0.0525\n",
      "Epoch 4/300 - Train loss: 0.9187 - Test loss: 0.9041 - Test score: 0.0700\n",
      "Epoch 5/300 - Train loss: 0.9090 - Test loss: 0.8913 - Test score: 0.0830\n",
      "Epoch 6/300 - Train loss: 0.8826 - Test loss: 0.9782 - Test score: -0.0082\n",
      "Epoch 7/300 - Train loss: 0.8767 - Test loss: 0.8712 - Test score: 0.1039\n",
      "Epoch 8/300 - Train loss: 0.8672 - Test loss: 0.8655 - Test score: 0.1102\n",
      "Epoch 9/300 - Train loss: 0.8329 - Test loss: 0.9055 - Test score: 0.0673\n",
      "Epoch 10/300 - Train loss: 0.8409 - Test loss: 0.8643 - Test score: 0.1105\n",
      "Epoch 11/300 - Train loss: 0.8115 - Test loss: 0.8582 - Test score: 0.1167\n",
      "Epoch 12/300 - Train loss: 0.8173 - Test loss: 0.8359 - Test score: 0.1405\n",
      "Epoch 13/300 - Train loss: 0.7880 - Test loss: 0.8282 - Test score: 0.1484\n",
      "Epoch 14/300 - Train loss: 0.8016 - Test loss: 0.8238 - Test score: 0.1527\n",
      "Epoch 15/300 - Train loss: 0.8010 - Test loss: 0.8165 - Test score: 0.1605\n",
      "Epoch 16/300 - Train loss: 0.7656 - Test loss: 0.8130 - Test score: 0.1638\n",
      "Epoch 17/300 - Train loss: 0.7792 - Test loss: 0.8062 - Test score: 0.1709\n",
      "Epoch 18/300 - Train loss: 0.7824 - Test loss: 0.8805 - Test score: 0.0950\n",
      "Epoch 19/300 - Train loss: 0.7524 - Test loss: 0.7992 - Test score: 0.1782\n",
      "Epoch 20/300 - Train loss: 0.7298 - Test loss: 0.7948 - Test score: 0.1827\n",
      "Epoch 21/300 - Train loss: 0.7296 - Test loss: 0.8376 - Test score: 0.1372\n",
      "Epoch 22/300 - Train loss: 0.7119 - Test loss: 0.7911 - Test score: 0.1867\n",
      "Epoch 23/300 - Train loss: 0.7343 - Test loss: 0.8182 - Test score: 0.1589\n",
      "Epoch 24/300 - Train loss: 0.7034 - Test loss: 0.8089 - Test score: 0.1684\n",
      "Epoch 25/300 - Train loss: 0.6984 - Test loss: 0.7860 - Test score: 0.1911\n",
      "Epoch 26/300 - Train loss: 0.6922 - Test loss: 0.7766 - Test score: 0.2011\n",
      "Epoch 27/300 - Train loss: 0.6920 - Test loss: 0.7859 - Test score: 0.1921\n",
      "Epoch 28/300 - Train loss: 0.6911 - Test loss: 0.9254 - Test score: 0.0450\n",
      "Epoch 29/300 - Train loss: 0.6734 - Test loss: 0.7762 - Test score: 0.2019\n",
      "Epoch 30/300 - Train loss: 0.6637 - Test loss: 0.7718 - Test score: 0.2064\n",
      "Epoch 31/300 - Train loss: 0.6756 - Test loss: 0.7675 - Test score: 0.2108\n",
      "Epoch 32/300 - Train loss: 0.6565 - Test loss: 0.7617 - Test score: 0.2165\n",
      "Epoch 33/300 - Train loss: 0.6600 - Test loss: 0.8003 - Test score: 0.1756\n",
      "Epoch 34/300 - Train loss: 0.6411 - Test loss: 0.7627 - Test score: 0.2152\n",
      "Epoch 35/300 - Train loss: 0.6343 - Test loss: 0.8007 - Test score: 0.1768\n",
      "Epoch 36/300 - Train loss: 0.6511 - Test loss: 0.8092 - Test score: 0.1661\n",
      "Epoch 37/300 - Train loss: 0.6270 - Test loss: 0.7710 - Test score: 0.2060\n",
      "Epoch 38/300 - Train loss: 0.6246 - Test loss: 0.7920 - Test score: 0.1839\n",
      "Epoch 39/300 - Train loss: 0.6415 - Test loss: 0.7511 - Test score: 0.2274\n",
      "Epoch 40/300 - Train loss: 0.6177 - Test loss: 0.7499 - Test score: 0.2285\n",
      "Epoch 41/300 - Train loss: 0.6182 - Test loss: 0.7471 - Test score: 0.2313\n",
      "Epoch 42/300 - Train loss: 0.6342 - Test loss: 0.7901 - Test score: 0.1875\n",
      "Epoch 43/300 - Train loss: 0.5952 - Test loss: 0.7620 - Test score: 0.2153\n",
      "Epoch 44/300 - Train loss: 0.5952 - Test loss: 0.7459 - Test score: 0.2329\n",
      "Epoch 45/300 - Train loss: 0.6072 - Test loss: 0.7458 - Test score: 0.2330\n",
      "Epoch 46/300 - Train loss: 0.5903 - Test loss: 0.7536 - Test score: 0.2242\n",
      "Epoch 47/300 - Train loss: 0.5870 - Test loss: 0.7381 - Test score: 0.2405\n",
      "Epoch 48/300 - Train loss: 0.5786 - Test loss: 0.7467 - Test score: 0.2319\n",
      "Epoch 49/300 - Train loss: 0.5788 - Test loss: 0.7471 - Test score: 0.2316\n",
      "Epoch 50/300 - Train loss: 0.5870 - Test loss: 0.7370 - Test score: 0.2418\n",
      "Epoch 51/300 - Train loss: 0.5713 - Test loss: 0.7356 - Test score: 0.2433\n",
      "Epoch 52/300 - Train loss: 0.5720 - Test loss: 0.7338 - Test score: 0.2450\n",
      "Epoch 53/300 - Train loss: 0.5738 - Test loss: 0.7328 - Test score: 0.2460\n",
      "Epoch 54/300 - Train loss: 0.5555 - Test loss: 0.7544 - Test score: 0.2241\n",
      "Epoch 55/300 - Train loss: 0.5873 - Test loss: 0.7480 - Test score: 0.2297\n",
      "Epoch 56/300 - Train loss: 0.5536 - Test loss: 0.7451 - Test score: 0.2327\n",
      "Epoch 57/300 - Train loss: 0.5500 - Test loss: 0.8206 - Test score: 0.1535\n",
      "Epoch 58/300 - Train loss: 0.5528 - Test loss: 0.7297 - Test score: 0.2491\n",
      "Epoch 59/300 - Train loss: 0.5390 - Test loss: 0.7392 - Test score: 0.2397\n",
      "Epoch 60/300 - Train loss: 0.5346 - Test loss: 0.7299 - Test score: 0.2487\n",
      "Epoch 61/300 - Train loss: 0.5454 - Test loss: 0.7411 - Test score: 0.2369\n",
      "Epoch 62/300 - Train loss: 0.5382 - Test loss: 0.7351 - Test score: 0.2438\n",
      "Epoch 63/300 - Train loss: 0.5295 - Test loss: 0.7257 - Test score: 0.2532\n",
      "Epoch 64/300 - Train loss: 0.5332 - Test loss: 0.7313 - Test score: 0.2471\n",
      "Epoch 65/300 - Train loss: 0.5482 - Test loss: 0.7302 - Test score: 0.2488\n",
      "Epoch 66/300 - Train loss: 0.5277 - Test loss: 0.7391 - Test score: 0.2387\n",
      "Epoch 67/300 - Train loss: 0.5244 - Test loss: 0.7564 - Test score: 0.2206\n",
      "Epoch 68/300 - Train loss: 0.5235 - Test loss: 0.7620 - Test score: 0.2162\n",
      "Epoch 69/300 - Train loss: 0.5172 - Test loss: 0.7567 - Test score: 0.2217\n",
      "Epoch 70/300 - Train loss: 0.5103 - Test loss: 0.7216 - Test score: 0.2575\n",
      "Epoch 71/300 - Train loss: 0.5018 - Test loss: 0.7247 - Test score: 0.2541\n",
      "Epoch 72/300 - Train loss: 0.5115 - Test loss: 0.7212 - Test score: 0.2579\n",
      "Epoch 73/300 - Train loss: 0.5024 - Test loss: 0.7203 - Test score: 0.2587\n",
      "Epoch 74/300 - Train loss: 0.5023 - Test loss: 0.7531 - Test score: 0.2254\n",
      "Epoch 75/300 - Train loss: 0.5022 - Test loss: 0.7194 - Test score: 0.2596\n",
      "Epoch 76/300 - Train loss: 0.4861 - Test loss: 0.7290 - Test score: 0.2501\n",
      "Epoch 77/300 - Train loss: 0.5000 - Test loss: 0.7659 - Test score: 0.2120\n",
      "Epoch 78/300 - Train loss: 0.4904 - Test loss: 0.7184 - Test score: 0.2607\n",
      "Epoch 79/300 - Train loss: 0.4832 - Test loss: 0.7444 - Test score: 0.2342\n",
      "Epoch 80/300 - Train loss: 0.4771 - Test loss: 0.7335 - Test score: 0.2454\n",
      "Epoch 81/300 - Train loss: 0.4736 - Test loss: 0.7177 - Test score: 0.2613\n",
      "Epoch 82/300 - Train loss: 0.4774 - Test loss: 0.7267 - Test score: 0.2524\n",
      "Epoch 83/300 - Train loss: 0.4675 - Test loss: 0.7214 - Test score: 0.2574\n",
      "Epoch 84/300 - Train loss: 0.4689 - Test loss: 0.7243 - Test score: 0.2542\n",
      "Epoch 85/300 - Train loss: 0.4793 - Test loss: 0.7179 - Test score: 0.2611\n",
      "Epoch 86/300 - Train loss: 0.4655 - Test loss: 0.7230 - Test score: 0.2557\n",
      "Epoch 87/300 - Train loss: 0.4683 - Test loss: 0.7177 - Test score: 0.2612\n",
      "Epoch 88/300 - Train loss: 0.4714 - Test loss: 0.7175 - Test score: 0.2617\n",
      "Epoch 89/300 - Train loss: 0.4651 - Test loss: 0.7612 - Test score: 0.2169\n",
      "Epoch 90/300 - Train loss: 0.4690 - Test loss: 0.7174 - Test score: 0.2616\n",
      "Epoch 91/300 - Train loss: 0.4542 - Test loss: 0.7191 - Test score: 0.2599\n",
      "Epoch 92/300 - Train loss: 0.4665 - Test loss: 0.7173 - Test score: 0.2617\n",
      "Epoch 93/300 - Train loss: 0.4534 - Test loss: 0.7567 - Test score: 0.2215\n",
      "Epoch 94/300 - Train loss: 0.4578 - Test loss: 0.7197 - Test score: 0.2594\n",
      "Epoch 95/300 - Train loss: 0.4621 - Test loss: 0.7307 - Test score: 0.2474\n",
      "Epoch 96/300 - Train loss: 0.4489 - Test loss: 0.7558 - Test score: 0.2211\n",
      "Epoch 97/300 - Train loss: 0.4414 - Test loss: 0.7275 - Test score: 0.2509\n",
      "Epoch 98/300 - Train loss: 0.4523 - Test loss: 0.8222 - Test score: 0.1517\n",
      "Epoch 99/300 - Train loss: 0.4428 - Test loss: 0.7452 - Test score: 0.2321\n",
      "Epoch 100/300 - Train loss: 0.4337 - Test loss: 0.7149 - Test score: 0.2641\n",
      "Epoch 101/300 - Train loss: 0.4344 - Test loss: 0.7157 - Test score: 0.2634\n",
      "Epoch 102/300 - Train loss: 0.4389 - Test loss: 0.7161 - Test score: 0.2629\n",
      "Epoch 103/300 - Train loss: 0.4338 - Test loss: 0.7369 - Test score: 0.2409\n",
      "Epoch 104/300 - Train loss: 0.4353 - Test loss: 0.7453 - Test score: 0.2321\n",
      "Epoch 105/300 - Train loss: 0.4359 - Test loss: 0.7279 - Test score: 0.2504\n",
      "Epoch 106/300 - Train loss: 0.4287 - Test loss: 0.7512 - Test score: 0.2270\n",
      "Epoch 107/300 - Train loss: 0.4252 - Test loss: 0.7161 - Test score: 0.2629\n",
      "Epoch 108/300 - Train loss: 0.4275 - Test loss: 0.7172 - Test score: 0.2619\n",
      "Epoch 109/300 - Train loss: 0.4428 - Test loss: 0.7178 - Test score: 0.2610\n",
      "Epoch 110/300 - Train loss: 0.4207 - Test loss: 0.7195 - Test score: 0.2592\n",
      "\n",
      "Layer obs - Score: 0.2641\n",
      "Average score over all layers: 0.4248\n",
      "game steps\n",
      "Layer 0 - Score: 0.9972\n",
      "Layer 1 - Score: 0.9991\n",
      "Layer 2 - Score: 0.9982\n",
      "Layer 3 - Score: 0.9982\n",
      "Layer 4 - Score: 0.9971\n",
      "Layer 5 - Score: 0.9965\n",
      "Layer 6 - Score: 0.9965\n",
      "Layer 7 - Score: 0.9709\n",
      "Layer 8 - Score: 0.7189\n",
      "Layer obs - Score: 0.9972\n",
      "Average score over all layers: 0.9670\n",
      "bricks hit\n",
      "Layer 0 - Score: 0.9996\n",
      "Layer 1 - Score: 0.9995\n",
      "Layer 2 - Score: 0.9993\n",
      "Layer 3 - Score: 0.9988\n",
      "Layer 4 - Score: 0.9979\n",
      "Layer 5 - Score: 0.9973\n",
      "Layer 6 - Score: 0.9973\n",
      "Layer 7 - Score: 0.9822\n",
      "Layer 8 - Score: 0.7964\n",
      "Layer obs - Score: 0.9998\n",
      "Average score over all layers: 0.9768\n",
      "0.705512561162009\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "total_scores = []\n",
    "for concept in concept_instances.values():\n",
    "    print(concept.name)\n",
    "    layer_scores = train_probes(game_data, q_network, concept, hyperparams)\n",
    "    scores = list(layer_scores.values())\n",
    "    total_scores.extend(scores)\n",
    "    print(f\"Average score over all layers: {np.mean(scores):.4f}\")\n",
    "print(np.mean(total_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
