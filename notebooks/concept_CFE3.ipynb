{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn\n",
    "\n",
    "from src.DRL.qnetwork import QNetwork\n",
    "from src.Qrunner.qrunner import QrunnerEnv\n",
    "from src.XAI.concept import Concept\n",
    "from src.XAI.concept_probes import train_probes\n",
    "from src.XAI.concepts import concept_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_steps = Concept.load_concept_data()\n",
    "sample_concept = concept_instances['random continuous']\n",
    "sample_concept.prepare_data(env_steps)\n",
    "test_obs = sample_concept.test_obs\n",
    "test_images = sample_concept.test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: runs/20240224-103820_task_0/model_10000000.pt at layer: 4\n"
     ]
    }
   ],
   "source": [
    "model_path = QNetwork.find_newest_model()\n",
    "#model_path = \"runs/20240222-134350_task_0/model_1000000.pt\"\n",
    "model = QNetwork(frame_stacks=1, model_path=model_path)\n",
    "layer = 4\n",
    "print(f\"Using model: {model_path} at layer: {layer}\")\n",
    "\n",
    "test_q_values, test_acts_dict = model(torch.tensor(test_obs), return_acts=True)\n",
    "test_acts = test_acts_dict[layer].cpu().detach().numpy()\n",
    "test_acts = test_acts.reshape(test_acts.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           random binary            |   0.0230   | no\n",
      "         random continuous          |   0.0180   | no\n",
      "            player low              |   0.9900   | yes\n",
      "            difficulty              |   0.9240   | yes\n",
      "           player in air            |   0.9650   | yes\n",
      "       player dodging in air        |   0.8910   | yes\n",
      "      player standing on wall       |   0.9480   | yes\n",
      "      player dodging on wall        |   0.8290   | yes\n",
      "          events quantity           |   0.7930   | no\n",
      "           visible wall             |   0.9180   | yes\n",
      "          visible bullet            |   0.9160   | yes\n",
      "           visible lava             |   0.9670   | yes\n",
      "           coin quantity            |   0.7160   | no\n",
      "        good visible events         |   0.7570   | no\n",
      "        bad visible events          |   0.8880   | yes\n",
      "           bullet close             |   0.7970   | no\n",
      "    bullet aligned with player      |   0.7740   | no\n",
      "          player dodging            |   0.9460   | yes\n",
      "          coin above lava           |   0.7000   | no\n",
      "         lava below player          |   0.9340   | yes\n",
      "        bullet below player         |   0.8890   | yes\n",
      "        reachable good coin         |   0.8670   | yes\n",
      "       unreachable good coin        |   0.8920   | yes\n"
     ]
    }
   ],
   "source": [
    "concept_cavs = {}\n",
    "for concept in concept_instances.values():\n",
    "    probe, score = concept.load_torch_probe()\n",
    "    if score > 0.8:\n",
    "        cav = probe[1].weight.data.cpu().numpy().squeeze()\n",
    "        concept_cavs[concept.name] = cav\n",
    "        print(f\"{concept.name:^35} | {score:^10.4f} | yes\")\n",
    "    else:\n",
    "        print(f\"{concept.name:^35} | {score:^10.4f} | no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    return dot_product / (norm_v1 * norm_v2)\n",
    "\n",
    "def action_name(action_idx):\n",
    "    return QrunnerEnv.get_action_meanings()[action_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def get_CFE(original_idx):\n",
    "    original_obs = test_obs[original_idx]\n",
    "    original_img = test_images[original_idx]\n",
    "    original_q_values = test_q_values[original_idx].cpu().detach().numpy()\n",
    "    original_action = action_name(np.argmax(original_q_values))\n",
    "    original_acts = test_acts[original_idx]\n",
    "    \n",
    "    similarities = []\n",
    "    for i, other_acts in enumerate(test_acts):\n",
    "        if i == original_idx or action_name(np.argmax(test_q_values[i].cpu().detach().numpy())) == original_action:\n",
    "            continue\n",
    "        sim = cosine_similarity(original_acts, other_acts)\n",
    "        similarities.append((i, sim))\n",
    "\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    #plt.plot([sim for _, sim in similarities[:200]])\n",
    "    #plt.show()\n",
    "\n",
    "    n = 200\n",
    "    top_n_indices = [idx for idx, _ in similarities[:n]]\n",
    "\n",
    "    actions = [action_name(np.argmax(test_q_values[i].cpu().detach().numpy())) for i in top_n_indices]\n",
    "    most_common_action, _ = Counter(actions).most_common(1)[0]\n",
    "\n",
    "    other_action_examples = [i for i in top_n_indices if action_name(np.argmax(test_q_values[i].cpu().detach().numpy())) == most_common_action]\n",
    "    number_of_examples = len(other_action_examples)\n",
    "    other_action = most_common_action\n",
    "    \n",
    "    '''\n",
    "    print(f\"Original action: {original_action}\")\n",
    "    print(f\"Other action: {other_action}\")\n",
    "    print(f\"Number of other action examples: {number_of_examples}\")\n",
    "    '''\n",
    "    \n",
    "    negative_to_positive = []\n",
    "    positive_to_negative = []\n",
    "    for i in other_action_examples:\n",
    "        for concept, cav in concept_cavs.items():\n",
    "            original_sim = cosine_similarity(original_acts, cav)\n",
    "            other_sim = cosine_similarity(test_acts[i], cav)\n",
    "\n",
    "            if np.sign(original_sim) != np.sign(other_sim):\n",
    "                if original_sim < 0:\n",
    "                    negative_to_positive.append(concept)\n",
    "                else:\n",
    "                    positive_to_negative.append(concept)\n",
    "                \n",
    "    freq_negative_to_positive = Counter(negative_to_positive)\n",
    "    freq_positive_to_negative = Counter(positive_to_negative)\n",
    "    \n",
    "    print(f\"Frequency of negative to positive: {freq_negative_to_positive}\")\n",
    "    print(f\"Frequency of positive to negative: {freq_positive_to_negative}\")\n",
    "\n",
    "    # Check if count/number_of_examples > threshold\n",
    "    threshold = 0.5\n",
    "    positive_relevant_concepts = [concept for concept, count in freq_negative_to_positive.items() if count/number_of_examples >= threshold][:2]\n",
    "    negative_relevant_concepts = [concept for concept, count in freq_positive_to_negative.items() if count/number_of_examples >= threshold][:2]\n",
    "    # Constructing the conditional sentence parts based on the list contents\n",
    "    positive_part = f\"more ({', '.join(positive_relevant_concepts)})\" if positive_relevant_concepts else \"\"\n",
    "    negative_part = f\"less ({', '.join(negative_relevant_concepts)})\" if negative_relevant_concepts else \"\"\n",
    "\n",
    "    # Combining the parts with proper language structure\n",
    "    condition_parts = []\n",
    "    if positive_part:\n",
    "        condition_parts.append(positive_part)\n",
    "    if negative_part:\n",
    "        condition_parts.append(negative_part)\n",
    "\n",
    "    condition_sentence = \", and \".join(condition_parts)\n",
    "\n",
    "    print(f\"If there was {condition_sentence}, then the agent would do ({other_action}) instead of ({original_action})\")\n",
    "        \n",
    "    plt.imshow(original_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 4778\n",
      "Frequency of negative to positive: Counter({'visible wall': 132, 'player in air': 40, 'reachable good coin': 32, 'unreachable good coin': 11, 'visible bullet': 3, 'player dodging in air': 1, 'player dodging': 1})\n",
      "Frequency of positive to negative: Counter({'visible lava': 106, 'bad visible events': 17})\n",
      "If there was more (visible wall), and less (visible lava), then the agent would do (RIGHT) instead of (JUMP)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ex_idx = random.randint(0, len(test_obs)-1)\n",
    "print(f\"Example {ex_idx}\")\n",
    "get_CFE(ex_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
