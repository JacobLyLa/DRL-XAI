{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import linear_model\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "from concepts import concept_instances\n",
    "from utils import load_data, prepare_folders, load_q_network_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: ball left paddle (b), dataset size: 6138\n",
      "ball left paddle (b)\n"
     ]
    }
   ],
   "source": [
    "data = load_data()\n",
    "concept = concept_instances[\"ball left paddle (b)\"]\n",
    "concept.prepare_data(data)\n",
    "q_network, device = load_q_network_device()\n",
    "layer = 5\n",
    "print(concept.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_r2(train_acts, train_values, test_acts, test_values):\n",
    "    reg = linear_model.LassoCV(max_iter=50, cv=5, n_alphas=5)\n",
    "    reg.fit(train_acts, train_values)\n",
    "    pred = reg.predict(test_acts)\n",
    "    score = r2_score(test_values, pred)\n",
    "    return reg, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(train_acts, train_values, test_acts, test_values):\n",
    "    reg = linear_model.LogisticRegressionCV(max_iter=100, cv=10, Cs=10)\n",
    "    reg.fit(train_acts, train_values)\n",
    "    pred = reg.predict(test_acts)\n",
    "    score = accuracy_score(test_values, pred)\n",
    "    return reg, 2*score-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8387622149837133\n"
     ]
    }
   ],
   "source": [
    "_, train_acts_dict = q_network(torch.tensor(concept.obs_train).to(device), return_acts=True)\n",
    "test_q_values, test_acts_dict = q_network(torch.tensor(concept.obs_test).to(device), return_acts=True)\n",
    "\n",
    "train_acts = train_acts_dict[str(layer)].cpu().detach().numpy()\n",
    "test_acts = test_acts_dict[str(layer)].cpu().detach().numpy()\n",
    "train_acts = train_acts.reshape(len(train_acts), -1)\n",
    "test_acts = test_acts.reshape(len(test_acts), -1)\n",
    "\n",
    "reg, score = calculate_accuracy(train_acts, concept.values_train, test_acts, concept.values_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cav = reg.coef_[0]\n",
    "# pertubate a tiny bit of cav and see how q values change\n",
    "test_acts_changed = torch.tensor(test_acts + (0.0001 * cav), dtype=torch.float32).to(device)\n",
    "test_acts_changed = test_acts_changed.reshape(test_acts_dict[str(layer)].shape)\n",
    "# forward activations from given layer\n",
    "test_q_values_changed = q_network.network[layer + 1:](test_acts_changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.9599, 4.9614, 4.9644, 4.9293], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([4.9599, 4.9614, 4.9644, 4.9293], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([2.0027e-05, 2.0027e-05, 7.2002e-05, 4.7684e-07], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(test_q_values[0])\n",
    "print(test_q_values_changed[0])\n",
    "print(test_q_values[0] - test_q_values_changed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30048859119415283\n"
     ]
    }
   ],
   "source": [
    "# how often does max increase?\n",
    "q_values_diff = test_q_values_changed - test_q_values\n",
    "max_diff = test_q_values_changed.max(dim=1)[0] - test_q_values.max(dim=1)[0]\n",
    "improvements = sum(max_diff > 0) / len(max_diff)\n",
    "print(improvements.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None: 0.3135179153094462\n",
      "Fire: 0.31433224755700323\n",
      "Right: 0.050488599348534204\n",
      "Left: 0.42671009771986973\n"
     ]
    }
   ],
   "source": [
    "# how often does the q value for each action increase?\n",
    "improvement_counter = {0: 0, 1: 0, 2: 0, 3: 0}\n",
    "for i in range(len(q_values_diff)):\n",
    "    improvement = q_values_diff[i] > 0\n",
    "    for j in range(4):\n",
    "        if improvement[j]:\n",
    "            improvement_counter[j] += 1\n",
    "        \n",
    "actions = ['None', 'Fire', 'Right', 'Left']\n",
    "for i in range(4):\n",
    "    print(f\"{actions[i]}: {improvement_counter[i] / len(q_values_diff)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do same with other concept (TODO: refactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: ball right paddle (b), dataset size: 5952\n",
      "0.7932773109243698\n",
      "tensor([4.7373, 4.7412, 4.7121, 4.6895], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([4.7372, 4.7412, 4.7121, 4.6894], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([5.0068e-05, 5.0068e-05, 3.8147e-06, 7.2002e-05], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "0.3176470696926117\n",
      "None: 0.26638655462184874\n",
      "Fire: 0.2714285714285714\n",
      "Right: 0.7184873949579832\n",
      "Left: 0.17899159663865546\n"
     ]
    }
   ],
   "source": [
    "concept = concept_instances[\"ball right paddle (b)\"]\n",
    "concept.prepare_data(data)\n",
    "_, train_acts_dict = q_network(torch.tensor(concept.obs_train).to(device), return_acts=True)\n",
    "test_q_values, test_acts_dict = q_network(torch.tensor(concept.obs_test).to(device), return_acts=True)\n",
    "\n",
    "layer = 5\n",
    "train_acts = train_acts_dict[str(layer)].cpu().detach().numpy()\n",
    "test_acts = test_acts_dict[str(layer)].cpu().detach().numpy()\n",
    "train_acts = train_acts.reshape(len(train_acts), -1)\n",
    "test_acts = test_acts.reshape(len(test_acts), -1)\n",
    "\n",
    "reg, score = calculate_accuracy(train_acts, concept.values_train, test_acts, concept.values_test)\n",
    "print(score)\n",
    "cav = reg.coef_[0]\n",
    "# pertubate a tiny bit of cav and see how q values change\n",
    "test_acts_changed = torch.tensor(test_acts + (0.0001 * cav), dtype=torch.float32).to(device)\n",
    "test_acts_changed = test_acts_changed.reshape(test_acts_dict[str(layer)].shape)\n",
    "# forward activations from given layer\n",
    "test_q_values_changed = q_network.network[layer + 1:](test_acts_changed)\n",
    "\n",
    "print(test_q_values[0])\n",
    "print(test_q_values_changed[0])\n",
    "print(test_q_values[0] - test_q_values_changed[0])\n",
    "q_values_diff = test_q_values_changed - test_q_values\n",
    "\n",
    "# how often does max increase?\n",
    "max_diff = test_q_values_changed.max(dim=1)[0] - test_q_values.max(dim=1)[0]\n",
    "improvements = sum(max_diff > 0) / len(max_diff)\n",
    "print(improvements.item())\n",
    "\n",
    "# how often does the q value for each action increase?\n",
    "improvement_counter = {0: 0, 1: 0, 2: 0, 3: 0}\n",
    "for i in range(len(q_values_diff)):\n",
    "    improvement = q_values_diff[i] > 0\n",
    "    for j in range(4):\n",
    "        if improvement[j]:\n",
    "            improvement_counter[j] += 1\n",
    "        \n",
    "actions = ['None', 'Fire', 'Right', 'Left']\n",
    "for i in range(4):\n",
    "    print(f\"{actions[i]}: {improvement_counter[i] / len(q_values_diff)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
