{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jacob/Desktop/prosjektoppgave/tcav_atari/src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import linear_model\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "from concepts import concept_instances\n",
    "from train_model import load_model\n",
    "from utils import load_data, prepare_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "q_network = load_model(\"../runs/20230927-233906/models/model_9999999.pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "for concept in concept_instances.values():\n",
    "    concept.prepare_data(data, max_size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_r2(train_acts, train_values, test_acts, test_values):\n",
    "    reg = linear_model.LassoCV(max_iter=50, cv=5, n_alphas=5)\n",
    "    reg.fit(train_acts, train_values)\n",
    "    pred = reg.predict(test_acts)\n",
    "    score = r2_score(test_values, pred)\n",
    "    return reg, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(train_acts, train_values, test_acts, test_values):\n",
    "    reg = linear_model.LogisticRegressionCV(max_iter=100, cv=10, Cs=10)\n",
    "    reg.fit(train_acts, train_values)\n",
    "    pred = reg.predict(test_acts)\n",
    "    score = accuracy_score(test_values, pred)\n",
    "    return reg, 2*score-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8366666666666667\n"
     ]
    }
   ],
   "source": [
    "concept = concept_instances[\"ball left paddle (b)\"]\n",
    "_, train_acts_dict = q_network(torch.tensor(concept.obs_train).to(device), return_acts=True)\n",
    "test_q_values, test_acts_dict = q_network(torch.tensor(concept.obs_test).to(device), return_acts=True)\n",
    "\n",
    "layer = 5\n",
    "train_acts = train_acts_dict[str(layer)].cpu().detach().numpy()\n",
    "test_acts = test_acts_dict[str(layer)].cpu().detach().numpy()\n",
    "train_acts = train_acts.reshape(len(train_acts), -1)\n",
    "test_acts = test_acts.reshape(len(test_acts), -1)\n",
    "\n",
    "reg, score = calculate_accuracy(train_acts, concept.values_train, test_acts, concept.values_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reg.intercept_ > 0: # TODO: positive then cav points to positive class, otherwise it points away?\n",
    "    cav = reg.coef_[0]\n",
    "else:\n",
    "    cav = -reg.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pertubate a tiny bit of cav and see how q values change\n",
    "test_acts_changed = torch.tensor(test_acts + (0.0001 * cav), dtype=torch.float32).to(device)\n",
    "test_acts_changed = test_acts_changed.reshape(test_acts_dict[str(layer)].shape)\n",
    "# forward activations from given layer\n",
    "test_q_values_changed = q_network.network[layer + 1:](test_acts_changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.3660, 4.3731, 4.3353, 4.3615], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([4.3660, 4.3730, 4.3352, 4.3615], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([4.9114e-05, 5.6744e-05, 1.1015e-04, 1.6689e-05], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(test_q_values[0])\n",
    "print(test_q_values_changed[0])\n",
    "print(test_q_values[0] - test_q_values_changed[0])\n",
    "q_values_diff = test_q_values_changed - test_q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40833333134651184\n"
     ]
    }
   ],
   "source": [
    "# how often does max increase?\n",
    "max_diff = test_q_values_changed.max(dim=1)[0] - test_q_values.max(dim=1)[0]\n",
    "improvements = sum(max_diff > 0) / len(max_diff)\n",
    "print(improvements.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None: 0.415\n",
      "Fire: 0.41833333333333333\n",
      "Right: 0.155\n",
      "Left: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "# how often does the q value for each action increase?\n",
    "improvement_counter = {0: 0, 1: 0, 2: 0, 3: 0}\n",
    "for i in range(len(q_values_diff)):\n",
    "    improvement = q_values_diff[i] > 0\n",
    "    for j in range(4):\n",
    "        if improvement[j]:\n",
    "            improvement_counter[j] += 1\n",
    "        \n",
    "actions = ['None', 'Fire', 'Right', 'Left']\n",
    "for i in range(4):\n",
    "    print(f\"{actions[i]}: {improvement_counter[i] / len(q_values_diff)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do same with other concept (todo refactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8266666666666667\n",
      "tensor([5.1732, 5.1733, 5.1466, 5.1700], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([5.1731, 5.1732, 5.1467, 5.1699], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([ 7.7724e-05,  8.7261e-05, -3.4809e-05,  1.6594e-04], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "0.4883333444595337\n",
      "None: 0.48\n",
      "Fire: 0.4766666666666667\n",
      "Right: 0.7533333333333333\n",
      "Left: 0.37166666666666665\n"
     ]
    }
   ],
   "source": [
    "concept = concept_instances[\"ball right paddle (b)\"]\n",
    "_, train_acts_dict = q_network(torch.tensor(concept.obs_train).to(device), return_acts=True)\n",
    "test_q_values, test_acts_dict = q_network(torch.tensor(concept.obs_test).to(device), return_acts=True)\n",
    "\n",
    "layer = 5\n",
    "train_acts = train_acts_dict[str(layer)].cpu().detach().numpy()\n",
    "test_acts = test_acts_dict[str(layer)].cpu().detach().numpy()\n",
    "train_acts = train_acts.reshape(len(train_acts), -1)\n",
    "test_acts = test_acts.reshape(len(test_acts), -1)\n",
    "\n",
    "reg, score = calculate_accuracy(train_acts, concept.values_train, test_acts, concept.values_test)\n",
    "print(score)\n",
    "\n",
    "if reg.intercept_ > 0: # TODO: positive then cav points to positive class, otherwise it points away?\n",
    "    cav = reg.coef_[0]\n",
    "else:\n",
    "    cav = -reg.coef_[0]\n",
    "\n",
    "# pertubate a tiny bit of cav and see how q values change\n",
    "test_acts_changed = torch.tensor(test_acts + (0.0001 * cav), dtype=torch.float32).to(device)\n",
    "test_acts_changed = test_acts_changed.reshape(test_acts_dict[str(layer)].shape)\n",
    "# forward activations from given layer\n",
    "test_q_values_changed = q_network.network[layer + 1:](test_acts_changed)\n",
    "\n",
    "print(test_q_values[0])\n",
    "print(test_q_values_changed[0])\n",
    "print(test_q_values[0] - test_q_values_changed[0])\n",
    "q_values_diff = test_q_values_changed - test_q_values\n",
    "\n",
    "# how often does max increase?\n",
    "max_diff = test_q_values_changed.max(dim=1)[0] - test_q_values.max(dim=1)[0]\n",
    "improvements = sum(max_diff > 0) / len(max_diff)\n",
    "print(improvements.item())\n",
    "\n",
    "# how often does the q value for each action increase?\n",
    "improvement_counter = {0: 0, 1: 0, 2: 0, 3: 0}\n",
    "for i in range(len(q_values_diff)):\n",
    "    improvement = q_values_diff[i] > 0\n",
    "    for j in range(4):\n",
    "        if improvement[j]:\n",
    "            improvement_counter[j] += 1\n",
    "        \n",
    "actions = ['None', 'Fire', 'Right', 'Left']\n",
    "for i in range(4):\n",
    "    print(f\"{actions[i]}: {improvement_counter[i] / len(q_values_diff)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
